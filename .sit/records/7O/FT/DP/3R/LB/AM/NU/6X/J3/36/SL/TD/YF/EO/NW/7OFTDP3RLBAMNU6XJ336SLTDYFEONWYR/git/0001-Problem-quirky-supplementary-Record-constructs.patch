From 63476a3339a870f2574c94dfd39050a29641b54c Mon Sep 17 00:00:00 2001
From: Yurii Rashkovskii <me@yrashk.com>
Date: Sat, 19 May 2018 15:40:36 -0700
Subject: [PATCH] Problem: quirky supplementary Record constructs

As a solution for the need to sign records, a whole
mechanism of `FilteredRecord` and `DynamicallyHashedRecord`
was introduced.

They are relatively hard to understand and have led to
very error-prone practices. For example, the injection
of the signature is done in an "off-site" record, its
new hash is calculated by wrapping that record into
a `DynamicallyHashedRecord` and its re-hashed value
is used to finally move the record into its right place.

Similarly, the verification of signature's validity is
done by wrapping a record into a `FilteredRecord` to
recalculate the hash without the signature.

Also, it has led to the creation of a very confusing
API of a `path()` and `actual_path()` for the `Record`.

Solution: extracting ordering and hashing primitives

This change takes a long (but, hopefully, right in the
longterm) approach of, firstly, abstracting a file.
Before, a file is always a tuple of its name and a reader
(`Read`). Now, anything that implements `File` trait,
will be treated as such.

Secondly, this introduces the `OrderedFiles` primitive
that always contains the list of files in an sorted order,
to ensure that SIT will *always* process files in the correct
order.

With these changes, the end-user program can compute hashes
on existing and to-be-created records without having to
resort to tricky APIs and file management issues.
---
 Cargo.lock                 |  43 +++++++
 sit-core/Cargo.toml        |   1 +
 sit-core/src/item.rs       |   6 +-
 sit-core/src/lib.rs        |   1 +
 sit-core/src/record.rs     | 230 ++++++++++++++++++++++++++++++++++++++
 sit-core/src/repository.rs | 271 ++++++++-------------------------------------
 sit-web/src/webapp.rs      |  51 ++++-----
 sit/src/command_record.rs  | 134 +++++++++++-----------
 sit/src/command_records.rs |  19 ++--
 9 files changed, 418 insertions(+), 338 deletions(-)

diff --git a/Cargo.lock b/Cargo.lock
index 6d471e9..caac6e3 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -82,6 +82,19 @@ dependencies = [
  "safemem 0.2.0 (registry+https://github.com/rust-lang/crates.io-index)",
 ]
 
+[[package]]
+name = "bit-set"
+version = "0.5.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+dependencies = [
+ "bit-vec 0.5.0 (registry+https://github.com/rust-lang/crates.io-index)",
+]
+
+[[package]]
+name = "bit-vec"
+version = "0.5.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+
 [[package]]
 name = "bitflags"
 version = "1.0.1"
@@ -833,11 +846,30 @@ dependencies = [
  "unicode-xid 0.1.0 (registry+https://github.com/rust-lang/crates.io-index)",
 ]
 
+[[package]]
+name = "proptest"
+version = "0.7.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+dependencies = [
+ "bit-set 0.5.0 (registry+https://github.com/rust-lang/crates.io-index)",
+ "bitflags 1.0.1 (registry+https://github.com/rust-lang/crates.io-index)",
+ "lazy_static 1.0.0 (registry+https://github.com/rust-lang/crates.io-index)",
+ "num-traits 0.2.2 (registry+https://github.com/rust-lang/crates.io-index)",
+ "quick-error 1.2.1 (registry+https://github.com/rust-lang/crates.io-index)",
+ "rand 0.4.2 (registry+https://github.com/rust-lang/crates.io-index)",
+ "regex-syntax 0.4.2 (registry+https://github.com/rust-lang/crates.io-index)",
+]
+
 [[package]]
 name = "question"
 version = "0.2.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 
+[[package]]
+name = "quick-error"
+version = "1.2.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+
 [[package]]
 name = "quote"
 version = "0.3.15"
@@ -922,6 +954,11 @@ name = "regex-syntax"
 version = "0.3.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 
+[[package]]
+name = "regex-syntax"
+version = "0.4.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+
 [[package]]
 name = "remove_dir_all"
 version = "0.5.1"
@@ -1100,6 +1137,7 @@ dependencies = [
  "include_dir 0.1.5 (registry+https://github.com/rust-lang/crates.io-index)",
  "lazy_static 1.0.0 (registry+https://github.com/rust-lang/crates.io-index)",
  "memmap 0.6.2 (registry+https://github.com/rust-lang/crates.io-index)",
+ "proptest 0.7.0 (registry+https://github.com/rust-lang/crates.io-index)",
  "serde 1.0.43 (registry+https://github.com/rust-lang/crates.io-index)",
  "serde_derive 1.0.43 (registry+https://github.com/rust-lang/crates.io-index)",
  "serde_json 1.0.16 (registry+https://github.com/rust-lang/crates.io-index)",
@@ -1479,6 +1517,8 @@ dependencies = [
 "checksum backtrace 0.3.6 (registry+https://github.com/rust-lang/crates.io-index)" = "ebbe525f66f42d207968308ee86bc2dd60aa5fab535b22e616323a173d097d8e"
 "checksum backtrace-sys 0.1.16 (registry+https://github.com/rust-lang/crates.io-index)" = "44585761d6161b0f57afc49482ab6bd067e4edef48c12a152c237eb0203f7661"
 "checksum base64 0.7.0 (registry+https://github.com/rust-lang/crates.io-index)" = "5032d51da2741729bfdaeb2664d9b8c6d9fd1e2b90715c660b6def36628499c2"
+"checksum bit-set 0.5.0 (registry+https://github.com/rust-lang/crates.io-index)" = "6f1efcc46c18245a69c38fcc5cc650f16d3a59d034f3106e9ed63748f695730a"
+"checksum bit-vec 0.5.0 (registry+https://github.com/rust-lang/crates.io-index)" = "4440d5cb623bb7390ae27fec0bb6c61111969860f8e3ae198bfa0663645e67cf"
 "checksum bitflags 1.0.1 (registry+https://github.com/rust-lang/crates.io-index)" = "b3c30d3802dfb7281680d6285f2ccdaa8c2d8fee41f93805dba5c4cf50dc23cf"
 "checksum blake2 0.7.0 (registry+https://github.com/rust-lang/crates.io-index)" = "b0da79fe9391e02df251e0d86197332d398b4721e80722fc91b9c4cbde3ce355"
 "checksum block-buffer 0.3.3 (registry+https://github.com/rust-lang/crates.io-index)" = "a076c298b9ecdb530ed9d967e74a6027d6a7478924520acddcddc24c1c8ab3ab"
@@ -1575,7 +1615,9 @@ dependencies = [
 "checksum phf_shared 0.7.21 (registry+https://github.com/rust-lang/crates.io-index)" = "07e24b0ca9643bdecd0632f2b3da6b1b89bbb0030e0b992afc1113b23a7bc2f2"
 "checksum pkg-config 0.3.11 (registry+https://github.com/rust-lang/crates.io-index)" = "110d5ee3593dbb73f56294327fe5668bcc997897097cbc76b51e7aed3f52452f"
 "checksum proc-macro2 0.3.7 (registry+https://github.com/rust-lang/crates.io-index)" = "b16749538926f394755373f0dfec0852d79b3bd512a5906ceaeb72ee64a4eaa0"
+"checksum proptest 0.7.0 (registry+https://github.com/rust-lang/crates.io-index)" = "a3ff101e7a7be1104b3d71f194bc10a3fa338e89b3539444cfde6fdb3aae94a1"
 "checksum question 0.2.1 (registry+https://github.com/rust-lang/crates.io-index)" = "d8cd16f7171d3c3d246b994e491d105f0dba9559e9b925c54ad136c49b2f6146"
+"checksum quick-error 1.2.1 (registry+https://github.com/rust-lang/crates.io-index)" = "eda5fe9b71976e62bc81b781206aaa076401769b2143379d3eb2118388babac4"
 "checksum quote 0.3.15 (registry+https://github.com/rust-lang/crates.io-index)" = "7a6e920b65c65f10b2ae65c831a81a073a89edd28c7cce89475bff467ab4167a"
 "checksum quote 0.5.2 (registry+https://github.com/rust-lang/crates.io-index)" = "9949cfe66888ffe1d53e6ec9d9f3b70714083854be20fd5e271b232a017401e8"
 "checksum rand 0.3.22 (registry+https://github.com/rust-lang/crates.io-index)" = "15a732abf9d20f0ad8eeb6f909bf6868722d9a06e1e50802b6a70351f40b4eb1"
@@ -1586,6 +1628,7 @@ dependencies = [
 "checksum redox_termios 0.1.1 (registry+https://github.com/rust-lang/crates.io-index)" = "7e891cfe48e9100a70a3b6eb652fef28920c117d366339687bd5576160db0f76"
 "checksum regex 0.1.80 (registry+https://github.com/rust-lang/crates.io-index)" = "4fd4ace6a8cf7860714a2c2280d6c1f7e6a413486c13298bbc86fd3da019402f"
 "checksum regex-syntax 0.3.9 (registry+https://github.com/rust-lang/crates.io-index)" = "f9ec002c35e86791825ed294b50008eea9ddfc8def4420124fbc6b08db834957"
+"checksum regex-syntax 0.4.2 (registry+https://github.com/rust-lang/crates.io-index)" = "8e931c58b93d86f080c734bfd2bce7dd0079ae2331235818133c8be7f422e20e"
 "checksum remove_dir_all 0.5.1 (registry+https://github.com/rust-lang/crates.io-index)" = "3488ba1b9a2084d38645c4c08276a1752dcbf2c7130d74f1569681ad5d2799c5"
 "checksum rouille 2.1.0 (registry+https://github.com/rust-lang/crates.io-index)" = "cc1f8407af80b0630983b2c1f1860dda1960fdec8d3ee75ba8db14937756d3a0"
 "checksum rustc-demangle 0.1.7 (registry+https://github.com/rust-lang/crates.io-index)" = "11fb43a206a04116ffd7cfcf9bcb941f8eb6cc7ff667272246b0a1c74259a3cb"
diff --git a/sit-core/Cargo.toml b/sit-core/Cargo.toml
index ec6046d..eb7afdb 100644
--- a/sit-core/Cargo.toml
+++ b/sit-core/Cargo.toml
@@ -28,6 +28,7 @@ git2 = { version = "0.7", optional = true, default-features = false }
 [dev-dependencies]
 dunce = "0.1"
 assert_matches = "1.1"
+proptest = "0.7"
 
 [build-dependencies]
 cc = "1.0"
diff --git a/sit-core/src/item.rs b/sit-core/src/item.rs
index 2e0a0e3..d3d5adf 100644
--- a/sit-core/src/item.rs
+++ b/sit-core/src/item.rs
@@ -3,6 +3,7 @@
 use serde_json::{Map, Value};
 
 use super::Reducer;
+use record::{File, OrderedFiles};
 
 #[derive(Debug, Error)]
 pub enum ReductionError<Err: ::std::error::Error + ::std::fmt::Debug> {
@@ -29,9 +30,8 @@ pub trait Item: Sized {
     ///
     /// Will reference all dangling records as its parent, unless
     /// `link_parents` is set to `false`
-    fn new_record<S: AsRef<str>, R: ::std::io::Read,
-                  I: Iterator<Item=(S, R)>>(&self, iter: I, link_parents: bool)
-       -> Result<Self::Record, Self::Error>;
+    fn new_record<'f, F: File + 'f, I: Into<OrderedFiles<'f, F>>>(&self, files: I, link_parents: bool)
+       -> Result<Self::Record, Self::Error> where F::Read: 'f;
 }
 
 /// [`Issue`] trait extension that defines and implements default reduction algorithms
diff --git a/sit-core/src/lib.rs b/sit-core/src/lib.rs
index 4684df9..a29ce37 100644
--- a/sit-core/src/lib.rs
+++ b/sit-core/src/lib.rs
@@ -37,6 +37,7 @@ extern crate digest;
 
 // Crates necessary for testing
 #[cfg(test)] #[macro_use] extern crate assert_matches;
+#[cfg(test)] #[macro_use] extern crate proptest;
 
 
 pub mod hash;
diff --git a/sit-core/src/record.rs b/sit-core/src/record.rs
index 8132d06..6d0e12a 100644
--- a/sit-core/src/record.rs
+++ b/sit-core/src/record.rs
@@ -1,5 +1,235 @@
 //! Record is an immutable collection of files
 
+use std::io::{self, Read};
+use hash::Hasher;
+
+/// Record's file
+///
+/// This trait represent an abstraction of a file: something that has a name
+/// and binary content to read.
+pub trait File {
+    /// Associated `Read` type
+    type Read : Read;
+    /// Returns file's name
+    fn name(&self) -> &str;
+    /// Returns a mutable reference to `Self::Read`
+    fn read(&mut self) -> &mut Self::Read;
+    /// Consumes itself and returns `Self::Read`
+    fn into_read(self) -> Self::Read;
+}
+
+impl<S, R> File for (S, R) where S: AsRef<str>, R: Read {
+    type Read = R;
+
+    fn name(&self) -> &str {
+        self.0.as_ref()
+    }
+
+    fn read(&mut self) -> &mut Self::Read {
+        &mut self.1
+    }
+
+    fn into_read(self) -> Self::Read {
+        self.1
+    }
+
+}
+
+use std::marker::PhantomData;
+
+/// A collection of always ordered files
+///
+/// With limited ways to construct this structure, it's
+/// always ensured to have all its files sorted as required
+/// by SIT for deterministic hashing.
+pub struct OrderedFiles<'a, F: File>(Vec<F>, PhantomData<&'a ()>);
+
+impl<'a, F: File> OrderedFiles<'a, F>  where F: 'a, F::Read: 'a {
+    /// Returns a boxed version of itself
+    ///
+    /// It's useful to ensure type compatibility between branches,
+    /// in one of which an intersection of differently-typed `File`s
+    /// were ordered together.
+    ///
+    /// ```
+    /// extern crate sit_core;
+    ///
+    /// use std::io::Cursor;
+    /// use sit_core::record::{BoxedOrderedFiles, OrderedFiles};
+    ///
+    /// let files: OrderedFiles<_> = vec![("file", &b"hello"[..])].into();
+    /// let extra: OrderedFiles<_> =  vec![("file", Cursor::new(String::from("world")))].into();
+    ///
+    /// let some_condition = true;
+    ///
+    /// let all_files = if some_condition {
+    ///    files + extra
+    /// } else {
+    ///    files.boxed()
+    /// };
+    ///
+    /// ```
+    pub fn boxed(self) -> BoxedOrderedFiles<'a> {
+        #[inline]
+        fn boxed_file<'f, F: File + 'f>(file: F) -> (String, Box<Read + 'f>) where F::Read: 'f {
+            (file.name().into(), Box::new(file.into_read()) as Box<Read + 'f>)
+        }
+        let files: Vec<_> = self.0.into_iter().map(boxed_file).collect();
+        files.into()
+    }
+}
+
+impl<'a, F: File> OrderedFiles<'a, F> {
+    /// Deterministically hashes all ordered files and allows to process them as well
+    ///
+    /// For every file, it will call `per_file(file_name)` and use the returned positive value
+    /// (from inside of `Ok(f_)`) to call `per_chunk(f_, chunk)` on every chunk of read data.
+    ///
+    /// This method's primary motivation is to allow hashing and saving files at the same time,
+    /// to avoid re-reading them to accomplish both of the operations. By itself, however,
+    /// this function doesn't do anything in term of saving files (or any other functionality),
+    /// that is responsibility of `per_file` and `per_chunk` callbacks.
+    pub fn hash_and<PF, F_, PC>(mut self, hasher: &mut Hasher, per_file: PF, per_chunk: PC) -> Result<(), io::Error>
+        where PF: Fn(&str) -> Result<F_, io::Error>, PC: Fn(F_, &[u8]) -> Result<F_, io::Error> {
+        let mut buf = vec![0; 4096];
+        for file in self.0.iter_mut() {
+            #[cfg(windows)] // replace backslashes with slashes
+            let name_for_hashing: String = file.name().replace("\\", "/").into();
+            #[cfg(unix)]
+            let name_for_hashing: String = file.name().into();
+            hasher.process(name_for_hashing.as_bytes());
+            let mut reader = file.read();
+            let mut file_processor = per_file(&name_for_hashing)?;
+            loop {
+                let bytes_read = reader.read(&mut buf)?;
+                hasher.process(&buf);
+                file_processor = per_chunk(file_processor, &buf[0..bytes_read])?;
+                if bytes_read == 0 {
+                    break;
+                }
+            }
+        }
+        Ok(())
+    }
+    /// Deterministically hashes all ordered files
+    pub fn hash(self, hasher: &mut Hasher) -> Result<(), io::Error> {
+        self.hash_and(hasher, |_| Ok(()), |v, _| Ok(v))
+    }
+}
+
+impl<'a, I, F> From<I> for OrderedFiles<'a, F> where I: IntoIterator<Item=F>, F: File + 'a {
+    fn from(i: I) -> Self {
+        let mut files: Vec<_> = i.into_iter().collect();
+        files.sort_unstable_by(|f1, f2| f1.name().cmp(f2.name()));
+        OrderedFiles(files, PhantomData)
+    }
+}
+
+pub type BoxedOrderedFiles<'a> = OrderedFiles<'a, (String, Box<Read + 'a>)>;
+
+use std::ops::{Add, Sub};
+
+impl<'a, F1, F2> Add<OrderedFiles<'a, F2>> for OrderedFiles<'a, F1> where F1: File + 'a, F2: File + 'a, F1::Read: 'a, F2::Read: 'a {
+    type Output = BoxedOrderedFiles<'a>;
+
+    fn add(self, rhs: OrderedFiles<'a, F2>) -> Self::Output {
+        let mut files = self.boxed().0;
+        let mut rhs_files = rhs.boxed().0;
+        files.append(&mut rhs_files);
+        files.into()
+    }
+}
+
+impl<'a, F1, F2, I> Add<I> for OrderedFiles<'a, F1> where F1: File + 'a, F2: File + 'a, F1::Read: 'a, F2::Read: 'a, I: IntoIterator<Item = OrderedFiles<'a, F2>> {
+    type Output = BoxedOrderedFiles<'a>;
+
+    fn add(self, rhs: I) -> Self::Output {
+        let mut files = self.boxed().0;
+        for rhs in rhs.into_iter() {
+            let mut rhs_files = rhs.boxed().0;
+            files.append(&mut rhs_files);
+        }
+        files.into()
+    }
+}
+
+impl<'a, F, S> Sub<S> for OrderedFiles<'a, F> where F: File + 'a, S: AsRef<str> + 'a {
+    type Output = Self;
+    fn sub(self, rhs: S) -> Self::Output {
+        let name = rhs.as_ref();
+        let files: Vec<_> = self.0.into_iter().filter(|f| f.name() != name).collect();
+        files.into()
+    }
+}
+
+#[cfg(test)]
+mod ordered_files_tests {
+    use proptest::collection::*;
+    use super::*;
+
+    proptest! {
+      #[test]
+      fn sorted(ref i in vec("\\PC*", 0..10)) {
+        let ordered_files = OrderedFiles::from(i.clone().into_iter().map(|v| (v, &[][..])));
+        for i in 1..ordered_files.0.len() {
+           assert!(ordered_files.0[i].name() >= ordered_files.0[i-1].name());
+        }
+      }
+
+      #[test]
+      fn add_sorted(ref i1 in vec("\\PC*", 0..10), ref i2 in vec("\\PC*", 0..10)) {
+        let ordered_files1 = OrderedFiles::from(i1.clone().into_iter().map(|v| (v, &[][..])));
+        let ordered_files2 = OrderedFiles::from(i2.clone().into_iter().map(|v| (v, &[][..])));
+        let ordered_files = ordered_files1 + ordered_files2;
+        for i in 1..ordered_files.0.len() {
+           assert!(ordered_files.0[i].name() >= ordered_files.0[i-1].name());
+        }
+      }
+
+      #[test]
+      fn add_includes(ref i1 in vec("\\PC*", 0..10), ref i2 in vec("\\PC*", 0..10)) {
+        let ordered_files1 = OrderedFiles::from(i1.clone().into_iter().map(|v| (v, &[][..])));
+        let ordered_files1_ = OrderedFiles::from(i1.clone().into_iter().map(|v| (v, &[][..])));
+        let ordered_files2 = OrderedFiles::from(i2.clone().into_iter().map(|v| (v, &[][..])));
+        let ordered_files2_ = OrderedFiles::from(i2.clone().into_iter().map(|v| (v, &[][..])));
+        let ordered_files = ordered_files1 + ordered_files2;
+        for i in ordered_files1_.0 {
+           assert!(ordered_files.0.iter().find(|f| f.name() == i.name()).is_some());
+        }
+        for i in ordered_files2_.0 {
+           assert!(ordered_files.0.iter().find(|f| f.name() == i.name()).is_some());
+        }
+      }
+
+      #[test]
+      fn add_includes_iter(ref i1 in vec("\\PC*", 0..10), ref i2 in vec("\\PC*", 0..10)) {
+        let ordered_files1 = OrderedFiles::from(i1.clone().into_iter().map(|v| (v, &[][..])));
+        let ordered_files1_ = OrderedFiles::from(i1.clone().into_iter().map(|v| (v, &[][..])));
+        let ordered_files2 = OrderedFiles::from(i2.clone().into_iter().map(|v| (v, &[][..])));
+        let ordered_files2_ = OrderedFiles::from(i2.clone().into_iter().map(|v| (v, &[][..])));
+        let ordered_files = ordered_files1 + ::std::iter::once(ordered_files2);
+        for i in ordered_files1_.0 {
+           assert!(ordered_files.0.iter().find(|f| f.name() == i.name()).is_some());
+        }
+        for i in ordered_files2_.0 {
+           assert!(ordered_files.0.iter().find(|f| f.name() == i.name()).is_some());
+        }
+      }
+
+     #[test]
+     fn sub_excludes(ref names in vec("\\PC*", 0..10), i in 0..9) {
+        prop_assume!(i as usize + 1 <= names.len());
+        let ordered_files1 = OrderedFiles::from(names.clone().into_iter().map(|v| (v, &[][..])));
+        let name = &names[i as usize];
+        let ordered_files = ordered_files1 - name;
+        assert!(ordered_files.0.iter().find(|f| f.name() == name).is_none());
+      }
+
+    }
+}
+
+
+
 /// Record is an immutable collection of files
 pub trait Record {
    /// Implementation's type for reading files
diff --git a/sit-core/src/repository.rs b/sit-core/src/repository.rs
index 42c030f..e875f83 100644
--- a/sit-core/src/repository.rs
+++ b/sit-core/src/repository.rs
@@ -8,7 +8,7 @@
 
 use std::path::{Path, PathBuf};
 use std::fs;
-use std::io::{Read, Write};
+use std::io::Write;
 
 use tempdir::TempDir;
 
@@ -16,7 +16,7 @@ use glob;
 
 use serde_json;
 
-use super::hash::{HashingAlgorithm, Hasher};
+use super::hash::HashingAlgorithm;
 use super::encoding::Encoding;
 use super::id::IdGenerator;
 
@@ -72,6 +72,17 @@ pub struct Config {
     extra: HashMap<String, serde_json::Value>,
 }
 
+impl Config {
+    /// Returns hashing algorithm
+    pub fn hashing_algorithm(&self) -> &HashingAlgorithm {
+        &self.hashing_algorithm
+    }
+    /// Returns encoding
+    pub fn encoding(&self) -> &Encoding {
+        &self.encoding
+    }
+}
+
 #[derive(PartialEq, Debug)]
 pub enum Upgrade {
     IssuesToItems,
@@ -381,72 +392,43 @@ pub struct Item<'a> {
     id: OsString,
 }
 
+use record::{File, OrderedFiles};
 
-fn process_file<S: AsRef<str>, R: ::std::io::Read>(hasher: &mut Hasher, name: S, mut reader: R, mut buf: &mut Vec<u8>, tempdir: &TempDir) -> Result<(), ::std::io::Error> {
-    #[cfg(windows)] // replace backslashes with slashes
-    let name_for_hashing = name.as_ref().replace("\\", "/");
-    #[cfg(unix)]
-    let name_for_hashing = name.as_ref();
-    hasher.process((name_for_hashing.as_ref() as &str).as_bytes());
-    let path = tempdir.path().join(PathBuf::from(name.as_ref() as &str));
-    let mut dir = path.clone();
-    dir.pop();
-    fs::create_dir_all(dir)?;
-    let mut file = fs::File::create(path)?;
-    loop {
-        let bytes_read = reader.read(&mut buf)?;
-        hasher.process(&buf);
-        file.write(&buf[0..bytes_read])?;
-        if bytes_read == 0 {
-            break;
-        }
-    }
-    Ok(())
-}
 impl<'a> Item<'a> {
-    pub fn new_record_in<P: AsRef<Path>, S: AsRef<str>, R: ::std::io::Read,
-        I: Iterator<Item=(S, R)>>(&self, path: P, iter: I, link_parents: bool) -> Result<<Item<'a> as ItemTrait>::Record, <Item<'a> as ItemTrait>::Error> {
+    pub fn new_record_in<'f, P: AsRef<Path>, F: File + 'f, I: Into<OrderedFiles<'f, F>>>(&self, path: P, files: I, link_parents: bool) ->
+           Result<<Item<'a> as ItemTrait>::Record, <Item<'a> as ItemTrait>::Error> where F::Read: 'f {
         let tempdir = TempDir::new_in(&self.repository.path,"sit")?;
         let mut hasher = self.repository.config.hashing_algorithm.hasher();
-        let mut buf = vec![0; 4096];
 
-        let mut files: Vec<(Box<AsRef<str>>, Box<Read>)> = vec![];
-        // iterate over all files
-        for (name, mut reader) in iter {
-            files.push((Box::new(name) as Box<AsRef<str>>, Box::new(reader) as Box<Read>));
-        }
+        let files: OrderedFiles<F> = files.into();
 
         // Link parents if requested
-        if link_parents {
-            match self.record_iter()?.last() {
-                None => (),
-                Some(records) => {
-                    let parents = records.iter().map(|rec| (format!(".prev/{}", rec.encoded_hash()), &b""[..]));
-
-                    for (name, mut reader) in parents {
-                        files.push((Box::new(name) as Box<AsRef<str>>, Box::new(reader) as Box<Read>));
-                    }
-                },
-            }
-        }
-
-        // IMPORTANT: Sort lexicographically
-        files.sort_by(|&(ref name1, _), &(ref name2, _)|
-            name1.as_ref().as_ref().cmp(name2.as_ref().as_ref()));
+        let files = if link_parents {
+            let records = self.record_iter()?.last().unwrap_or(vec![]);
+            let parents: OrderedFiles<_> = records.iter().map(|rec| (format!(".prev/{}", rec.encoded_hash()), &b""[..])).into();
+            files + parents
+        } else {
+            files.boxed()
+        };
 
+        files.hash_and(&mut *hasher, |n| {
+            let path = tempdir.path().join(PathBuf::from(n));
+            let mut dir = path.clone();
+            dir.pop();
+            fs::create_dir_all(dir)?;
+            let file = fs::File::create(path)?;
+            Ok(file)
+        }, |mut f, c| f.write(c).map(|_| f))?;
 
-        for (name, mut reader) in files {
-            process_file(&mut *hasher, name.as_ref(), reader, &mut buf, &tempdir)?;
-        }
 
         let hash = hasher.result_box();
-        let actual_path = path.as_ref().join(PathBuf::from(self.repository.config.encoding.encode(&hash)));
-        fs::rename(tempdir.into_path(), &actual_path)?;
+        let path = path.as_ref().join(PathBuf::from(self.repository.config.encoding.encode(&hash)));
+        fs::rename(tempdir.into_path(), &path)?;
         Ok(Record {
             hash,
             item: self.id.clone(),
             repository: self.repository,
-            actual_path,
+            path,
         })
     }
 
@@ -475,9 +457,8 @@ impl<'a> ItemTrait for Item<'a> {
         })
     }
 
-    fn new_record<S: AsRef<str>, R: ::std::io::Read,
-        I: Iterator<Item=(S, R)>>(&self, iter: I, link_parents: bool) -> Result<Self::Record, Self::Error> {
-       self.new_record_in(self.repository.items_path.join(PathBuf::from(self.id())), iter, link_parents)
+    fn new_record<'f, F: File + 'f, I: Into<OrderedFiles<'f, F>>>(&self, files: I, link_parents: bool) -> Result<Self::Record, Self::Error> where F::Read: 'f {
+       self.new_record_in(self.repository.items_path.join(PathBuf::from(self.id())), files, link_parents)
     }
 
 }
@@ -525,7 +506,7 @@ impl<'a> Iterator for ItemRecordIter<'a> {
                 hash: self.repository.config.encoding.decode(e.file_name().to_str().unwrap().as_bytes()).unwrap(),
                 item: self.item.clone(),
                 repository: self.repository,
-                actual_path: item_path.join(e.file_name()),
+                path: item_path.join(e.file_name()),
             })
             .collect();
         self.dir = dir;
@@ -581,136 +562,19 @@ pub struct Record<'a> {
     hash: Vec<u8>,
     item: OsString,
     repository: &'a Repository,
-    actual_path: PathBuf,
-}
-
-/// Somethiing that can provide access to its underlying repository
-pub trait RepositoryProvider {
-    /// Returns underlying repository;
-    fn repository(&self) -> &Repository;
-}
-
-impl<'a> RepositoryProvider for Record<'a> {
-    fn repository(&self) -> &Repository {
-        self.repository
-    }
-}
-
-#[derive(Debug)]
-/// Record wrapper that dynamically rehashes wrapped Record's content
-pub struct DynamicallyHashedRecord<'a, T: RecordTrait + RepositoryProvider + 'a>(&'a T);
-
-impl<'a, T: RecordTrait<Str=String, Hash=Vec<u8>> + RepositoryProvider + 'a> RecordTrait for DynamicallyHashedRecord<'a, T> {
-    type Read = T::Read;
-    type Str = String;
-    type Hash = Vec<u8>;
-    type Iter = T::Iter;
-
-    fn hash(&self) -> Self::Hash {
-        let tempdir = TempDir::new_in(&self.0.repository().path(),"sit").unwrap();
-        let mut hasher = self.0.repository().config.hashing_algorithm.hasher();
-        let mut buf = vec![0; 4096];
-
-        let mut files: Vec<(Box<AsRef<str>>, Box<Read>)> = vec![];
-
-        for (name, reader) in self.file_iter() {
-            files.push((Box::new(name) as Box<AsRef<str>>, Box::new(reader) as Box<Read>));
-        }
-
-        // IMPORTANT: Sort lexicographically
-        files.sort_by(|&(ref name1, _), &(ref name2, _)|
-            name1.as_ref().as_ref().cmp(name2.as_ref().as_ref()));
-
-        for (name, mut reader) in files {
-            process_file(&mut *hasher, name.as_ref(), reader, &mut buf, &tempdir).unwrap();
-        }
-
-        hasher.result_box()
-    }
-
-    fn encoded_hash(&self) -> Self::Str {
-        self.0.repository().config.encoding.encode(self.hash().as_ref())
-    }
-
-    fn file_iter(&self) -> Self::Iter {
-        self.0.file_iter()
-    }
-
-    fn item_id(&self) -> Self::Str {
-        self.0.item_id()
-    }
-}
-
-#[derive(Debug)]
-/// Record with filtered content
-pub struct FilteredRecord<'a, S: AsRef<str>, R: Read, T: RecordTrait<Str=S, Read=R> + RepositoryProvider + 'a,
-           F: Fn(&(S, R)) -> bool>(&'a T, F);
-
-impl<'a, S: AsRef<str>, R: Read, T: RecordTrait<Str=S, Read=R> + RepositoryProvider + 'a, F: Copy + Fn(&(S, R)) -> bool> RecordTrait for FilteredRecord<'a, S, R, T, F> {
-    type Read = T::Read;
-    type Hash = T::Hash;
-    type Str = T::Str;
-    type Iter = ::std::iter::Filter<T::Iter, F>;
-
-    fn hash(&self) -> Self::Hash {
-        self.0.hash()
-    }
-
-    fn encoded_hash(&self) -> Self::Str {
-        self.0.encoded_hash()
-    }
-
-    fn file_iter(&self) -> Self::Iter {
-        self.0.file_iter().filter(self.1)
-    }
-
-    fn item_id(&self) -> Self::Str {
-        self.0.item_id()
-    }
-}
-
-impl <'a, S: AsRef<str>, R: Read, T: RecordTrait<Str=S, Read=R> + RepositoryProvider + 'a, F: Copy + Fn(&(S, R)) -> bool> RepositoryProvider for FilteredRecord<'a, S, R, T, F> {
-    fn repository(&self) -> &Repository {
-        self.0.repository()
-    }
-}
-
-/// Allows any Record to have its content dynamically rehashed
-pub trait DynamicallyHashable<'a> : RecordTrait + RepositoryProvider + Sized {
-    /// Returns a record that has its hash dynamically computed
-    fn dynamically_hashed(&'a self) -> DynamicallyHashedRecord<'a, Self> {
-        DynamicallyHashedRecord(self)
-    }
+    path: PathBuf,
 }
 
-impl<'a> DynamicallyHashable<'a> for Record<'a> {}
-impl<'a, S: AsRef<str>, R: Read, T: RecordTrait<Str=S, Read=R> + RepositoryProvider + 'a, F: Copy + Fn(&(S, R)) -> bool> DynamicallyHashable<'a> for FilteredRecord<'a, S, R, T, F> {}
-
 impl<'a> Record<'a> {
 
-    /// Returns path to the record, as it should be per repository's naming scheme
-    ///
-    /// The record MIGHT not be at this path as this is the path where
-    /// it SHOULD BE. The actual path can be retrieved using `actual_path()`
-    pub fn path(&self) -> PathBuf {
-        self.repository.items_path.join(PathBuf::from(&self.item)).join(self.encoded_hash())
-    }
-
-    /// Returns an actual path to the record directory
-    pub fn actual_path(&self) -> &Path {
-        self.actual_path.as_path()
-    }
-
-
-    /// Returns a record with filtered files
-    pub fn filtered<F>(&'a self, filter: F) -> FilteredRecord<'a, <Record<'a> as RecordTrait>::Str,
-        <Record<'a> as RecordTrait>::Read,
-        Record<'a>, F> where F: Fn(&(<Record<'a> as RecordTrait>::Str, <Record<'a> as RecordTrait>::Read)) -> bool {
-        FilteredRecord(self, filter)
+    /// Returns path to the record
+    pub fn path(&self) -> &Path {
+        self.path.as_path()
     }
 
 }
 
+
 use serde::{Serialize, Serializer};
 
 impl<'a> Serialize for Record<'a> {
@@ -742,11 +606,11 @@ impl<'a> RecordTrait for Record<'a> {
     }
 
     fn file_iter(&self) -> Self::Iter {
-        let path = self.actual_path();
+        let path = self.path();
         let glob_pattern = format!("{}/**/*", path.to_str().unwrap());
         RecordFileIterator {
             glob: glob::glob(&glob_pattern).expect("invalid glob pattern"),
-            prefix: self.actual_path().into(),
+            prefix: self.path().into(),
             phantom: PhantomData,
         }
     }
@@ -1095,49 +959,6 @@ mod tests {
         }
     }
 
-    #[test]
-    fn record_dynamic_hashing() {
-        let mut tmp = TempDir::new("sit").unwrap().into_path();
-        tmp.push(".sit");
-        let repo = Repository::new(&tmp).unwrap();
-        let item = repo.new_item().unwrap();
-        let record = item.new_record(vec![("z/a", &[2u8][..]), ("test", &[1u8][..])].into_iter(), false).unwrap();
-        let record_dynamic = record.dynamically_hashed();
-        assert_eq!(record_dynamic.hash(), record.hash());
-        assert_eq!(record_dynamic.encoded_hash(), record.encoded_hash());
-        // now, put some file in the dynamic one
-        let hash = record.hash();
-        let encoded_hash = record.encoded_hash();
-        ::std::fs::File::create(record.path().join("dynamic")).unwrap();
-        assert_eq!(record.hash(), hash);
-        assert_eq!(record.encoded_hash(), encoded_hash);
-        assert_ne!(record_dynamic.hash(), record.hash());
-        assert_ne!(record_dynamic.encoded_hash(), record.encoded_hash());
-    }
-
-    #[test]
-    fn record_filtering() {
-         let mut tmp = TempDir::new("sit").unwrap().into_path();
-        tmp.push(".sit");
-        let repo = Repository::new(&tmp).unwrap();
-        let item = repo.new_item().unwrap();
-        let record = item.new_record(vec![("z/a", &[2u8][..]), ("test", &[1u8][..])].into_iter(), false).unwrap();
-        fn not_za(val: &(String, fs::File)) -> bool {
-            val.0 != "z/a"
-        }
-        let filtered = record.filtered(not_za);
-        // Check the content
-        assert_eq!(filtered.file_iter().count(), 1);
-        let files: Vec<_> = filtered.file_iter().map(|(name, _)| name).collect();
-        assert_eq!(files, vec!["test"]);
-        // Filtering alone doesn't change hash
-        assert_eq!(filtered.hash(), record.hash());
-        assert_eq!(filtered.encoded_hash(), record.encoded_hash());
-        // But doing it dynamically does
-        assert_ne!(filtered.dynamically_hashed().hash(), record.hash());
-        assert_ne!(filtered.dynamically_hashed().encoded_hash(), record.encoded_hash());
-    }
-
     #[test]
     fn record_outside_naming_scheme() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
@@ -1167,7 +988,7 @@ mod tests {
         #[cfg(windows)]
         drop(files);
 
-        ::std::fs::rename(record2.actual_path(), record2.path()).unwrap();
+        ::std::fs::rename(record2.path(), repo.items_path().join(item.id()).join(record2.encoded_hash())).unwrap();
 
         // and now it can be
         let records: Vec<Vec<_>> = item.record_iter().unwrap().collect();
diff --git a/sit-web/src/webapp.rs b/sit-web/src/webapp.rs
index 866844a..d8af47c 100644
--- a/sit-web/src/webapp.rs
+++ b/sit-web/src/webapp.rs
@@ -64,7 +64,8 @@ use std::path::PathBuf;
 use std::fs;
 use std::net::ToSocketAddrs;
 
-use sit_core::Repository;
+use sit_core::{Repository, record::OrderedFiles};
+use std::io::Cursor;
 
 use mime_guess::get_mime_type_str;
 
@@ -72,8 +73,6 @@ use std::ffi::OsString;
 
 use rayon::prelude::*;
 
-use tempdir;
-
 use blake2::Blake2b;
 use digest::{Input, VariableOutput};
 use hex;
@@ -225,9 +224,9 @@ pub fn start<A: ToSocketAddrs>(addr: A, config: sit_core::cfg::Configuration, re
            };
 
            let mut multipart = get_multipart_input(&request).expect("multipart request");
-           let mut files = vec![];
            let mut link = true;
            let mut used_files = vec![];
+
            loop {
               let mut part = multipart.next();
               if part.is_none() {
@@ -243,8 +242,7 @@ pub fn start<A: ToSocketAddrs>(addr: A, config: sit_core::cfg::Configuration, re
                  if field.name.starts_with(".prev/") {
                     link = false;
                  }
-                 files.push((field.name.clone(), fs::File::open(&path).expect("can't open saved file")));
-                 used_files.push(path);
+                 used_files.push((field.name.clone(), path));
                  match field.next_entry_inplace() {
                      Ok(Some(_)) => continue,
                      Ok(None) => break,
@@ -253,16 +251,10 @@ pub fn start<A: ToSocketAddrs>(addr: A, config: sit_core::cfg::Configuration, re
               }
            }
 
-           let tmp = tempdir::TempDir::new_in(repo.path(), "sit").unwrap();
-           let record_path = tmp.path();
+           let files: OrderedFiles<_> = used_files.iter().map(|(n, p)| (n.clone(), fs::File::open(p).expect("can't open saved file"))).into();
+           let files_: OrderedFiles<_> = used_files.iter().map(|(n, p)| (n.clone(), fs::File::open(p).expect("can't open saved file"))).into();
 
-           let record = item.new_record_in(record_path, files.into_iter(), link).expect("can't create record");
-
-           for file in used_files {
-             fs::remove_file(file).expect("can't remove file");
-           }
-
-           if config.signing.enabled {
+           let files: OrderedFiles<_> = if config.signing.enabled {
               use std::ffi::OsString;
               use std::io::Write;
               let program = super::gnupg(&config).unwrap();
@@ -290,30 +282,31 @@ pub fn start<A: ToSocketAddrs>(addr: A, config: sit_core::cfg::Configuration, re
 
               {
                   let mut stdin = child.stdin.as_mut().expect("Failed to open stdin");
-                  stdin.write_all(record.encoded_hash().as_bytes()).expect("Failed to write to stdin");
+                  let mut hasher = repo.config().hashing_algorithm().hasher();
+                  files_.hash(&mut *hasher).expect("failed hashing files");
+                  let hash = hasher.result_box();
+                  let encoded_hash = repo.config().encoding().encode(&hash);
+                  stdin.write_all(encoded_hash.as_bytes()).expect("Failed to write to stdin");
               }
 
               let output = child.wait_with_output().expect("failed to read stdout");
 
               if !output.status.success() {
                   eprintln!("Error: {}", String::from_utf8_lossy(&output.stderr));
+                  return Response::text(String::from_utf8_lossy(&output.stderr)).with_status_code(500);
               } else {
-                  use sit_core::repository::DynamicallyHashable;
-                  let dynamically_hashed_record = record.dynamically_hashed();
-                  let mut file = fs::File::create(record.actual_path().join(".signature"))
-                               .expect("can't open signature file");
-                 file.write(&output.stdout).expect("can't write signature file");
-                 drop(file);
-                 let new_hash = dynamically_hashed_record.encoded_hash();
-                 let mut new_path = record.path();
-                 new_path.pop();
-                 new_path.push(&new_hash);
-                 fs::rename(record.actual_path(), new_path).expect("can't rename record");
-                 return Response::json(&new_hash);
+                 let sig: OrderedFiles<_> = vec![(String::from(".signature"), Cursor::new(output.stdout))].into();
+                 files + sig
              }
 
           } else {
-                 fs::rename(record.actual_path(), record.path()).expect("can't rename record");
+              files.boxed()
+          };
+
+          let record = item.new_record(files, link).expect("can't create record");
+
+          for (_, file) in used_files {
+            fs::remove_file(file).expect("can't remove file");
           }
 
           Response::json(&record.encoded_hash())
diff --git a/sit/src/command_record.rs b/sit/src/command_record.rs
index 04a392a..0a2cfdb 100644
--- a/sit/src/command_record.rs
+++ b/sit/src/command_record.rs
@@ -1,14 +1,13 @@
 use clap::{self, ArgMatches};
-use sit_core::{Repository, Record};
+use sit_core::{Repository, Record, Item, record::{OrderedFiles, BoxedOrderedFiles}};
 use sit_core::cfg::{self, Configuration};
 use chrono::prelude::*;
 use std::process::exit;
+use std::io::{self, Cursor, Write};
 use std::fs;
 use std::path::{Path, PathBuf};
 use std::env;
-use tempfile;
 use atty;
-use tempdir;
 use serde_json;
 
 pub fn command<P: AsRef<Path>, P1: AsRef<Path>>(matches: &ArgMatches, repo: &Repository, mut config: Configuration, working_directory: P, config_path: P1) -> i32 {
@@ -60,65 +59,62 @@ pub fn command<P: AsRef<Path>, P1: AsRef<Path>>(matches: &ArgMatches, repo: &Rep
             return 1;
         },
         Some(item) => {
-            let files = matches.values_of("FILES").unwrap_or(clap::Values::default());
-            let types: Vec<_> = match matches.value_of("type") {
-                Some(types) => types.split(",").collect(),
-                None => vec![],
-            };
-
-            let files = files.into_iter()
-                .map(move |name| {
-                    let path = PathBuf::from(&name);
-                    if !path.is_file() {
-                        eprintln!("{} does not exist or is not a regular file", path.to_str().unwrap());
-                        exit(1);
-                    }
-                    let abs_name = ::dunce::canonicalize(path).expect("can't canonicalize path");
-                    let cur_dir = ::dunce::canonicalize(env::current_dir().expect("can't get current directory")).expect("can't canonicalize current directory");
-                    match abs_name.strip_prefix(&cur_dir) {
-                        Err(_) => {
-                            eprintln!("Path {} is not relative to {} current directory", name, cur_dir.to_str().unwrap());
+            fn record_files(matches: &ArgMatches, utc: DateTime<Utc>, config: &Configuration) -> Result<BoxedOrderedFiles<'static>, io::Error> {
+                let files = matches.values_of("FILES").unwrap_or(clap::Values::default());
+                let files: OrderedFiles<_> = files.into_iter()
+                    .map(move |name| {
+                        let path = PathBuf::from(&name);
+                        if !path.is_file() {
+                            eprintln!("{} does not exist or is not a regular file", path.to_str().unwrap());
                             exit(1);
-                        },
-                        Ok(path) => String::from(path.to_str().unwrap()),
-                    }
-                })
-                .map(|name| (name.clone(), ::std::fs::File::open(name).expect("can't open file")));
-
-            let type_files = types.iter().map(|t|
-                (format!(".type/{}", *t),
-                 tempfile::tempfile_in(repo.path())
-                     .expect(&format!("can't create a temporary file (.type/{})", t))));
-
-            use std::io::{Write, Seek, SeekFrom};
-
-            // .authors
-            let authorship_files = if !matches.is_present("no-author") {
-                let mut authors = tempfile::tempfile_in(repo.path()).expect("can't create a temporary file (.authors)");
-                authors.write(format!("{}", config.author.clone().unwrap()).as_bytes()).expect("can't write to a tempoary file (.authors)");
-                authors.seek(SeekFrom::Start(0)).expect("can't seek to the beginning of a temporary file (.authors)");
-                vec![(".authors".into(), authors)].into_iter()
-            } else {
-                vec![].into_iter()
-            };
+                        }
+                        let abs_name = ::dunce::canonicalize(path).expect("can't canonicalize path");
+                        let cur_dir = ::dunce::canonicalize(env::current_dir().expect("can't get current directory")).expect("can't canonicalize current directory");
+                        match abs_name.strip_prefix(&cur_dir) {
+                            Err(_) => {
+                                eprintln!("Path {} is not relative to {} current directory", name, cur_dir.to_str().unwrap());
+                                exit(1);
+                            },
+                            Ok(path) => String::from(path.to_str().unwrap()),
+                        }
+                    })
+                    .map(|name| (name.clone(), ::std::fs::File::open(name).expect("can't open file"))).into();
 
-            let tmp = tempdir::TempDir::new_in(repo.path(), "sit").unwrap();
-            let record_path = tmp.path();
+                let types: Vec<_> = match matches.value_of("type") {
+                    Some(types) => types.split(",").collect(),
+                    None => vec![],
+                };
 
-            let record = if !matches.is_present("no-timestamp") {
-                let mut f = tempfile::tempfile_in(repo.path()).expect("can't create a temporary file (.timestamp)");
-                let utc: DateTime<Utc> = Utc::now();
-                f.write(format!("{:?}", utc).as_bytes()).expect("can't write to a temporary file (.timestamp)");
-                f.seek(SeekFrom::Start(0)).expect("can't seek to the beginning of a temporary file (.timestamp)");
-                item.new_record_in(record_path, files.chain(type_files).chain(authorship_files).chain(vec![(String::from(".timestamp"), f)].into_iter()), true)
-            } else {
-                item.new_record_in(record_path, files.chain(type_files).chain(authorship_files), true)
-            }.expect("can't create a record");
+                let type_files: OrderedFiles<_> = types.iter().map(|t|
+                    (format!(".type/{}", *t),&[][..])).into();
+
+                // .authors
+                let authorship_files: Option<OrderedFiles<(String, _)>> = if !matches.is_present("no-author") {
+                    let authors = format!("{}", config.author.clone().unwrap());
+                    Some(vec![(".authors".into(), Cursor::new(authors))].into())
+                } else {
+                    None
+                };
+
+                let timestamp: Option<OrderedFiles<(String, _)>>= if !matches.is_present("no-timestamp") {
+                    let timestamp = format!("{:?}", utc);
+                    Some(vec![(".timestamp".into(), Cursor::new(timestamp))].into())
+                } else {
+                    None
+                };
+
+                Ok(files + type_files + authorship_files + timestamp)
+
+            }
+
+            let utc: DateTime<Utc> = Utc::now();
 
 
             let signing = matches.is_present("sign") || config.signing.enabled;
 
-            if signing {
+            let files = record_files(matches, utc, &config).expect("failed collecting files");
+
+            let files = if signing {
                 use std::ffi::OsString;
                 let program = super::gnupg(matches, &config).expect("can't find GnuPG");
                 let key = match matches.value_of("signing-key").map(String::from).or_else(|| config.signing.key.clone()) {
@@ -144,7 +140,11 @@ pub fn command<P: AsRef<Path>, P1: AsRef<Path>>(matches: &ArgMatches, repo: &Rep
 
                 {
                     let mut stdin = child.stdin.as_mut().expect("Failed to open stdin");
-                    stdin.write_all(record.encoded_hash().as_bytes()).expect("Failed to write to stdin");
+                    let mut hasher = repo.config().hashing_algorithm().hasher();
+                    files.hash(&mut *hasher).expect("failed hashing files");
+                    let hash = hasher.result_box();
+                    let encoded_hash = repo.config().encoding().encode(&hash);
+                    stdin.write_all(encoded_hash.as_bytes()).expect("Failed to write to stdin");
                 }
 
                 let output = child.wait_with_output().expect("failed to read stdout");
@@ -153,24 +153,16 @@ pub fn command<P: AsRef<Path>, P1: AsRef<Path>>(matches: &ArgMatches, repo: &Rep
                     eprintln!("Error: {}", String::from_utf8_lossy(&output.stderr));
                     return 1;
                 } else {
-                    use sit_core::repository::DynamicallyHashable;
-                    let dynamically_hashed_record = record.dynamically_hashed();
-                    let mut file = fs::File::create(record.actual_path().join(".signature"))
-                        .expect("can't open signature file");
-                    file.write(&output.stdout).expect("can't write signature file");
-                    drop(file);
-                    let new_hash = dynamically_hashed_record.encoded_hash();
-                    let mut new_path = record.path();
-                    new_path.pop();
-                    new_path.push(&new_hash);
-                    fs::rename(record.actual_path(), new_path).expect("can't rename record");
-                    println!("{}", new_hash);
-                    return 0;
+                    let files = record_files(matches, utc, &config).expect("failed collecting files");
+                    let signature_file: OrderedFiles<(String, _)> = vec![(".signature".into(), Cursor::new(output.stdout))].into();
+                    files + signature_file
                 }
 
             } else {
-                fs::rename(record.actual_path(), record.path()).expect("can't rename record");
-            }
+                files
+            };
+
+            let record = item.new_record(files, true).expect("can't create a record");
 
             println!("{}", record.encoded_hash());
         }
diff --git a/sit/src/command_records.rs b/sit/src/command_records.rs
index 468d9d1..1e9d5e8 100644
--- a/sit/src/command_records.rs
+++ b/sit/src/command_records.rs
@@ -1,9 +1,8 @@
 use clap::ArgMatches;
-use sit_core::{Repository, Record, Item, cfg::Configuration};
+use sit_core::{Repository, Record, Item, cfg::Configuration, record::OrderedFiles};
 use serde_json;
 use super::get_named_expression;
 use jmespath;
-use std::fs;
 use super::gnupg;
 
 pub fn command(matches: &ArgMatches, repo: &Repository, config: Configuration) -> i32 {
@@ -43,7 +42,6 @@ pub fn command(matches: &ArgMatches, repo: &Repository, config: Configuration) -
                         let verify = matches.is_present("verify") && rec.path().join(".signature").is_file();
 
                         if verify {
-                            use std::io::Write;
                             let program = gnupg(matches, &config).expect("can't find GnuPG");
                             let mut command = ::std::process::Command::new(program);
 
@@ -58,14 +56,15 @@ pub fn command(matches: &ArgMatches, repo: &Repository, config: Configuration) -
                             let mut child = command.spawn().expect("failed spawning gnupg");
 
                             {
-                                use sit_core::repository::DynamicallyHashable;
-                                fn not_signature(val: &(String, fs::File)) -> bool {
-                                    &val.0 != ".signature"
-                                }
-                                let filtered_record = rec.filtered(not_signature);
-                                let filtered_dynamic = filtered_record.dynamically_hashed();
+                                let files: OrderedFiles<_> = rec.file_iter().into();
+                                let files = files - ".signature";
+                                let mut hasher = repo.config().hashing_algorithm().hasher();
+                                files.hash(&mut *hasher).expect("failed hashing files");
+                                let hash = hasher.result_box();
+                                let encoded_hash = repo.config().encoding().encode(&hash);
+                                use std::io::Write;
                                 let mut stdin = child.stdin.as_mut().expect("Failed to open stdin");
-                                stdin.write_all(filtered_dynamic.encoded_hash().as_bytes()).expect("Failed to write to stdin");
+                                stdin.write_all(encoded_hash.as_bytes()).expect("Failed to write to stdin");
                             }
 
                             let output = child.wait_with_output().expect("failed to read stdout");
-- 
2.16.2

