From 4082ed9674da259a79fc863e1b5d50ca05a1c5ac Mon Sep 17 00:00:00 2001
From: Yurii Rashkovskii <me@yrashk.com>
Date: Thu, 2 Aug 2018 10:08:51 +0700
Subject: [PATCH] Problem: the concept of "items"

It originally was a conversion of "issues" into something that
can be somewhat more generic. However, with further exploration of
different domains it became rather clear that it doesn't fit many of
them well and can only be artifically bolted on. That's not great.

Solution: transition into a flat records namespace

In order to avoid this problem, the idea is to move out all records to
.sit/records into a single flat namespace and make the transition
(almost) seamless by retaining items for a little while but converting
records in them into "text link" files to the real records.
---
 .travis.yml                      |   1 +
 Cargo.lock                       |   3 +
 Makefile                         |  10 +
 appveyor.yml                     |   2 +-
 doc/overview.png                 | Bin 18958 -> 14002 bytes
 doc/overview.uml                 |   9 +-
 sit-core/Cargo.toml              |   5 +-
 sit-core/src/hash.rs             |  10 +
 sit-core/src/item.rs             |  49 +-
 sit-core/src/lib.rs              |   6 +
 sit-core/src/record.rs           | 150 ++++++-
 sit-core/src/reducers/duktape.rs | 434 ++++++++++--------
 sit-core/src/repository.rs       | 935 +++++++++++++++++++++++++++++----------
 sit-web/Cargo.toml               |   2 +
 sit-web/src/webapp.rs            | 290 ++++++++----
 sit/Cargo.toml                   |   3 +
 sit/src/command_integrity.rs     |  61 ++-
 sit/src/command_items.rs         |   6 +-
 sit/src/command_record.rs        | 166 ++++---
 sit/src/command_records.rs       | 191 ++++----
 sit/src/command_reduce.rs        | 105 +++--
 sit/src/main.rs                  | 155 ++++---
 sit/src/rebuild.rs               |   7 +-
 sit/tests/command_integrity.rs   |  71 ++-
 sit/tests/command_item.rs        |   6 +
 sit/tests/command_items.rs       |  16 +-
 sit/tests/command_path.rs        |  20 +
 sit/tests/command_record.rs      | 153 +++----
 sit/tests/command_records.rs     | 106 +++--
 sit/tests/command_reduce.rs      | 165 +++++--
 30 files changed, 2136 insertions(+), 1001 deletions(-)

diff --git a/.travis.yml b/.travis.yml
index f1eb3b3..c1ea4ec 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -2,6 +2,7 @@ language: rust
 rust:
 - stable
 - nightly
+build_script: make test
 cache: cargo
 matrix:
   include:
diff --git a/Cargo.lock b/Cargo.lock
index 6b9f132..ca376c7 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -1163,6 +1163,7 @@ dependencies = [
  "fs_extra 1.1.0 (registry+https://github.com/rust-lang/crates.io-index)",
  "git2 0.7.1 (registry+https://github.com/rust-lang/crates.io-index)",
  "glob 0.2.11 (registry+https://github.com/rust-lang/crates.io-index)",
+ "itertools 0.7.8 (registry+https://github.com/rust-lang/crates.io-index)",
  "jmespath 0.2.0 (registry+https://github.com/rust-lang/crates.io-index)",
  "pbr 1.0.1 (registry+https://github.com/rust-lang/crates.io-index)",
  "question 0.2.1 (registry+https://github.com/rust-lang/crates.io-index)",
@@ -1195,6 +1196,7 @@ dependencies = [
  "git2 0.7.1 (registry+https://github.com/rust-lang/crates.io-index)",
  "glob 0.2.11 (registry+https://github.com/rust-lang/crates.io-index)",
  "include_dir 0.1.5 (registry+https://github.com/rust-lang/crates.io-index)",
+ "itertools 0.7.8 (registry+https://github.com/rust-lang/crates.io-index)",
  "lazy_static 1.0.0 (registry+https://github.com/rust-lang/crates.io-index)",
  "memmap 0.6.2 (registry+https://github.com/rust-lang/crates.io-index)",
  "proptest 0.7.0 (registry+https://github.com/rust-lang/crates.io-index)",
@@ -1206,6 +1208,7 @@ dependencies = [
  "tempdir 0.3.7 (registry+https://github.com/rust-lang/crates.io-index)",
  "typed-builder 0.1.0 (registry+https://github.com/rust-lang/crates.io-index)",
  "uuid 0.5.1 (registry+https://github.com/rust-lang/crates.io-index)",
+ "walkdir 2.1.4 (registry+https://github.com/rust-lang/crates.io-index)",
 ]
 
 [[package]]
diff --git a/Makefile b/Makefile
index 4fa43ef..6fc587b 100644
--- a/Makefile
+++ b/Makefile
@@ -1,3 +1,5 @@
+.PHONY: test
+
 osx: target/x86_64-apple-darwin/release/sit target/x86_64-apple-darwin/release/sit-web
 linux: target/x86_64-unknown-linux-musl/release/sit target/x86_64-unknown-linux-musl/release/sit-web
 
@@ -12,3 +14,11 @@ target/x86_64-unknown-linux-musl/release/sit target/x86_64-unknown-linux-musl/re
 	sed -i s/sha256://g ._docker_linux
 	docker run -u `id -u`:`id -g` -v `pwd`:/sit -w /sit -t `cat ._docker_linux` sh -c "cargo build --release --target=x86_64-unknown-linux-musl && strip target/x86_64-unknown-linux-musl/release/sit target/x86_64-unknown-linux-musl/release/sit-web"
 	rm -f ._docker_linux
+
+test:
+	# Test without deprecated-item-api
+	cd sit-core && cargo test --no-default-features --features="sha-1 blake2 duktape-reducers duktape-mmap duktape-require"
+	# Test
+	cargo test
+	# Test sit without deprecated-items
+	cd sit && cargo test --no-default-features
diff --git a/appveyor.yml b/appveyor.yml
index df5db5a..d1d3a60 100644
--- a/appveyor.yml
+++ b/appveyor.yml
@@ -24,7 +24,7 @@ install:
 build: false
 
 test_script:
-  - cargo test
+  - make test
 
 on_failure:
   - ps: $blockRdp = $true; iex ((new-object net.webclient).DownloadString('https://raw.githubusercontent.com/appveyor/ci/master/scripts/enable-rdp.ps1'))
diff --git a/doc/overview.png b/doc/overview.png
index fdafc5d1fbf5bb49669d122a001f599db09c9c12..6480f21283458461e41a83add9ccbea926582a0a 100644
GIT binary patch
literal 14002
zcmajGbzD?k*Z)t+peWrjfHX)+!vG=@f*{=?-CaW~NDG4kf^-Pd-Q9yA-3^0;^w7=s
za9!7PKlgKgpYQMY*YG;$%szYeUTf{O-s?lSvXbnRM--1xP*9${mV2d&f`SVCjT(l9
z23!#s5mp2~Sly(x-Ao;wyzI;^+)!lA9n4*f-OSBsO}uEW+}xZ*xVW6`j2+zE?d>>C
z9qsYCg{goMe7)7R-Tv!33JNsETt(q+#|yj`$BuwRr$8yn8pv3Xin=-mk7j*Rc~Mz;
zDr2LbN%pPh589W<b-YWir{i8#ExnaVa=dOh;PF|Z-6)QgY$g=VP0ggQLx~(w6aMj1
zk2@bPsgKv$b}%zcS$-&bAE8?Lj-hlU-$Q*spijh}1=HV;no8A_6y#1))tb8^(JFMh
zrb~^K6;TrvFfK_<h4z24iJ>@*@Fi9uoOS6Ju~AQO#|k9O+mJKAVSe3|lgXrITsw2S
z%mz0d&(G>UHA9F?9ljm=*}~e(ZS&Kg1r+spf?GkX${VkG)q%@F*2(o2YodjfLhFps
zDYq;?FxX>$Ip^TnFp=pzErjT|`(SQmbr!OF*B>RJYGhJ*kfR$aE{5Wr`Yun5q0faV
z@vW!G(G95A39ly2T;kDpqF?2k7Zx#bgN2Zg@LYt!uP^ACgndfWyAjwY5z^~3(7Wch
zu<UoVOmh8b2~;Ydg#@XFzBVaz38E;}FN(`_d_h6sYkK`kQXM+GoBB{&L*wl3HHM;`
zI$kfTIu*B*lC-iD*hzpN6gK*cFWx_^<;zzq9AOllZzMP@z1U~ZvnBINpJGN}%@nSY
zDOus<EPv{~yX)TdX;|>tTPt8eTRJHUwOkqyzS^nWzf7r~tiReZJ-A~biXh=x##3hL
z3VKNgCVGU-P!0nHzl5;FMSPHLKe_I2#8t^(lg4(K_jQIYLsu|U^TrRev`(qKN1#;L
z`tDwyLh+Z+x69vam<NHP4b<bLb6S2~!UH<OLGcCHu<!3Ps;a7Xc6JDvm42_Uudl7)
z<FcLbfFDWRou8i@G<ukunZ1uG)G8%_{TL6$tyIc=wR4<Cx%yml#w;Vtf2nspXmuWP
zI-uut(mH45w1yAETgovuHs;~sp~Vo#!1)M;MBO&nE0`tYuL#@_(VV|3dGhJg0@*h*
z0`h9Z3&r;xrn(<B_IJe~rDi>&JAI^Jy>-rqI5?Pe2XtW-E-o%%@L21Wn_o1{SFgsm
zv-KMoww#)pEV|izB_hi<FOEq2t-RK-U||mm-^14jl8GNZpu$41BamixU8hLZx=&HF
zKZg5y?)aVytFLfB+wIih6Gy199>{r5>8*%>2PKJvP}Z~t{S1C>C6bd<>hPC=xA?F3
z?{Z~XsY7o(FG#B-5Gw6Rp#puF89GU6Ux?ALNw!T7CL5aExNlg6LuqRT!mz-#yxLEU
zo<2?;52o7iRwIUd#+UoKqsADn1ev+9Ju1WFCr?6~c<t6BW*ikM4EmeC>c-_<|E^5+
zTjW6E;ox|nabrj7n)Vzwdf1;GiKZ?uODAyczs&UaQ*e0+Nz-`S4U(+_msp%tqWcC*
z!jjkNH2l+>RCv{3-pxZ%Mgc7NxZ3uT?d@Yf2t_<SQXm(_q)vu!KY}i0AYq}Om|*E8
zDM$H93%I9Lj|2?!5BqY(=o-e36Fn`cE_`2yL+xfNwBr&ul1K7mvssK9s!Yf8#ND?i
zWnTT>-=}9QF8W2vnS%H|z7-{yg!0|z3@7Z8kQw29wx?e>X?uDa)zO&{+4lgONl!01
z`P(-EM~B9MI}+Bqr03>wna1%`Mzw9SG5PkMRM<DxQ-k36{sbQw*@)WKQI)l$j}MF<
z98V3iYW(n7Wqab&V!jsXawfT=HCtAN*v;Y?A<T7y!1!#n=Lz(9bv2XIK=<k#x>#Q+
z!E7nIBT8pn%{_yPuJ0rq+R*4}P-Vr&Mg!>uehu<Rx)K@(D=Xz2MO!KnB9DV*P3=~!
zoaKb!I-9-BEip4sQg{d5-r@pm@b@~?RG!LBX{+i-Ueqe9bf~%q<f)CDhC*Maed-)K
zEW|^Aap`xIZtH?^Vp=^2qhuA)O`Z2^5T{gU3?qcSMyJ_3I$`Raam8G100$c(;Z$2_
zhSTy3x!qa*96T#Tm+|r=j<&Ga*eQ9i3?;atG18QgvH0`p?$Xjl<NkU!9!)ES5KrAx
zu#OPEVm9ewXGKfAc<YC*iTy&@SsSs4n4dxrrY53~nvznxILSGZB<iDpgMPsI0l34A
zm$$Pk8U<wq?-36VYIL+>4(5t#3?jSC|0Ymy$rn8_ie{g4KI|EI)&pLSL!&8oVr<;6
zZ!njAa60Fg@a!948?u_O_&4%CS<TF6%g3{2TCXrJ<2O1t-r(K1;{GNxXsnS&jcF5U
z|1{f^r_QDo;i4YbinC9*>$27tfca!gz_dqO141ECH468+KI~tD(*8n^%H!ejI{EdD
zCJcn^jc|aVFqP~M#wQG67<iW8z~KRR6MKt>m#fZ4>u=q+5_hM|OUk$jy?S?M3@<LO
z@Jy(M30Pfh6Q6CZJSs6<crvuSah53ujuE5BZw-*3=XYPVE&bNkd41N}=XWL0zKO5j
zPKgznaIiU?$=LKE&c|x6Bph^na~4`_Gf^cAi*9n2hD5jzCBowTBga39U%!j1pU7Sk
zE1<yf^ZYo}C!Ea$%ePn2BZQgl*SG#U8>7M9yuR3vBwHWNp~i}MmtAM!xwpeIisJkD
zamqxMwUjcS^(fZw0h3ZwxQX}aj+KQ)gq+>>WKN!B-eiqE_H;wAbn$0;pSz0<um<EQ
zy%t@JRR7b|;duiRShJ5HqDav0fF9hHtv$pl_{xL4(E7}ODZs(Z?)$2iYo@c}e5rX?
zoJjzm;;A&7Nr9G8vB#<m8<G|bLxYKumkZp`2TfTewX~YJCx~<M+fEeOsB8EQPS7uq
z*SUm_&E?FcKkq_Erq!O+oh?#!q(2CUFI`^c@{bgU6b{HfQ&}COU$wh3J!Z!Q%SFU|
zZbiz(R$3B<gOKN;xh?#{7UM)WGhu_#3nO#e8#+fq`QcD?U&y1wu~^Yo>bp~QKVP|y
z_C)HNB?ao!_RhdJvoy#&qPN(AF@BDIWJ?~e^m}!w?Y?7_hSyR;t!AkzBq3}ImFvAy
z2z$`=@_PAdr1@NpBS|Y+hXI4*TuOzNv+9qL@aRr12D{uDe3*QL>dzoi@{KskQL$V{
zTM=cQ1#(LY>)Bn<6&?BhP*WnA{0~V;-5_y16c6`)P1F&{ETj;)?h!m!)yRUFy($3}
ztZw5qQgHw_D*3%lpT|`X#?}8hA0%&Xqm)B{%N7q+&hN^O8y_x<U{No$@ZA`^Rka?Q
zpD!|&Vi#@1tf?t|o5-#1E}imY5{M{UQ?(yOL~HRQzvwsC_yFFP<uaV%urb6uViOKO
z>M*^#<w(Nzh46zBGxP_*)<?#~bPp|BC=Gh3obNSW6zd5RvWLHtDQO6h$S&h{y*%bA
zh{RWA#|K}X+Pk>hFSRuL!J~0RJ^h*4o;-g1l_QzQVg5bfwDe3&%SbdVpGi^S>cEpK
z>oMQ6J=$@*xl`iDRT_o4Vm=-aX9Tihqm0exN(S&xgF2^(+_M;aVTiA=hos_*wrAD}
z$$|l2P9770y}a^)lVvj~k49p#St|7F=3<$#SQi0E2(dZhr#x1YdNZ84;GR<Y-F9lQ
zb0%LSD}9r)xMp<a10Grr$5#}HkHAPzk8V)~Dm_V!&!rn0n@XLpm)1f<_1IW#7{A5s
zCHn&(9qn-uk0PjIko)#}q=uFBTE5ytY1r4?_-?7<wfT87c6L{!P+n^*tg655!$QmD
zmQe+i&q2RcI#On$kP=2QAzJ`HF(mr>?A!XbC~9zB9Ty{8iP2Kws&6EiBReFGKJM~j
z1FJf;{_5CSx4}*1et!6rlvvrGuG_R#I=qxC81K49;~Qn7w!(O_vTuwT3$A3OFV427
zayA1ZpOaHkuDIY#@j%N8yV9P4Z8%Ix_4gU+zj_G!YSU376&6=dcilYCN=8M7m;A3@
z*E;MjS36yRbf22N^nY&Nmlqbcb|5V>sKwIJTH2b%o*FltuO^%AGun|kF8>kq3Cxr;
zBSBWKF2LhO{Ixh7^s6Btz)}&i=v|nQ*Cne18Q0YWqGpcJ!~qM>+4~Zm)wx>7a(+v*
zkH8tpZo<YrT&TrdF6n<O?t8tNJtDW}xFA2~(eedtO3Tno+U3<)Zu65_1;(o%UnL;#
zKxH*uU2p}8A364uA)uP7sv`Qp!oa{F?pOG-H<z|mSTle%QR&l};M<1KTTg;;F|@37
zFtiFa2jV<lD=t6}&6;o^@A{S>dGYqWer>z_qzls&eo6{$yFkGu!jsg|OHLO)3fj5I
zs=d1@RfXc#(ROJeIMFgFo_9srsc(&6|40us(4Vcbn<4ugLeytV;XIN(aUS#Tox;cc
zr~Gf_w4>xO`Nh1iQ<FL=X*;|&QYEoT-b{jES+d(KtF!w%^O$u0sUjAP>)?~E3F-0i
zvP|OVjw?LNEiWE4k>6gPLmxrf9v`|KlaMz-^WX1W1inonJx3)2EdE#Dr6Akq4;h7W
z5nas&x$8~kdKPR1L0Ph;_=MKzKtO=OMI0BqaHw@_?B~$5{G6vE<so69czH;kIzkfg
z{bF6+BOGDs7-*a+q^en^v1*;#MT8a!Wj)ZYbLxZBNca<;P82q7kMj_oX;%-Z={KEc
z15rHS=0tyH#{bJ%Olkp(D7ng9lavyO0c;L~f8&+V)=S2AEb~60LXr?u9}!7OC4^D)
zTVB0}_9|(_rGCm=t(CZcm`mCz7~9v*j`q<3F_4b94XHJ`vnzVPcxhjg{xNh%U3%tc
zn8?4TGu?FIigDI@omEz8n{fw`9+>eb09U9HS1U4)WTxQALHfYB+5#qYT&3-!MGSuH
ztTuzEYS<;?xokF_QvXbkt3S0coG?@)Usd`f2gx|77MHrqoU;y$VvdX%5EBBH;lNVz
z?{F9-&j?m$LuRP5(}8_&p2U~7u53Hz0e=|<NUd!<Ci*CU^8v!`U!n7_XKlK>rFL1P
znN?@}6p+%&Ig1tJf$2-3!NK2##L*fw<|2#S(!<1WM#^=i)5Vn#)@W4Cem*{b{saJV
zU|a$kGm{^?y4K%l#_S*~du2Nr8p7%9RMx38J+18ntyB2H#DRe$E!c%9MC99<n$kP&
zJI{*juddGIsfeZI9v8i0?8qiE!qA9-hJiwITF5ChKa<2kOQ5|iy<0QL;Tqj;n1sKm
zi<#q}&9=j(yW5w<xI`^?w`1RU#g4mH&z5SxeftKM0JDP~6ciV<pMpPpsBG{I7#ppK
zu7SIs?kzx1?Vdu}X`s)H_7-v#kC+s<6xbOyFLD`Y{L&H9%1H$?s1sk!DMxB<gQ|Q#
zj(5!0?`JMfR5vH<h0fKEnGd1GD<mk%f(|%xzuUbR6BZE&zCG2evT#g4mew2%?@h~X
zLqG0Vd7(0VBf~y1!FE8+8qc1S4FYl5O#YJ5$6|mu%*z$))z+-j_f<gK0*i|Wc;si5
z6bW%ZF^J3np(5BM7^kEE2^fgiQgpn$Z*=J-(*-%K=gwFSF&KT^)wkb|SJ=^uOa{b!
zg(>eQC!GyLu+=di_=UWD)#XAMtJPf@%dT~s4rHqXi{gJGi@rPbrZM59rnfq_p(G56
zUuDQ`P!{uP6}ItT&DX#BvsrhVP3`PK09NKp{ET0K3(mmWG+8P)y;>!p=Xq8f%SE)x
zdeBCOh+D~8VRPP$cpv(E)5xznN&DZXm6M-Dt?c*Jpc0>YTSBg1cC$_D=-GGq6rneg
z*QA-jkqUbMK9wg4fdS#Lh9#?<2HgkV(SFi*jF5`TPD;MAmmqZ{ib@iLRlit9-5xE&
z_R<o$;=`9!UNGyiMHxe8rFxIuB$3G(7C~s9*lNK>^4BUcnyVeIz|l$65nxd+i|#Ve
zaR(}6*qnKKJh`MPMzfFJ#`zHCH}%SIh1867Wm*n+gC5o%5Qr>V<<#gtD4CIw(dZ6W
zfM&cuKaJ#S(m=il8r4O+T&81%(1qwyf;YLhR7g0x$Ez@(>XrXSvBPX|&NixtOAQHf
zh&=$$8e-(+R!}QHDdD3WvAh9Iv`pliGCdF&iiQ(5|NTm$(A(p&*UdhjJ?3(AePk7d
z8njnmvX~yi)P4}O$qXbh5rD~F;1|b-fzVc|MJL0r$PaYo#_+|hJJE&dTo@*Zv6BSs
zwMUvlZyj~LRUr{oO<3~0ixWHVZTc&s;_7aLY_NqM=wp>P%MGOC!<fB4$B#d;|G`R4
z@$eyn(`+<}-PB62*kq-HH9g?=GX*%1(T?ljy`Smkag*zVs$nSxNZGpJqSez;GJEJd
z1y&}a+3&A!#C#?TtHb*-0DpNRNsk#SfqlEm1Y?2pM`oN0u-bcH9CC7V<<L}I-d=U)
zP`bUP&_`+=Z4~AlK4oc9ln?EJmwt^pW*B<5=S&E5;m*g<68)3*X?U%_*&1P<RbKu<
z6{vRe)CcRI0{LAgGZ>CmM}!`)z~jV<$(CR;Z1l)szNum(X88Mi+Tiqnu>DaE*Mtnh
zaZ44Xw5o!UpuLwfG*4bvSJ&6qS6f?~d+pl;s1sgVdYim)VcB#_N($*mSq~2Zr%&PG
z?d5`MX^QVbpcUbVJA|5#^n$wq^wB~KS^n|-`Ew_Ar~C{^G72tEhbzG}a}iO^qsV6O
zlP&BHbXo+ImO$K=bZrLXe(cybapRma4Q)F^!$sh(ELx-x1EQWV&XRDsT@tE<cJ(p7
zL({nYY;VCw5~?h(a{oqiLWCp)fH_bA;~+Eea1oMpU}BY*Qc|g@sfusj0H^>+$}_H|
z2nY!~J3Cu1)+z6wKl~CC^8z^5f`J715s&~A{XNJ_NZ-px*x37v&6L#CPau2Z1ozir
zj4Uj@%jr+kUeJQOg0eLJ`$Ygl`qv=;y!+oT{WUHf@SVfwt0VQU8yOk2(GX;wKGbb<
z*mx{gk<lSnoec&S>-)?MJOsR40!TBxcrAWejpu#N&(9AE>b$+VQt`StTq`$)>+0y}
z=;`@*dEH!Wq?;rN*w3C{UIKxZQcpxgWN)F7G=6b$aiTz@5&%$@m6XCR3^tmjhW3t*
zFic85D{kA#qQF43fo1s`)^aWpQwxg_Ov}NP*AN!-aCi)z6i|S9t^fL#m6c@*k4_c$
zqlkBKaOezq(&&G4S#3LYd9uB+x5qi-*8i2GRKGsZ#mT8GDk`ezEG#Tc$bE~5;(E7s
z32>pywFIL+MCQymaup6xuIOgv7Jz+xKnI0^a(*2M`J5Jg_<;IGryBe*gW!&U21X?u
z2qWb(Bod$|BV*aRyWHj)zeB=l8iESnzklBz1nR#ZYrpjlN45$Whf>giyDlq^2h7UK
z8WIvx_p5Mnf2Q(>%|yW{ywP*N!=pQxN`RVxAWJvk@b_y)2#~@|0x=<3*2KYK@Aq$p
z$WS{qfTRJ|_ne2P-Owr&s@ym26ZT$yz$Zl_z|a@seVkWt7E}Evnp#vIN^6K_P_`3_
zOM{@-$H*I|!KDK%Pp{S?wY=Qf-(MV=5vQ}qV>L|s8@@4^8iXsk$))V<?oQ2bL-dr2
zVGSJ|?vN~l#_PGKuL48K2Z#VEr~V7_eC+3rH^>*DFR`)Rx@;;cDp*wxOD&4PHiUr4
z5=Go?fHhZCRHUY+md11cGn&H#U;)4hb#%PEz2)~cCqm#YepfrYyS5Vr4@M81yCaAP
zlK5RcJitOu%gpJ%SrTAi!aV{O78by+IZTyM2eHeOuL4f-kBR@gpZqVE?#=K&yy@>t
zQU<eC)|F7CiJ)NZ)<j{p@A2ly^71=9y}2ZQTcuPH4R1XCxh<gzc7*TMZY^-|e#LR#
z8fTS~>g2T?1l&^P_P}cN`)f_j$y8BKh?v;!&JNR?M5mj}6M&Q^CMUzYyTb>nilgZp
zpDGy|riF*UmXQgW#=Jh>o`Nj~LE{u4U%8Ap`$RqW__(=IC=siPJf`bI>816NTU$c2
zBvapnoDsi&#;UM9dsd`XYG`K00J!xU0q&pt?c-xN{ga%4_O9mUW@#N@lCx=dA=@vY
z9#^Nk=jTub1qD{JdytT|l4<HrMa_<=vYo<NnH<iP+W7UYb36sAt_^W3iq1xd0ZUqA
zGtt-Ei)H;77@k<TZnQ=u8V7QCbOh`f{+DoAtqbQ?o78SA5r8>!^78UjvSk2^A*O+G
zE+(GoMLz>;sRf8vb0*QtK-fOF6^<8b?E@~3SRIJnFf9hjeUyW~e=<(0KeQ2s59@nM
zLP9b*ISJG`TE%bnHW~4s9@JGZE9f-aPQp>Ccn~TxYrP#O8Bbf<Y4HNlro*^h!nxf7
zO;?ujVDjlv5EgZ^Murxo02V6vfRe}kDi<et;4>XK&SYl49_8H*H6LL>W_c;@i@kQ^
z`>XW<C*IKb!8_AVvHDI?Dj=?2=y`agG8{}#x^>MQnBianag;+4C;hSDCYALTiBSM;
z1^!<brIrPWWCr1y!7eO@Hjqap8%B$MVV8j?VN2fTCnfa{^Qj_8OCJb2Y(;`<NSwLj
zbzdL%rAfUFftR;wBzT6Z<rC|{9u#>~K*}stR7m1=%THi;9|>{UG)Td(Q6;Udt!HLt
zn3Ym`2L=ZE`{}{zTc!{q|63#y+32wgYz7M5s84w~oY2-mSH16-S2^cuoFXRM)|rL?
zCDFEs|JnT8A*zVg<v2CSOW%Z$;Nb4AuJ?H7ctUsxWS6%CymfUJ_Nna8kMlNW7yEZ+
zJ3YN!F}-;weU4~E;IXGg-tf9;iDs@Z=o)(m)6YF$J2`P<eZZBBi;s<!f~38mAu-GK
z8R9r4R!De74Y121?cjaO6%sKul4rle;<+GCNs7?G$%2lWEJRMU1?;GJurD*yJXTp9
z=62)a!I}cMKR*A=#K(~$Tsm2=1JF(8A2kd11;{d$IuDkz|JwXicTx1W&*h&r(6=)U
zJMV5Cy@{}1>y(8_$wJub4CSVas&;WBwah!YtjbmRP0@)_8EnKcR3?MbN4QqVFV3O2
z+eZ6`$&BC}JWa+bs)%2D6UUvnGCJCNC=UVOq}zX-TyJu!7b`RMyflZzoDMhK^@!y^
zA-dqbD@k!Nh4fVUC=Bdbg3ccWfdvPo3a-VyvMqAK#uHbwpY0hD_*6}K8OzIm#vZ1M
ziYldDYyL??(`5p8t=4behVy3Mo_zaHYVH;cuS#F%V8MrR=#fMoR+#gOxVsRoDI|D&
zqL}#MurLddq^qkdNc1u1wUD<PjY7W&06Lq`7V%WP5U=$27gKE~yayIrRG{ZBD%R%a
z(UY^)m9mWDU}1vrueOtX<U(b0UE!U;iOuq0VbVm-Y}}ha+jDE;0n|!HEh!?;&Ik9c
z7*fcSbL40KM4dBwL{LL$XoH(|RR49V=#{HWji94La!gr68TZkE;8Nmqb9F<*t%b%b
zHC2Ik{UF@udNp>}e}2U7Er`CSP#dEN#R+~0nO|r$;pGdqAMO~<8B>vy*HtS{;sI7L
zCqq8A#OAedRk5qj^2qRD?(gI#mF;Z3$0NLF@0Za6kO&-g3(L?|d0bnPxgtX`c)u<8
z&f>3ML?opRS0B*nfZ!ANlm&|Ug7E<5A<S?2mScV0Le;h{1gP0nl|KdLj$rQ_>nzEq
zFTHqbw4V(CZ+`KAfcGp7C1sec@4xZxysjRbMtB#7kcdFMIHxWj@kMjn>Va`^-lynO
z**HdfUi;ZOAgPKAIm_FlipS?j_EFDQW#r>%!ho0v_V7`E57_%al?{YL78HVM!9<k>
z0CHfcczeT){8i)@vw>ENHR*T0`w;?}_^8RKYgOh_*}2jmHtgx6!m2+=#JM?Y5yJqu
z_HwY<6fW|eyjRL%=(KNWDKrBsoc|3~742DDHBEd$J?P6m&<t5>P5+$KfUKT+^PIPH
z{Gd%hF<Ic#C;i|<<Z3y;jXID%W%K!Soh9C`lJ@_9py~C&36Qu>I;1_7{T@v>Hq?-M
zmh`|pL*u6kPINa0qn~~j3J|yM3QLn?cro(vp;R{~Ji7aMX9hp|f${WYu|kfh7Er;(
zwI@d^%mGk?J_^Y0viWj1*#sFHysT!Mm(J2D$tnMwPh6LumF)&_(1&!&LD+J|>ta6-
zTfG=<Z5`wD3+UeB^wYPQEYO+AE4WNych>U!^QB8ETR5aE`|0+6^5pffznPndUHDo4
zZRQn`%9AVOP2u-l*@4?{=_TgZgl`^B_eMmypY)!7gJ;r%iH)!i$2^6ao9A3*=7+q?
zK7-?jw^N&?B%s<cKY{!4!FcB}U8nS(>_Kj2_^o^Wi9LIvxdU{RUD?mq>3YXweW1CQ
zrE>D~1fF?9bm5CM)g0o`A4^&Gj?tIx&ga1&2dG#ODqj2MscH^#XNfJve_oioTRv9*
zZe2^W6Kd8Zab#k`l8Om%kNZTM07$?Y!EZmok!>2&vGT>!Y?@X9CXl@GzU;SqVlDbV
z6C{+`oBnT@yavKWM-Te3*HyW5rC+Vfzbfh(k<f!Yx+*Ix<NNV3?$YVCfuDbnazm$f
zgOPWBfF$uF+<|Ux1?g@A5DOWF=ExDAw}a+ZC!_mGPKVT|kR9%?oZ!m<N%Ii+;o748
zET7}(cmFqU-se&Mjc);_Oes(VPY>9We1hqHyeXasbkqDdhxbHIH6{SFRMpFpnRP}Y
zU^3A=Hz!lBNM|5PD=FEXtF7Ii9x>h+-2ZMbe&hBfG_(;gg-xpfm3sR*E&I6|tBC^Z
zp)~5ZDPd!iJjUd%8!e$S!xeu+4gNEY?VqGZ(17ESRggKC!K|^h&c<YM)rOe<7yQ-M
z{;vaMf(~uTjxBUIf)L;OW<UCI42)lajMkNy12}m#&*tR9vor0<{>4Uib|}7ow@VZr
z>l`U(J+58K;^&ZLE3Emn+K1CpMBYpB3t;QJvk2y8z-jF4ilo=#+3)a!85MFbE|p%;
zaqcPnv2F49D~<Nka9?h7F!DR$(t*4L*xO;XZ6lH~+#O>mP4She$<G(o$%R^;f>!TN
z;54G;Q9xV96dsWvsa@;PqFtw1WBSEhj+A-EZ^9d`v!dep5a7gz9l>hix6l;3AqCGm
zbtK-T$E91~xub)_^UEL}R_`k9uQ(7sQQGQfb7A7ybfTYT2hrjsCDSwU@XP1Beou6D
zA&9j#ORgmVHkb4@L-(uhq`-NSMaICpG*a*vZ2yx9o3nk(jDy|Ubhquv5+DrK$t{~H
z$HrDJOrD;ws>!TeOSS?(>*T<=`{L+zg$$EHqNyqR_GEF?cIdFhfL&Mj<GHZ*Kpb*J
z$Us)s_0`GtA@tE@&>K_J?4~C5nP_YO(u%8s6ATgS(J+2n-*Sb{5X}znv@@rC1f7AA
z?RZ}Fos3LLpkNHy*oROH(D!?g<;qvJlIcaF%BVCyKmX=hkl&r2^WuK?n)W&#2mAvs
zlG`C?^XT)d47|@@CJWXQi&Gf<nJA1s=kgAR9lUqS__C@7(5EaX=o{baia9ywj`ygX
zb>P+Hy`?3cBZY~b#PzcRd!uT(%LF5$y5|7y0`gZ?lOY9jV1<>hxEgqTp+BKk+wZM(
zYVgHmr6|EkmUJ3vq6sX;3yEKA>Rl~mfkxy^`xGC#J?2s10dO**vq%q2m)~?dp?jk8
zP<^Yez5rnCW)P@^hWTyJw!m`?%(_J^&u2aAvliVEFrbNm8YZ`VxMuK_;rwI@;Y4z4
z@VMCy{(Zk%iJBK5+PlY|Y~`_k%akIt^QPbe33ueuKSv5bNx*^Nk<ww1I*$}+@K&$T
z&7n>#%U9k{(UmNn0#`#pnWM1gndsjeY={T0OL-UP?A~rfL-Uqr{v0O;is}FYHA+Y3
zZjrHyxxxaTQ5>pqH#zlxjap%mjoQi<;Z#y8)~&K)STlS0un=G3T|Zb1%p6xi9owQc
z{?2nJFh$kX2(avzB=jlqn&MpERlhUGKd91hQbRNFNNOIZwa?T)Au!VZa-ALRLal5M
zET5l@lm}Tl4z7KDC;)(hxNI>iFxBe)NuCwbXfP>J)%afYA7bjVIzGfPWMCvVAC=R2
z0+3NuB#WOkMsQ(Kp{>urRlRx6(YoT!a3;{J<5(tCN|k5nl<BiM2nT5xN&n_pD967%
z6cQP%&jJExe4ph&zPh;WAn@TknKG25cK`7|x@|%797BKtWqBX0e!JJcB$ju*AQb@l
zUm?!JEmsYsm`eW(LHiL>T#feJY1BsJ4Xi%buO>j9$?!Hv_TRA11@^%*ZCqyCpz&_m
zMM?@)^Fi<6Am$sOOrCb-T@(K6ZhTvZ@kW`)w6B9hi6OMD-^|SH9gT8M2E-B-O!cvX
zKwD^sY7!^8)%&Et5Q;)?_atrE*+V6*5@0?rbsj#W^1!hT9oSe~`x6YRL4Q4sIx_vR
z&y@s#IxOrTf;<0uv(MQcaCc4m5ipx3yZ^>2_Y6fPnvsuh94G?1y1IskV*qB;C&2(r
z5CXZr50(HsdCK+h;luw4f&MOAv!8u0D?0$_$jHb@+v*<uUo=KLFfj1(EvpG8KaiFY
z75~qd{fj332OIjY!uemgXpI0im?{c-@WA<Zxa?X-wp1uivVc9CGjEQn*YTzbKzja~
z`z^A!zdxDBR3=*{>J3oXQ&FAnFTwiy6S!aii0td@o1LBQ@82GhxFc!=T9iFgQ?;J^
zi_@bcBhCPa$~!(iEzvAa%E`$|O<m~yOs`VuePZL|<HI+dAsM7oX+caxWQD0!p&0Hr
zLe9&}%O~Wz{stk*ssIUjOg>s^IRsSSM8w3@q8>ZPf5!6MTwN&z?50n)r%DYPCrgba
zJUu;s<^ox)*IFNOTu@Muy`7y|v+S!^UHNK1hL;^%Zzh2`akXBnlHd;HM$<?bHha78
z1RnzRJr0%7i+gGTpQ*G2x~}i~3QlM-;?EP#p}%|aeVd@jtg=6CZ7)>rri=nIZ($O*
z!_@i@Ffbm2A=>w2`QP1m3S|M~EY>*(wG-!jLdv~<&BMpnWo}sQKa?h>QK%U&zS!(T
zTEouyyX;R)4Bo_LEc06%L^*KC0{b}!A#indWoBm9ftV#ngogu>G$B0v;pt1!t{~N(
zMJWt*o5j`ZizCG9NVcp-b7+yG=gzcB2Rf2qGtgYZ_Z*LA<>`yyTPRjNu-Xmo+n=JM
zj*gDP0ZQcplMKS7lMwgZqw>Xi8So*Zuy7lw<MCE#S!oXB+~)WQ5&@PM;f*1uQJ`M$
zw1U<rXAtAH4Fie9q@+CiN)Zte@iN05XiWp#zzb<>8_!n**4)a*W@~ekB`{ARfisGn
zw`X*86xjQ*F*R@Z0s+YB?wqBgqfwzIM@$HeU9-q)vgli7<x$%Qbcu`Kgf~bb-*fI7
z9$wx;KtTo+y=3|-ePjT*{9l;k|8nWx3;_Ui?-2ikc+!ENkLD^ScSn*o*4Jy48d9%i
z%fc{0pt;%E$s!%st?~TP%H>&--p>X^8*`4W_CT}RElll)5;+A$ny~AA*>M;u8_T3v
zQBkosU%&e2kF}+xpmE1Xz_`+doIB>{A)K5_cDeQ+sAi;{4-XIDym<rQ;4XpXA4aYI
z$3Wt&k0|%Oa8X&Tcl`lS!D&1i_$PASfLq@I19j5gk(!plu5d!;w`reV0s=UI**&GF
z2U1Ly1gIRY;g26bRtvapu$lIDcRBiiNsgRi3F(76Dgjsmhr{)Bb>-X100$&~f=iA4
zdsCa}2e5KjwIMjvB9?<xx$9lo9f(ZR4^-69BB1dP7@LfYjGQS@C+79G$Jab?aa;bJ
zp6+O46A|-xO;4EAeL3^g=n*pSTvc6t954pJZnJ#dkUdRHE@sHOq|2jx_Yo>igi1Yz
zVGiITXZuUC7wbQd$|unoUNS)1Ft@NvHeBn%WElytv9WD!w}CuTfnPL*N$w*Sq%EYv
zd#VVAE~MX;UC~dskD`pf^bQY864j2Sz&+}}fKDH0u;;!kna9k?A2B>MNE}m%3ct_y
ze-RzgY0x_==)UW9aL@QIh^FIjqT_m7fr9>M3Tb-fDZ~U|=vs#ABO)lnG>$N3+AmZ9
z`n0ZXEj}yD<o1a6S!mvrqyv3~D&NvMpMYe@+=Xk{;-n-YeKLOooz1oJox3Yll>tUU
zx|6jX!}h3TpeDg?v0#0eEB@JV#x)G8{s<ENproNmG^OAN7+YH!!iEn%?~9D6$n)N!
zxqEmIx&I#$Nra@|r_hce32|}%sS*Qna&p>N-mZMW{=F@-RE@v8m=^3YPpSC%Li(nq
z&mzcl0djije+pkYcZrY%8W%u~keEn@hem@20!$oExSjufc+<l%c<xxucbTwWfcv?J
zso7t}|C%7`BbYV5W;0=fkA7bmt0&a%TO)&z5ZTAJP};t}pFaUNS$%kHEV;gyUrE1p
zqQYrF;4WlnSZPAsk}j=%45@>@zUZJgX=ht5_d2o&eu)aoy2!YX^bOO~i+5td{nL4V
zkBaTC-_plQ(Nl%wzDarw2*YyPOwX=(iAz>j{@++9uESV+vLXjK#MGT2E+#?rc9-o4
zjhO>%T|4!G=@-%{;YqkE<GU9dnRP#az`46kPM%rt0O(H`%0TcmyQ|0o|9{!e>#dXM
zy;Ewc9d&X-ZVV7tgRd7UFm*0bFe!l)aj|UP%*_spk@3K4u9sZ=60_s@ukrZFX2<Kx
zAP0zm-9e+PW$SP#F7D3;{J&qT+SC;9Dy~s^)t)BR-ovh8I8(*^$}_3tAn~+6tGfX?
zU19DV-ae6|APOi-)M_2<$Iq{>02Yi?UB;iYQ~tkTj4Vy5WfwYUjzYquxOkcqm$2|0
zkS8n3X)6M2IJ26`{ion-oYb61EeQN%*G|6WCuOyG%bM~6G%;zCTTn2_V|P}Q1h%tt
zki@SDhV&BM8T>6L1ZLX@h9OP}`92v!ar-YdFRw8P)JjVoAn*1z1{q)COa4RvI+*{E
z1OhwJgt3^N<f<-HWw)o2BOgCpbwF?swvagNd%%mS1;8F1oo|KayMH}cFH7i|SXU#e
zWhhSQwos1-wng{+(^OlC3kLf6Kz{lU-N4)K{oH$VReMjwPodX*{@!s*Px-U&m8}jZ
zo1U<O5UC~Vl}eYvyq~5vdgGH_^u}8|M(bDceW``W)rA!)n+fk?S4;T!@BF}P<HW##
z$P3XBJyzw@x-TL4TwoMgSU;TDgI>}+PY4B~CDhx`iJ5+|CSZJ>KPh*=RC^%@rZAw(
zUr3>$k?zW<50BvblDfE_!j4ceM!vsou~yVi#<w}bR~X++CjwM*#=iFkX$FbljrmOD
zKyx%gxcr$od3x;VUe#ur@Q<nuzz?Z>9!cWj4Bi3is!N_~p?(Ktw6VYm5djOO{XQL9
z<zwr!DMD?>P<kh_ICwK$CA=2+1lSgNVcgeNe6;zE8zsa>*JXaL$L$EC$E!G93``jN
zhUZ=;@PA}&oSs8Tgut5FoK+063V!!_voz_JQPIE~P4@4yHeJIMOu(Skfsuhwe&4MF
zreN8<3SDONT~im+C>mCRuwjG8e<&kVtefBo>=%<bHz&|#c|`ksP~SZ8G=MMu?W=ts
zWUV#{Kp;^-(<UG=2?p<FjSlU1cD%gsVwor)U#hQ6|LZrx_gfu-<V(ySQUjfw4Ei-b
z9+kB?TqZBsE_pK34zmF=zQYtv=KJ76WApA^ncd7M=T*!mpcx5hO|x9Cp=bAc8;1qE
z=`wJ@ZN2QQ%b(Fdd0pn>jOLxczJUQXYG&&V35URRtz&GVEl~FDih8(B*B^-vm@YJ3
zj5Yg!#@WV31pvwLQcG%yuCV8xj}VovtLygrfJ`70lckqEy}jJ7FIbeSIa*oi-`%Cm
zWTJgXa^Lk>{dRyC;tmMXOej@=BrxEW@y{>TEiHuKIf4SkrRbiT)QA5p3=i+N4J^{X
z2rx13u$}S%^q|LxZp6v#AixLIJogLW66he0tF6L-{GlVin1@(^$Qd5Ji@Tj*rG5ey
z;zQ#G+K!b+_4Plk9#OxTSy~GHYg?omvhKygw>OW8T5e8b0ov=nJ6ofeyk2H)tzaAn
zcs~IAUoo1{ktQIB#s8__Bb)E*ccm2NfFSrvXT;G)teHJ>x;zo+5mp5RY+ybq!l1K(
z&Nsv}MTY8b(9>(73aGf=Tp9xVnnsM9|2Q3`vcDJ0esNxNn&nfAR;iMW9#A4{x3=UE
zQMm8zguQgDk_huY4Z9cBaXTwQ%+y>52H62=iTkVj<iij0<;&#qA(su_!DcuJ!Ba<s
z?;P$uVA?*B0?EI{wCs`=^(Z3D7ofr!J^uBJI}VUR#hO5XhM$wUwT|px3Ni*D^NB;g
zc#gt`x3OFbgZ)T@5|!!#B`sR<R}M=03JU%L*m}8{>%DZr>6sZ$@A(om`{!&mjFd+Q
z5M@IiW{G}I+71Uj0tCp*Hz}!e&kRJUKj8z;(GqaRV$ke$#H@mKUzaNVW&S3qf{rGk
zI2>~|_Nc9(saN;ry*w0nfA1e-XE}pzCh}`X_<T!F=C`vlx14GND9S^^5cyVg@%`{{
z;893y-yp@aljiquu2vRhl*e*)QZK=+gc~|cOj~29z}i-v?&$3Q9xrg;wg6z;QnM%)
z|6GmV19rQ=aac|`T~h4bxW$vcLD^@{r3B2+3J{+Y61JA#h3;A3US{4E$y?j3{*A`0
zR095t;sB(-;7AjgYcFt0{g+NM|3kn{ybA!z0ewF_nz*&rdZFPWRYZ6zv7Y4u)&2<I
zeLrUi7J>%riQ2BU8p-o^H=Qt|bbs?^oTpGVX%@?(sOZ<x(OG7b(@Gpn0xY{P3Ar^!
z9T~axyA;ZweD#;qQ94P%*3RyuZB5O$$S;|;$*?>hE-~h3@{8z;Jqyi+t*vjv2?^bQ
z6{x%8$1+7}SN4#mN;=S&U;(SN*+Ku@MdR*vumWnOv=sB$V9xi|f{&Q>9%?ZE+3s9U
zS3V=-U;$Bt#maG9U%YBE@RjT0uorl)k;{*muzd*HCrVpMBvz_Cb|Kc{@kN;mm6+87
zvg6GO;)Em`$oG0=;!W`5Kc@0s*<CvEUjWi#0jSwugaI4*ZQOT%F-neGx5n<%cAne-
zA%P}6t)wChd?z=+|HQz3GGoWLi{NaO_bgAVv;;^Vus+DZ_UPAUL=IS-HFLhx(M5hP
zdFKOc<auRAgHno+-Gz(e;xyxZ!17+{fc3rwr0#_aL%@ZgKBED^6aEgaz*$}dJvb2r
zRBp)O2oRuoqXW-2gNy<?r<U+=*TKKU{uPJ+J+d~%{Y^5i7lNP%p18Mrl91zsKuW>V
z9bpDOR$9504H`tFTmL-c`CdNbW-dopHo@!vMi$bJ?M}wS+-}0c!T>Q>07NJyfdCCS
z?-Nuz#(PW@f*ll+**`GA2qxCS0|TgHxxZ&kS#m^*TbYdWF-6E8(7pz~hg}kIp5#pT
zDz7XuEA(9kw>}x)V*^7&Fi-&ma*-vx@Eya-eyjYi0UJH{!NC6tu{8pMkzlAY%UjMn
bny^3keefDwF5sWgP+m(by()S6F7W>V$f<WC

literal 18958
zcmeIaS6Ecbw)d?fqU4OECK-^7WN9*pg5)e2BxgxY2Fb}52`V|~AV|(p5F|>@G&$3f
z^IN^vUi+-Q&psF5&G%ls=XrdzowMhhHLFIAs_`Gc(V>d+(m0qDm^W_Rz<K#XQu)S>
zo8a>;n!C5a5scU9%;29VPEwjq#&-5@)+VM-H>6E$P2L(hnY^Jja-%hOa<YHM&TemQ
zXzS!`W6fr4XG6dtKn3oS>#nNl^w;qlH(-e-9~JBnqSzg~3`lAgdHWZVw`7%Y)vgt5
zvlN+>tJ5diDWA(h%}w7?Z11@0KaLTfDp<YTT3xLvlc&%ib(4KiQ%)LJ{YzcIhUw%N
z;SFtzs<5)ipIkOEQ>6GUa%}pXTTtf(_I8nyhE!7ehtEtNipYjvel5;(il$48nr44D
zvSC<HGkhpSQNS(LywtR~gc00fm@VTLa>{}5u_UUo3^p4lB(fQbp6FlWJD)oV?M8}5
zvwT<|Cx5gdp8kWb#@$$INEOGKR8i2}e^pn!?t^MY0($zLk73rb+*n?NRMW`?vzI=D
zBgK7c8ZRsyA0iWF-xi#1-KW3pJ&wh8VKDsVK6-e&nBCnL#xu@{GrH;74t7PX+H}Wj
zC|ZGRG;L=0@AxK}PU>1CrengmhXQJQ!yUL5&%B|e^Y4$k&6)TyId%IL-YqoODd8G%
zZ=sLwOQaljI$TE0P2DC-8^c29@)W@(MRfCu^%BS084;xT`q5xtcr$)K(T=NGZ0TgL
zaQ^~h;EaxmeQF&30-^p*NCm0Qa)ovuV>aNoWc{-nH>9^-N{Xq%CbyIBX{xCmU%$Nl
z1SW-kljLT{O|(^2N%U1MB^5_s#-dj$>yI~>Ei6_(bf?Bj7>2#8w`b>~co1)#n)$Ke
zHGd#cyu=fJhTqpd4(G|X$H^WwjNJ#i{qC@%nZ$3q!smtkT2@Km!<}omc$zr@8t%<N
zaVR4(LM#m*4>J&^$k^^Lo<{{+n(L}7+vJFSt;Bu3QbZPv(a1iO$^ia*u(8v|P602R
z_hqi5&l~<-s3msO#2=%v?(5#&*w@L2a2onhjM#iEcueYt^78VZKYvC)R#;hDT3T5l
z#A7<V2MI&>3k?kwblv&c)pdhztXP);qL2rNPzzK%whZ1)tY$Ngjl_6DaS&<C`=F)G
z>U#Qg?5ZyIjs^kp?!G=D0RaIS8HV`0#Jp%o=dZOAZ9eHL2!X|z0y0_uU~+!#1ZVJv
z;UMQ`tUmga`t0Xg$Frkt=NoCTc-@Xx<Nd^rw6rwZ+rqb%)LmS7k&ItRq5KDz51Mk%
zykcZYJE`Pi#u$*8*9z$@9#<Eq%CGg%TNy09Z|seiTSSYe`J#z=N<n45Klh}ek@{51
zc~0_r;w0s{9i9e1o~(z@qewVR^&V7t_P1I!JlIjOgZ9N~p!OWwiu2FNh{!@48>m;%
z_2t~b{j8p^*KFsBN77Ix0Z3=;W|Va^LTy45zpN`asMIg)1|bhkdg0V&3B$eR4b83X
zO_MhP(U=G&nd7|Qcv5_n?|y2J95DEVm6n&@CJYJ+l9;37H9jpIo1@n4NsoISlXbBc
zP3<+ybi|yPM2&6`7gzB;V%_!fta#OxKP?TbL}wyY-2aaHQUDBEkSvcKY00D0yJLoa
ziscXC8<EYwFg?H1`${NVFD0SLTZ0Aib@JjOr7!X2#_$i5q0BM;W{23jcn6U%d_3|Q
zVek02N1c`~BJEQ|*7d5}S&?;ZPC4ricJd-e69^;Zc)eQ`BfIXi24iV5rAAKy=iyvo
z=graQlEnAd9y1jcu?k;0l@(a^Xz1Huf7qE5Vcbwiezi7Jr&9F#`t94dArU%{m{$8!
z-WVGj+S-m5e!28ROURnH{Jo?U6g09i@~vI^L!OPRC)wGr$|54BPptdYoas5kt9dGO
zdxzB0(EMkR()a%9#-jz~4OS(6%@SPkL#mP{b>|I5k0Go5kK1-SBPsVz78V!!lC)1x
z-R2rRXazkew*;S9#BxmBM5~>Di%ZS_b+a{4Me%fRA&r!k!s`NAmuk|VY}fl!Pr#EO
zk&{x{d?v++-W2d%%@I#+m#(hvgw3;~!2@I9OJd@7NxjkUF@28!uAAlNDKJ%MXu95d
zeq4;iRCNU!1c!P%tmy~kH}8af4k1UpyE>g&vU#~be?}B){UQ!xuGFfqtc3UD8<tH~
zdOcx^j@D=kPPN}N(A=Kn$-*~Bv>VQ2vNnfQ+37R8-M4{t?XWd6KQyT*x4XWw)%Ov?
z3v6#!YYuH8LGr&t8{~Fh5Gth5+}y{0kS3<@RgY0Tu)dyPV^h=-D<~{n{Tyd;rI$K@
z*K*k4WDnB%29G)nU+~tA013wS4)mI8?kI`?S+Ov9>)GMHzQ?wj0k8Lk=)&_i$bm}1
z#?3XQKvf!o(&3o~YD~NOL02RquiYO;6`H?58co2Q;GtTe&I)BMyAMV1SvykX`|S8p
zWmt{zGTtE6eEeBy>VB-uGN#h|(0juRLYcb7dY6WK^R~Zo;A$Nih7wj@^_}cZ7m*mP
z(18#Nm0zFwlP}-H@Zk)lk$0NgD`skbBNI|L`$h)a+wB_1N2a8Gptdt-rSjDK!^6(#
z=)oU?f5tCIf2yLP8!a^+q^}D4kq#-IpRCZ`!^R@5Xa9)trvF7d4YX^#%C4>H$^;W{
zf9{&;cz5n@hO|Ap9W9GqYlhc3>E0dXowS;|N00&6S@PL3lW2(0v%NkNB;(MGv9KbW
zX0GW$lt_oBrik~B(#*hq5rH?eDLkG#yVAr)4qAEMcWN?w>k{ePmvH<(#E?y2UP|#c
zWd~24%44#qJM+f&dp{q^QM^lcoul@v*V>AWB^mo>hT-VQC26Ex$s&d$UcqY<-!{t1
zY86Q}ao#WDT7V#+ruG%ZWes-{cXZW)9_`HdW?UUjp@VKGUUyrr8cgc6oV<KzC(QMf
zcL+JGV=lhvH^zmKDHVx-bWTsgInu*ER_*3UgQSJP(cpFDNSDhD2@R`w?^GkTRbgGr
z(R{6$+}g9mg3ek7m{k5IW!6;6({?mua>;IW)f}X|^IiL*-KE#!#&}%Y$O;2#LFoG6
zy`xLcvsg5|2U1;K`d$^t8pj`?ITsSg4Z=@shu>UIg!D!zY;W)H|Ex(ImV`2iKu+D(
zrvw|KPQDX+dA=A@aLBuyo8{YTkUkAI_i4|Nxp<8qu;p`k+0M&A*gCplV63pVA=xPw
zoYVJ+vOS~wa+J#LMf#=hF0@`*M8DQ~>JhRXf5+&2RL+BxO=g|{*@VeSN2VONAVNt>
zgUJoXw^;vs%BjRcI{{lczIx$BMsKaxDmV9H68Wc(ZR^}27-Kc*gm?(ChmdxE8K@pN
z<ncSSy%|+YH}z6+5Au1jEOla5tliSL==wBbtgG(yFmy*err11zSQ%)pDncxa5U#8&
z(Po*hm=T1Wsl$-TlEcE<55g&;rncGM-jw@1pI1xYr?TmLQ<sAK>$}>T3exb8I!%pM
zV7{fl1r|@nmN{S<+PUAl*zDIEkL3yFfgq}+=ZoYLRtycplN)-swrtY(4#)OiS6DKs
z6NbLWh3(O1q|OhNTNta7F=VRKL63Il)^=u#bp>;9sS{ndPF|~0+`rGF`^;;)`esSP
zk)@8#Kr}kOONpzq&Am;Fnc9hBUAo+f+C!}S<~?z8?nhhpzn7v-`VH0O<#BcEDo+o7
z{fM8Hs9f&qG8sqb5fkIe(gl-CX_V^)Y-wf3(ZxlQM)L9mi8fVb=eL7HIV!>8;A=-E
zREuXhS?T=yV5@i$_E5LZh3&n35#goeoOy*BE?xjWhi&QYd0-u21vZMsxnKHqhRf`u
zVrXkDv*6}vQBrcFRw3s;aGGB~WtkKe7N+yyj20z4R!<{|%~5zvBCHp$PKs9%=lHf#
zTU$FM#sAKovzK+)6vNx$>{qPe(izWj;`v-TI5{Ca`EXVEW&<OO9&}{R=N9I@d(01+
zY^TQy7GYR4>={AH3^8Y?tBe&ij>qeZwQqiKzqW~OV-Oa;|9p30P|y5VwoB{1=8!Dr
zW9E|2wBJJ_aROp<cPNR7#!K{9Td!HW-&k7*^a$v5exTbS^eBVnRz&F9H++iFoLmMD
z(Yl@84KC<9gn_%oRD{-G+ABR%TM;<cx=dpp`r+Q`kEI_O>FIGTWb6ETX?L$1FW$a)
zQWVd5MIO2H5-V7_03X8P{yE0<+Mr!|V)(#Bv+@yyWAo~Ah8qdHJk(1kq%lD%T509!
z(8VEC+cL(d(Q4f*eC8UZMiZk5W(&VGgyc1gmgrG;+;MX|M<V_4o-@QYc?rr*A!RUi
z^xfAV{veP`I=f@e9=nzD8oB37-8}g*I)%j|F|P6@C1iZ4JOBON;@|r|@94t#H^%gh
zrMhPGenrn?5`=4VQN8>o45O_U@1d{8y!)AMyUcDbNF|5RdH$x#9gVI8CHa?HICiwW
z_XR7Pn$h|&V5z=$yT5-&Y)$OGfs-{{?)t>GdNiZcH4?fK+!z^1gS^R*$ypJ(x<8pE
zn*bJAx}gu^ZgLE4p7j(ogxJ=hd%Bq`FJBhm|47Z2hBv7=!q6o7?HUDOR~IkO=9Nxh
z)FwLTGt;jb+DlYA>&K@vyf14*;wgB`pRce&?@W{B`tr5ui-_3yVSE<Tdp}F>PsUF2
zK}c^ebn%wRjSRDXT<P~07_nWV18NVX5VLG5j<e&eTqL1l3yWhRq2+!u(2!1|BtciB
z^CQ;Da*Ou`jn$h{e|U(85LG5*sxmVrq%0ae-0Nfy;oS1>7z;D`a6(6K)*B5C&7n%8
zR@!x4Ilt0<<h;v>>CNJI9BZ2*>4>$we#*E{Y)S83fa4YoFUf^<$&<1$L!IgiD0PSS
z<z}DpdOU|p-rV-NJcM$6(-_W9$$i4RGg4p-Y_dJ$DGYBSFCd;t&`a^!EpoC_r+m#n
ziowI@beU@6N1)?MeWcCTj9}?=V0|Vz;`u!Ef*GZ%d-%^B5MQfiDZ)z6_Szno5H`8k
zXe2#bK|DJ2#~|0OE&tISW;HwQ2UCSX%jF)bs!Xi=pY>Y}mzuy%jHsir)Ea`fRA2Ny
zf0M!#M-Q>5rM&<HYHiIT*{NO>&)N{Q60I<+U5dC?q=m%Z#IsSkH=^otmU^{M;cV@8
z?h=2%8V~M){E&p1HxaTG@myz;hqKyKKux;=7b^N_PxK}PyEE{X4kB4-F5P}j@%A(J
zrw<WIFZVtq$>e62{lbvtE-4*nt&n4j0f#X2MniDXbDORk)nZV)S<{xH_wF{ZSD)wa
zNg4ji?*EXtsQ><bB|`tM;DR#PKZ_M;@JVW=Y077mjJL#Ysfzc`%Q&7Hgs$+A)@5xi
zi8Hpk6FB{l4;*fnn2LA~69MMpz;}yIad$S!Y0L_7(|Z2dhxj(J1qL0`v&BU&$@tN%
z`~yhr1D;Qyb$Ot5hbd#4TXAL4SZN%>pD9{dGgrz~=tlMicryr`7CaoXg5BL+M0|v`
zTpO4mhnr&^Qn!5;*xI$fXK^<GXWk_dBCY1b(zWidifBRom8Kh&EK~J4fK7X)hfDe&
zh8Eh1)s{j0N&H}c-^D)H&cJ|n<^rraVSd4t0zO&Q#E97j%DyC77pHPyo*6$;4=)}M
z^)JK1mzkBAiV^E251Wh=Ck6&Bt%aZy%#cqB^^eEG&+oO3NqU;gE1}fcCWsJ&c1zi3
z3H)_Z2DbJYb*@zLTsZ_R<}p}MZnNQaE{Cs*#y7=BCL%lJ$zxVNuc@OhypPvQ?tJ!&
zYFNitk+phA$V9PKVyayXb*d+c8Jz2or;5?_Rg~!sPkPF@kj8ranb+nO2t>eE9)E={
zETaP-Pna}Q8AOkNt*CfR6+?>-^!zvG<g((-dNDB>DWSQ;Vd*9dLh8k$o>JhT5JCOB
z8jRTP;Y69gItq0?=AmAVmb%F?YX>^HOoK@t`iQHXP|w{pb)@(cX=!bbb9bUgFqx)1
zzr1MA4pz?&b=!iE@ppA-pw$T*3f*T14kS&Fnyad;Rv%oR%}q|;I>e)aY>W>scgH4`
z5mgx*qw#FEwUG%53L+S{wyf*x@5lsa*V6LU(#>M9d&k;XTQ6-2?&OV4<o<-kAl_kT
zg#@3pd>!UPwL$|LfRi?5Gs%sIrLFoJrqggH;pEf|CZVtAWH~3p^8@0;IiDuerLNhb
zDzu*Ki&aN8sN%^=0^IE9-VhOd&S%cj*470fS%2a%)#ybT*1^CJGd<oZ(b5_jtPB$^
z-L#HjhsLq)+sxEz0gsbOLdZSW|Df*Z-B#mJ%_m(Cv7=?>`22~RBXK5_gR8Mh>F5=%
zaz7yGOrKc31mVuJ>`d&lZvE)Ux_3}DXT;-CU?X<#N6=fx<AqxhkbLTpEkjJGXbDXE
z7G@c<@ry8FV@65x)fZqT^71fWYt5G1ZVwb~1;K<Di1UJqHvKVJ#=n2Rm65qUz>REv
zksjUP?mT=s8HDNIIa%R|MblI+^_os>|MFFt6?@lCL0ItQBvu*wry&<-)lJ{wGHV9+
z#-}nH3Gv4RP)yaJ0MB>gs>4q~7|>z&SflVngeHY9zG37jgKb>#p9_DSw_5fj&O{qA
zJA#}ewdZk4eU7mScG?~!BwMuXB*dz6WAb<PQ3kbx6Cp&AJNI-$Q41<cFwoIx+<Dab
z@VSv@p$7Y`;jIoBCX^$H|4p@dwT!2;NwdV;1NJ5ziNX)5r{0eyD#+d(t93}&Y@<(n
zlKqjtg_WK;S7ybVzRH|YzL4fdto#s{Dx3Byd>~!+6EA3DWom#^Xvc`_d~>m{RuN@c
zaA--8Y)ezSv<<WI-K3``+|MPdZyivbhh53S-k3h0oP3>umJjn~lp`!(hA8T|;(t8c
z-3`jVO*dKJIh<!lTS649Q|Ho~qivRvxB@}&6;ICgXV!p0-ZfT3DxQ~Y^<;6YX=6zC
zltr$cb~D<*%prlQq2Zi;4a62NM3UH*c5do6Og7og_2thDxO_g@_`)?O*~(fUP#Mb^
zz=}(bVAJ)t@8x}(&xWhhiiX}^mEr?N2ZJJJlyCq8@8!Zh&f&>D(O@Nbnf((}(-PV;
z5?S03vK;I2uc@tzbmxEckW5(cAI+Eooii`<jX+4B{NbUT`<QCpd>XK-5i*&Z7E1$v
zJReaYa&<B@+aS2`G}FceTPG(7_fWCN?St1#rRadp^<OUyGEC)E?%`plhKz=Fp!qpi
zZai}kLDR#ssD<sqSs-2aq8RduH3u?Zwso%vz4^o7#a|*Bhkw6)(hJi#LRV5o^~8QR
z<DafT5c2FT9ziOfwRvQw);7eyvMr{O;@&+3+nb?yX5)(sM`B+8!Elc{Wy`DeoM@5r
zEi@kJZP{_X`J3n82iDzIG0oG0U%(7{OByFNGdU;sn&XsTF_t?l-l=mfVPAhnsdijy
zkXNr0W|upZtx>#ndtdpCu3)#GOQ%*$V`x51p*N)@uDd7eB#4PR{&TfV=a8Yj76QVD
z%)JpUbAp@yI|GSqQGP29B8$EndI(q&9z(Rmbi(|)v+h?Dqs7W{uCbr;+3C)BX`0I@
zh8T$%e7^qJ>qweGG;F5iK%bXYLdn;}4^@50%F4>g$w^O7AM^X?Ehzupeg%W9uWFjs
zE-pt{tqfdTMEu`7Iu`2ql#=CqF)$Vc?rjmNV`>L>0Ku-F7CN8v^y$;RqIqR8H{P2N
zs({r8UllZ;Sd)-?Y)@8@1z?D_AN##HDNKqnBbsj!gUR1I4~T75H!Q8GsbRm1=Sig5
zu0fwH`10Q`zP`Ey7iSTp!|d_96YxRIMF(OoacBreAWYTZ9v+@6h<$l@c(}PAfaAaM
zUdqeAkBGR~C@2ZRK&E!dDk~F$z!gZAP#{*q6j29(c8O%fdcw$9?YgT6wk3Pj$C{|)
z(5Md|@cn(lJ{!q_+e;Pv>%&l2{c)rJdj3BTq3-=>lko9m0^2iGa^&gg=&0NfN)>zN
zbB&kZBPqjYUgfDmM7$Fj6#i_xC-kkOV~#?~&iuTAsp-nrmgju)O;x>`w<cTTrK6*x
zyu7@^!oogRr#a(Uz&&1FT{U<de~)8hWAixPk;*D5v5TbODJ(3cqNbL9PZb)kR-i5*
zAdn`etv&UH%WP$J)#{E$nOvyXAi1NXBR9YCcWi{%6Io~wF7@O$vwrZ0l$6xe#3V_;
z@lGrR0%;4vsdHHT4t5;phnsx%^P)epwad*N4mZ?dBqSuZx3=CiNUN$2um8#!oVRPb
z9L;<g9m}lIjYyjq4kdd0>eZ{SWZhMEbHX6bM5e}&Lst8exHvd`pA?Mx<EtX{5sRh9
zoqNckEZNp<e}8|eOMRcqz%ww9C0y-Eh>5x1bm413xf9MVkLMObDy=8p?ytz*(TI8a
z-MBwl2<Vp8KMO{8XB+C=4>yK7K?k(BbOciIQj?NqzxLS}egcFO+nLD*57)X*BSXW5
zjSZ&oU~3fz2Zsjt!>2qv9eU=$Fvae1j}Tv(UJspWdofR__eFL7@rR0aT<T{pV6=L-
zbiZy%!y#bbb~|@~29FNNI{H<%Nu{L@dU_D>Mp`?ZuswsNPM|Ob<B6@YD>}Hk((qUk
z(^EZIMuUXgCOp5zW!6Wf1iz67wrOPSdXnUMSWoRPk)jxtc5`fT6k(yEVyVunebitW
zxS-9=F;7$|c&*LB&?6A^?{a%SvBSx^zIS(bPfkuwO=-JV<@2Iq^xdT;lqB{c2oAns
zH(8#SkT8`h<}ZA<#&C(`cRygP<mBTk0fF;Wr46}`64+T`qAdLH(*$Lv|KZU8WXyDs
zjiFlSO{s8FHyG^m=g+C07bnPp0Ywjw^LQRB`7ckU&giNuM;zX0v}=7cl`Bv$$}Hjc
zIxA00TbTG}7K(w)g~7OOr%$?~7+iN}508#qoSYIl3|k{9`Q($K7KVmkn$hz9s(ki-
zD~un^{_N~*a&mGb%DrDD`XcUl2qikCW~KEP#@+GKw&vy=)**1??-5`4?2=d5@(UKt
zwROx8?V-_+<iyibQ&YV!&jtqv!OT{D0nOCc&B@7G%xAyEdbG2-$=p4u-Z^-5ZdZ*P
zVCK3r{qohT^0Kmz?>K=kV4{RP11C%A<w3U**t)s9_azG@<Ov{i%VBGp)Y2FbtFdC6
ziL$JyD1xE;s0$qJvuvEHs9{UX%U`~Hp?g3?V`rv6<QF{Y^Q1lFqpYD}n!kTr9IJMF
z=VCbT(p4O5cxQ!|NQxd=4*>&2?Zv#>##qVqd<z;9Ihu!s<VAZR{s7v1XJg-P$)O!=
z=?P?IWhp5WY^Eyn)V=5WwCN@19h{E|vR;lc(A@ds8=v%7iqT0zEB(dpVj3`X=gP*U
zF;ih-1jAHMt(OeNVxqKv7ufmY&);k!(9St-H2lW@wB29%frZ^q^!pwd{muI3^>RK-
z5Gqn&e;+Z%Y$Y3qUw$Pp8#MDc=M#7YTxV5gtsF7T+L_9m?X4h208H^JjxzXL7$N*q
z-J@Ze0P6rWko&p*P!t)=95G#Xt5twl?H2rk(oMsKI(s9p>8EZE_j-JEIb0$wXJxKl
z%@5gpGXxed;{|bdK3>3tORL*A$LdC@T0XH<R}_8Nf`*}@2@8;6mAYIEegP!0jaG(-
zj1RyX#KpD0^dlPhGGH4(UGsVu43;b-BSc@4AlK8Uq9F%Qtq@8(+>cpJ`y*<Qy5FBr
z;wf{l6<9yxpY^&Z7NAKHN))y7mWKtLvWJF*goKBq(e2UM)3#?!ub&QIKPaapH~F74
zK<^!Cd`x|~ZEA;+<4`jPb92VKet2Rru}MjC(C#SVZjqQB!JIA)7A-1AZY4c<JM)D|
zX!%x+*;Nkr=1|AK<bR?rPlb_;T)fH{3aU=zl;8BzVk56D4vzL1&H9(BJS`@GY&jn#
z>=rlFhSeuV;!nFwX6se=d5n|qDQ{V21@eIW>e%O(v1nKFDVD`FFtSAlPK)TFMiCah
z*hqA`@CeKMl(~0lmG<dE%Ge+gSzbhNnQ)BO{7lm1u6i{&k>5G@WhrH84b9E@4|)x`
z;`-e$X9g=+Ec2wax+Dmp^<kHoW@eqe31p#fL10Brz99Jyri$GVLj@T-a^|T^Az5OF
zey`5cQ(oqq;xjkhP#SG0p_xL(gv;%V&F$oz*H@CgJHarIcafj+8_FGAKksnsF7O<7
z*6bg)8~-!yQeIU;M)5kPN~baLnWbt<t+Q3eBaQ(DYdaeo<cNl2JZ}XTkC)qb>=MV-
zk25n<X;7Gbm3EakSj`tZ)<;()GX6ayGvy8wNjiodtl6*j6<u7^@6HN+NNOn3;yTaF
z1Qw~+@Jz4atPN}fD=aUuroi@06-X?6RiiB}T);WO9P+uh|65i?xbk!$rw#0J%1q^c
z1>@m`!VA=UkC5c_d*h8>MY&W@+r4(CL({47IV7w_fy{%YOcj$oh_!1t()>EbjCSzw
z3`z|F+b|x>`+RmgwB<?}cThnh?BaL0xb^;bO0T99#9VqkQ1(iiX2U^Bf^1Fb)wI!5
zBNIos<w$;DjuffC^hHqhBmcurR3hUZye*hP^p-eF#WrX&BYXVt8%68ZJ2tMxo)?eS
zY8}y`qj!8XrW<tCpp#X01O%n3F<6+mHMNzAJUtk0=;DROo#}W~<FCMAxw-4@@NA#=
zf66EKT2kO79fhZOsPY|nS_RC7O=LWZ%(KzbUg;b0@Rk;iFA;$Z4&JP+9DPyUbmg90
z?Z^XCH+#PE@<}?%%IZYGHz#MWF*V5@?G2TmqtAJozOl|+%sVC8HJrP4e@>O6ix2M(
z?QE+fe~F8xe6?SZy^g`8?!5CW%d{wdBr?CCzlPA&`4fx$4uAZS9F%E4v0#p`_^NoO
zYy9Vl(XPs+#4)oG#Zg<{AGR!PeB2qeyL*tVev9{gduN@8$yslf0};F%F72)74)P3j
z^*N6(3Na|xIbSx+PH&#hW?V>c+ai=6db8dIN#BoCk<(e&gDuYywXqJ7cOc2n60Gsz
zOvl=eOLSesRmXd?WYy4zZjP-B=>ZRpM1PL94^U%~+IraxyRx;hKe9=eBZ4#4D*phl
zvl=^>?IAZc`R2n=JB~E9&FHpZP8#{{&*~T|`5ZB5bstGANO3ZO{h=xXNx#QWK;`S7
zrYx(}fw>I?E~Y~Pi>y5ev&Nnm@$k?HQ48~D55>G!y?K9R0{+M%^an{tQhayag(wzq
za~G<6%li(up<~UmGx8rmU$a$pvXz(P)(>NR{k`Zg-)!2u%$wXN2_#o{$alI!{Dz@@
z=7Z@%Vt51bBWkN%M+@ret8IL|LuP<{_(n%dfRzlDIxP&Hu0345JjdYK#KFcUWj!+h
zvVp$000s@%>-=jfU~**<K6m(=VjRe<<KxYbt*C4-(?M>5RhxHx;#=E~Xem2h35DnI
zonQHCzbb8#ph9&8NA`V*RfBh5AMKg@tjgD}G+GLsUO3L-3B!JCPxO3JDJtBUZcI8F
z?!0=VRRnSbTNPt^IGFKIY_hjuK;IO$oxWjBMMjqCAv-ciDdKGaL{yGjZ9#`8`~5Sy
zPuBeklAh!hPU7;$QBzI)dN8$}ABf6;f`qkvio7^ZUqN9g(DmhByGr1|_x3u{JulDL
z5(UbGe*c*~INqUFoLK>>JYd{D7o`%O#_H;WGIuvedpE}i(E|elVhKt3Y`4_7jMfp4
z>q=fL7-)}<k^(_oDQM8=WTDzjz{Om?&xJe0Ut9p?y|Nc!=p<%+57LxVq6omI6fgZN
z45{jKea}+E%L`X$`&C|CmP<L#`xT3!QP5NjwiJn=YS~9@R`k+vCN`ZHQ5_Ps9G#sQ
zV@2AOV~^A15+*~LsVWH`qdjxV#o!GOy|*=1vLCIrhKEN^Nx8hT)6+L=YNu}pysDB?
zPbPW-5Awr|M$zK|kOnMuuMlyu7$123d02&}ZjYlnU3M+3*NLjc>C$_dBpL(nsgrfy
z<SLJq@WyBn>xCwGXM+h#)1p<sg5)P7WtR321^MH1UTRkrP(g;6Ufo9$cFf&Z$-{<6
zd}FSQyi1abcE`!@Q#0Su?ryeQwu8I9%={V1Q*}HU0}^OszL4M5@9<k1!dY*n<{Fcn
zGgsUpf|CS20r`luMOao@-g?gosaNICuDf=lKlQMQ@1$vzy#M3ro6#O!xPNvK6PZqn
z-PPe3WH=y@^&?M|*Ew(Ev)J78+YG#4zj7$Z>#+)FXW4wL)M~ttAeK)Ik%rkXcgqtz
zzBsdDVHzt=n#xmAO7z`KtafklpBmRp6gp30f;ew{4j-3r(br;LpS|R{eUF1DZ{>V<
zOsD?D>m^+GwnoUHlsyT`p@Xpm`m0$_Ow35Nc=+$}(#wZX8Ta{oGnopOiVPcjZiVPd
zTaB7wDl)>81HL&bsLxgA#}&x6Cf`!0;sY1f*WB+IPzj`s>blxW>)C0s?$eJS)#(D7
z<AmIyKb{)WbjdiVfdm+cJHlS$Df!QoVm(#u^)f;F*0ddDIS+T_2P<P7h`6K?5Xd?>
zyE<Amfc(<u_?<<yHi;D0K?TK|*S<~O-m`>|heGx?HNlpGW&R8v@o(ySJKtsHxw~I0
zkA)HivudkbvZuukr40-ODjO++C)y_?xC!8xp&0axI_qF*wV3Vqviw_qVzajTmztQ`
z)I2_3pFg7>furoPWk6gy79x}IugvC&wj)z)6Hkuv>7O6WcEn6}#GtvTP#P>usek4`
zm$Bi6w8F=!ziTj3JQPo-C47D~xoraWM_lEdI5F0(wu?{J$=~ivOU0@=bmyIIeD5W>
zkEbTK>wwKqNTon56;8Y$_9Rr55IQt8L`X!$Ku<6JWD*td%P?^;eI~_b5frRTM?`)3
za<6d_fw1RDV0?WWb@l<r<NGA9u<pb~N2@3yeHVMWx|$7dIH600-@wBa552u|JL8>2
zOLMVqow^e8#svQjTHMFg(dkk^y-1V1<@ipirQE;(>@rD6@SLda7w_ZKCTE%x0Cj>f
zsyWd>m4o&E_~rRAGZTc^3-!GJzvPFA|CJy9SAO`vEk9rt{IC4*|EBzqT`L!JmjLFA
zv)rQ#_q^YZ(l2zMnibyuOMH+}%CP#U_~87c`j|G~eRcS~oj?A38n-i?bGOEBoaH?>
zGL`tA!HxSEb640tX%6a_^Ah|lC`H1RT_@BtFWP`1+ofc8s^JGG9VDh{`TWQZ6Z(+~
z+An3h>Wh!pJ@?jTm*8s}hl^}3-`73En|}xrbfGxGj1kYw&;uM9yLlj|e7}pgp1tyF
zi5J+%l8R&#czMoG%&xa@H#<azXU&Q*V5$gP8<`1~4f?0}usm9r>YLMo=0QpdNmFL7
zx<X1k0GWB`g(yPek8yEvU%t5gUiy)km^eMH14Ieo7Ku_?z=t>hITMIfw36=ZfCMdF
z$?Vwr!pYaz!*8-E7Iw!gRt}@H4nD`Ty7(=ah@YQ?7|wD15YVSUfJ6bLxB;*j&HkLL
z$7wTNjCI~&#~0~icceS*LgaD7-)ogzFuhpd;pwh*O*}v0I?oVLB*BFPeLgrS=pFtE
zzNFT~1ds}DpD_XedpD6@zx0j6&p}ByA;OZq>jy(+tI4M+Z`+wjAxisbzMa`}3B;J_
zR3RHOH`+5`|C9D0U<<Sd^Rp!_89a7=3^nX`G5Xbq+eUhw(_Q0TlcV2%nVrmC%fWBb
zd91K64G_R(ipipRpKPDE{X2U4j&T#wGX54O3AQKKSI64WZ|xbx{~sj?>6@PcyTfUG
zrrXqr3XQ|k0AsZ{*;s6P{O#REpcp)1<Dr`OH!pwFY>3Is`B`aE2ZDg2mP6z^2e3fT
zoZo)oUOyZXx?K*U-A>0rG$OP1i*q8LIvT|GJzl;1qoMCJhPA((0>_4FR{PjV;V8x9
z_fXa^K^G^2We}K1M{cN8+1h|Kub-c{0)0dH92_#!*_|&BhzGkSAyw66=$C;y*PPcC
zSIbLF_~bROR9|arr&fTtM==!M`CckxIi5!j180NR0l@*JLK(3tUK$GOZ+g9Jx*pDV
zAn}7S+4M|Pqixy>(7qG}7iSv*+iBnQ)SW>TNxJaV=Xl2t;99-$6OSJjF@cD0(y9aq
zrA&OTbASvz+BzlG7WRbYN`*hC@wwOm@tcyd=~4GW8^JBOA6lIe7k8k|K<meczZ74*
z)Y8oe;sjA>R;tXeV#}8T<&oNg^MeC}#U}~%oSVi8cq3fLzVo+y)|Hu<xVRVqY`_z4
z1DK5MMXuW}cDA;6!Zl_t=Ucu`R#?dp5JS;Y31PkgkA?S|O|h^X^LPv-fS&Ngd~otE
z#dG%hU^O%=uVg>TvCRzlaWjvwkk_}OqKfJx5Y;SF%+=TU4?K^gz^0i+iyharIj*jz
zCHwSfs51~Nhqj3fMkSPwA6r`L7gCmKlP&M%55|3H5Aw*Clf1O7M!Ldsr1cklcngEK
zgidtJ*(#)qv)0AN{}!#Emp}OkYv8dcepb%$$ue2sk`MsoKDvm>{Mj_+XtC0Jl;wYs
zo+Nvkloz@V$1ZBfYUfSqrRlu9%@3xucwcyW9<$qtyrX|G%Hc5ZZW?XOTQz?L@}d!_
z`v>!4-$APU>X7}HL@@pEUNf&;Ja@!<T+!3^&=U<k;H}y-xRXD5$emy9XIVa{IaP@W
zJX~CbjNk~(Q7lv$9p%0>w$vVtt8qL`o{NIZ*so$fvzry%+1YMSDnKq`w02vKoN469
zv(ZOY+tZn}ha|svAUYUuFWKl*VPSQ$kYIBuE%sEINvPAROe<R0Q`qKER&Q5SL)3Sm
z>MK#GIK|FA@_<?Vjo7>hJ^s4uBgF8&?FE!6N4P#AYKen(Sw#Q8Bbv+(8m>POOYbuT
zf&dz{xl5_xGiLk7+SIf3IPWU$oP-nS+;C067if)}aE7_Lb)ll$)>NTz*W>Pkgq}18
zNUZ+;{*a39-1xGP(1MxJ_zU>Ujl&ha{$t284FdRyeDS-UFW%Ng)y2>~8-Jlw^|W}f
zxlP3^8V8|7vXB2}W6A@zi=~tNv0h-oUP+wLgVxl_Xze{ZR#hYKhTx|K;A9+9L!?I<
zJ~`{1+SHDf7s=guA~(&UIA}W4=tvQd?2C~7vEW1jRN+6t%MgrMSj>GmQOnKoXqlpE
zCUtXmPKc`I$lym0cr5eDZw$+<v459am?{wSh6V<E!%46>uatt(Ttm-e+rc4zK=|q_
zD#ojb%Xn3177I6tG0qsW%tY&LJkC{KNUOPTnwP7IxPcC+O?U6W<b>EW`<J?`8nBST
z57gg>IwY=%R83(l+ACAF&fh?~50KEI-C(pq?k8QXAp0*JqeT?>77QMnsb_BPE@P!7
z`Lnf$8Iy!OL+`^$y*S>!*=27^^oO4x+c~+~fw)#B7`IQ*#go-$AKAI<?uN59lqF|v
zotg`ToN$2oR#{JE0xIpX!Xxv|&tD@19A}?1m`}82TqX&w$DijPF75YwiJZ*;z%yaj
zm#-+xcRY8Q+=sCJ2tm$e$>zW*`R0KJ6MIETUi0(EkDDlF)9~eFq1ZRHeAXUb<t=k_
z%I6aqqRYUy4BV8Ko)YqCOyX?o`HS{o6=N!>jM$B(_SE9~!1H-E5I`DIO}>IojIDir
z&sBj4>;HG0GV7P;;&(mj^Zboev6)67hnB$tg4s!zH^*ET9)vpI?oX0^E@<>a)FQ!Z
z%w=No^)<2+*V@=Zi<!B=oIJpJb0sv;%0%#yR*;j!N0juz!D3|<USEI7=ySHdgeOAv
zcxr!$noSKFP?01M{opDg`Wy9S%V%O?Jr-FENIdn2*KszIDPXXk+erI$fB2xF7!vl{
z)bb2e4h&+lFsomr0D4|dR*_Yf)r!(nj%&b_qaO?J2YS=R+ejdxC~AIN$p9%vm+i?r
zWcR4BEz7=DO-zj?K;4Mn(;RG$YpB5?YC6>)=&jxi1quL29(=dj`>xI8u)NOCuaWmz
z)&RXY&hqHdSN*0wh3r%jC?G;(66zExjpJ9<T=XlFMd!R++c!q8#<PI_Ybez3QLT#n
zP+S6v0^VIem&RzOd=atUEb$HP4>m!7VsZ~aE_s9)wuXjmS9NxCcXWR9u!>a_PL^%W
zTgChF`n&DaU{rUCnZ60&vodA(<gOhm(2z#z9}v<k+*}ZS*qKwgt0K9u_nE(<Z0dzW
zD?p9yg}#5;nVXZ_&$M)TwO?;JrNR2~YMBhZ_?66ZSfiI9+0?!=Iq2cxt8iOv8a*gv
z@)<3vSNjJCf`V6+Uc`bb30W&Xpwxi!52@>E370*dUeSaW00#i|7)?fr%f;G<bGlhq
z6kFQV*x2D{%k^yDZ?iK`CA2mY+wW#EUn_MuXDmwPX>0A2y+Kb{{njMs?mh3z3dY1h
zA2JE{DbDr!(L7_eTX+**CPckEGy48S!AUQ900Xsx=-5s9Wxw8x=0G5BPe6u#`zL6X
zHHNA`bMNy5Dx6+JPfMukzxI$AZ2s*#rSBu?K9?8u9rlY<w8&f2eSPn-$m9n(mEBPi
z4>yo_U<&{>ZBcqpF(U1(qob?M3l#q4Hz>|j#GnTvl>8v3j5@lH+48HPi<o>~O$iGG
zFxdEgGR!Gt!g{|IH$?OBKH)+YLqaq$`{!3iDMHy<US8$Ae@m@sqg6@Z^<2W`ehMxg
zO4#Ws^JllZQ+7wC0)iDcA`$zitfMz8%Dl`9s&TS1(_c|MDQNL|#s${+l8{vUSZ7ze
z95<1wLMM=(*q*8aAhLjGE69DAjK9#r5k{tN6ok}g3G#~fz%v#TnVDi?ig_1B0<qn5
z@%vRPs#l|l{}gxr2B!m*j(#zUq<s~lDttT-$n_MDHMsOuueOFO4QV_fak?h{{gtLS
zphC+0-I<PB;$utlweP)Wh%}~gVnGAGEh;IuK4k!HL@ZhCy#R^LSFa*MLhfckeNbG;
zQ{r)fLTcWWq@*G;2uP*+K4D|S^{`EcnxW2?5o+>pQH|mz^#AxVh=m9H5)pyDg_cho
zv&z!!@2{wS3oAIOZPIWbl!E=j!ZQdcY9WI5$#*-FqEs7ZzreOW!|ku9VDsLv*X%-j
zPmq=ZASHb$n#JVdSNlJn>~nqP)v%XZ{{r>A-yrk(7ZrlanUiR?wzbVnPrs6r!@<Ep
zNn95aAETog7#Nz)HkeTq$?uObF_M2E9RG%Ybc<tRV(!e;kx^1&L3e~eo)yZd@ZiCN
z_W2ZgQ$>(G5gTOs*N6QDjr@a3`5$xk%5=!J;XIWWFYZbw!&F&ODW4|5Y8dgUFvWJl
zX;!;XHwSH}flp6Q142WPpa1ihF9L#sH2n5AVl|3&$OT;rD=I1?BO~GP{uH09CoTZ!
zuV`xW0Z2t@R(N>NY=ei=`sSuK;NqB>nWd#WqZp*qO-J$p+%IoFFgoh8^7G5->1ljR
zthI`fzSH;VX)2t)&zzv^x(VTF62V7X6Z=~e-vR>zwY0R%`Vz&mf`dE18n)R^S36vu
z9fB-94i&#***YofYn=vnl4XDs03K3nmw<%C`Ru@g`((<liN|8-4PYkAVCKBei1vF#
zL_}MGzkyBTL7*?7j3z;yHIA#;*w_Z$`G>T(V^2Pvz_!LYJ?ov;KYm>Y42{zDn7&Wi
z6<p+MfLaF~9UX`KsU#_0Z?^aKr7M3rt9Ipdy<2n(Nmc}M{F@m(Esc(CKmV}Kb+=fr
zq4od?I^e6W16{COaA08GXv#BZ86tR*c9qNS?95K7rlw|fZEZJ#Zc0^0N2f%u0a!;V
z*(8WtpB_QzQ<e82WNbS4G;kV`;tioUHnkGLxP*|9PoiWj=Ytv2CwIwiG97eEbO9|9
z$o*#4)`_1!NrN|v^T38c@1G)1_g5Dr@XxSRr)OqB8Yu8C#>-RR&h)A5sOFzvxTJ>}
zMDx{)COg8(l%8*ZdOjcMfFJ0V@T?#sBO`qCnHonF+k%b9!C}%J6NEz<|K&?fb#(~s
z#_#1GKu(mFm6cUi9vvOU=_Tdkz(FGf1q8szVr4EYf^Q`7+H9<>@R|>#!iCRX_(0!7
zgu-lo_Vxn)VW!eX`ws>OuuTAP`uj9NS?+&0go3jEgE1?H1V@zH&bSYzO99g8(W6I<
zG$P(mZtmgP*+$dec$Mr|QQla^HhxqSQVye_o-JREd7W84McBsN9Coy&g~Bf&5P**e
zzg_B@sdH^;XrQL1e*EgQ{o?mXP%!#hQxi<Hklu3E4-9pT^0v0cd3hGkp9hWKxj5Jy
zgU|i}hX6F=QMaJW76%8%4NAn~XHMgl-h`Z*@QqsnlcQr__#F^{Xi{WkWX#oX@^*6K
z22m6VA>MlM*!uc<^@i;AyU_Eqv#_#C^ta`gx2cNJ7AAm_4#a9ubdqTh0m7H=py2oD
zZ=G1eKtfDAKsz}(88B9+mhw<0R>(8bu0cPrJ+jiSw6=KjCV)E#bpe%*g*GifP2Akv
zOifMi{!na8@_LB@vAoU#C)vSV!o|e}7l@snq~p{yne-qWZ07oN#yZ|sgFP}KEcWbh
zQv|kmV_7?gt$hmn!`-O88<e^IO;Mc-^nf^FVPyqqaiz`Fqmj&7`44|6I{&~)!1ZdM
z+8V`D=?7gn?uy;CX0&vQeCiZvyfBXs&u2qFhDegT$ZwzU-n|KtQ91q`FLZ>H&=Cdf
zoqj^F9nXNu^PKA<@cYO%22HCW>S&F}Lf8#7%rT@_-Crz8`5`In!33TVSxpj(8}aF>
zXpn9WY8_`yn{93lMyJ9@h@A#M;J#06GAzJMn<xRu@8`emmUJhat354Ou8UNM*FHv<
zmw39cU$3wtlzyP+Xvw_GdpJ~3hX>NKet!u%LOjfjzA#lfsC_pU7F_XgSj0O71p@vL
zHN^<A|BjQan4^OBLbKy1J|_br#s8)01h;#@whynD;2EL+LD9j76K<}@?2T8JNKYQB
z)UT2?@bW+NmT-Ej>GacmSwjr7Bo7c1(X}4BeIW(*FpvP@=jJ93Xbz_B?(XY*1fock
zq%%<b<Xig2u@c+gfs(SV(_iTwBv|m=)0@qpjzbPJ@D{G*e(-NF3D=B_wXds4biaS!
z(l9q!^r2`Ff_6_h_SbO%gfW*8w&iXX)anII^k=#w*3CYB=E7NG3_`p&Hdc%4To=37
z*`17u!PHu{0l)%f-b=f9n#bshXx1}PVu_QIk8toR5{Ra+NDw=FT)FWtJZT)9ZPa`I
zyxP(aeEoL_pi8P(B%<63;=KV%5XT!Q+Bz^`zn0Ku%93(;R+nL=HLM(7_8~a)z+J`l
z9PFg>BktW7mmt%tDT_wk;C*MulD$*`0Vo1y?$X!X{~KK*lQ7HYb1BaUne(oj-<d%Z
zrxAL_viTgm6eAqAg+!|LU1|O&+T>GUxYJ^(+kU!{f5Cr=Im5T_oDqO<nQbq`?iv3x
z(}wuLx}yzjD0jvaIVsh+$<9@Bq_6DybWLnZ3g5J>%Tc9i?^g6jb<{OSFveGP`45)|
zcx|_Rr6r{65O%-67b;jU<Wb^*0vi^VpJ|}pEvn;hw8(YwYo4i2v%A1)n82k6&+h$A
zA88-iEuh5ve15wBLs3$(4Au^kzPX0e|D}(hw2!y*LYCDXZ`!+8ASl<Y5YBQ3euDF|
zHwbEM?|fn(P*D;1dQ={$F9Kac6nFulR&|cci+o~ZNzC)5ys(@;k2+A_q-ftYQn6g9
zB@EKm1V+??q+Wm(0Jhx?fzxy<glm0O>|H~Zf`9eCn9it8Th(T`Q2z<xv3O<EGZ_zi
zAou04ryf1)?W*O)iQgU_pl1qH9)AK!QDAj3LJ+_}JaVGWu{g$RJpI`<{-RUGF%4i9
zI_z^qFtAU8xqHF*7+M;AerAuvXVc_rj?^f8im$L#=gTh^UX`hSzno&{>gDfP93q|7
zfp&KOedJz|bZ)OSi@LFoYWvh-FcQ`GUyzL5qR$(fY<^-qY+iif`Bq^!#jI~RLKmTQ
zitOr_RdDuVFxgTCC7@e=pJN*BwkeNL)CXvxsyFmDos@9q_U2UU*t&u7`58MAH3on_
z>cqc_p=7I7Iuw*r>#?hIb?Q3B+i|6O(9W@7pz~IFtyn=sc8B91HJ~IrRV%1Bo@^-G
z@3#BZkZoi0^o0c?$S#6+^C;=pK!mHQjtp)IqdXY5KadabWfX4-#K&(4RQ*X#Vt!5-
z$z-UsT8sY~sG-S^IM%FrXSY3|uW-AB7V=Xl_oomrYg*u?{&69gxD=>h*u@2)lI0cO
zz9D~8Ffx&`z?xD;y&*Dxk|E&x8NU~i=eydyy}cj@&K_TJxHkZlD#?a4!wOJ#KWv5}
zQY>I^u<!Uf2{pTYa{c^TfX<03TL+Tj_y4F!48_UDy^?syw(oJ|DQFz@DO{Fl&912<
z4ClX<hwj&ba!%ycrN3pYg+&6urU6l@QIyEFYU4@$dVkLx?vqw;K8V2}eRTD^M<5@R
zg6>B}^&}=zDH0KL6Ged0MZSXFZF}bU=w4}LZoT^<hLUDIEWhdcwnfjshU4+HsBm2K
z^ByR*0mMm-Q=WN4C7{CwhZ{ULkp2IV4>tBaX&|=(0Hpy+F@g_ex%1ueJb7+$fO@TO
z`vL+}gT&8#-x{Q%%9i`Xf}Ny%{$wHk7RYBiZ<>C!u#h#3nV6UY(^~4GQ5u_WnEFWs
z9IsfrikIz3Jb|}D&`tRg2l5YUqoM<7basuW)jmFa+S*oPArz1*yPO}0w9(VGwHwWk
zEJ4Yr>>rju7rQ`Y-~y;RpzC5$1`Zx?j40Xk?5{>s0=-f^0}xe;pi1<%Qa=O<h_M?)
z0H)yO8QZE?t`UDN9Rr4MsFUHL2@l(K`kkBbWEd^PUzUL2Q|{OWTXnoj&hXrPL^UIi
zbJB~71^W-#G|!0r-U7K=IU+{{a<{m!a3f@%iPqo_c=xObjE^@J{rE9ZG45e|hWW@x
z8VLgP3iH9cQ6srZUffNxyvO`r&+g3y{=7+kT~NZSS9kP-{t<|Q{T_=sJyv!ULW<JS
z8$GE{NzmSWD4Xr~2S0n{2p<{&m>zK;3O7KY0wPf0UgP)}C3pc+XwSo5?hpGGCPgjB
z|1fmvz)p$I!WQM}p4QfSAandzbyfe(l;d_uFpH93nwa6lo#{0%e$ppqym9Bjw4tHG
zZ0J4<5z*oL4e&zJF1vcW8<S-~RV&iwo2p>G%>&wTli7Nr>}7v4b!I4CeDw9ODNc8v
zG>c1#(PNf;L{vgu|HK5r%rDQgwCh3{3(LjTlymRB7IP(^)3^DtYSbfc%%F`_fW0>Z
zanY||eBpV1K9?1%Ls_b_J+HO2q;_pySJ~=yzGr)8$|mD2I^`)j<FUR!pg2F6tK<)U
z3;{&AYAL)MpFigst7man5d75C)?QlPmOlNZ@EG7j`~Yi4;$eXS-}=?5RsnXvC>dx-
z=e4mhgU+{#UY!_h-9PUsV5syPvd4>t;evyG!0cj_{$49KpA9kNDqX0z4ez6^BG9-E
zddX=46!i}@H6^e>;(zfykQn2oQ99Op*ejI!bp@r=2v%f{YsHEWvLq%0gR(>|zD*<q
zca3ZbbXwjRD$rM-9gd~z^B3s~YQ!r%v|1Y~6tmeUaNf=850FxW&XWe=?Q+^oel|if
zx~OMm&eS!TT3O))fHD5?viBJLfWYkxkdCN+A2tkqVnK3?aQI*i2_M$^HK1npXTP%x
zIl{sAbaHA;;x4zl6U~$UQ9tR@Z%hwyu(Si5(5FDa+S2(Bl;t44n)G<O8Gl0gtF?~s
zIR+62plG;=fCE5wh(`ssDANMYZ&3?5ziD@JMu|ux!DG_*k${$a;5A+al{C=-pZeM3
zPaphmewFbP><u~+g{6RcL6nq%NNZY}t9N!jHcWdWMhAXg#_&p(w_hv5QGxY2pY0>C
zZ~hyD;*J%B<sX#RgW9geYCYxRav+Ha4{v)iCpjp=p?IGSn<9wq@nb+>n~K3cL`C^U
zNA{$>OAj_k<<Pm$jXhIgH5MXmLaK9ZAMZdXnfo>RpQm(fZP}2yKi?5W$kO(4x2{DK
z3*ANwTxd--T-%vzQh+kX<g<Ygiw;68^JDoM?HwDI`2!rXHShyZH(pA~OBRb8y!$`J
CkS1&Z

diff --git a/doc/overview.uml b/doc/overview.uml
index d35d6ba..0d3c6cc 100644
--- a/doc/overview.uml
+++ b/doc/overview.uml
@@ -2,11 +2,7 @@
 class Repository {
   hashing_algorithm : Blake2(N) | SHA-1
   encoding: Base32
-  id_generator: UUIDv4
-  version: 1
-}
-class Item {
-  id : repository.id_generator::type
+  version: 2
 }
 class Record {
   hash : repository.hashing_algorithm::type
@@ -15,7 +11,6 @@ class File {
   name : String
   content : Binary
 }
-Repository "1" --> "many" Item: contains
-Item "1" --> "many" Record: contains
+Repository "1" --> "many" Record: contains
 Record "1" --> "many" File: contains
 @enduml
diff --git a/sit-core/Cargo.toml b/sit-core/Cargo.toml
index f09b1b1..65af5bc 100644
--- a/sit-core/Cargo.toml
+++ b/sit-core/Cargo.toml
@@ -19,6 +19,8 @@ data-encoding = "2.1"
 data-encoding-macro = "0.1"
 glob = "0.2"
 lazy_static = "1.0"
+itertools = "0.7"
+walkdir = "2"
 blake2 = { version = "0.7", optional = true }
 sha-1 = { version = "0.7", optional = true }
 uuid = { version = "0.5", features = ["v4"], optional = true }
@@ -37,10 +39,11 @@ cc = "1.0"
 include_dir = "0.1.5"
 
 [features]
-default = ["blake2", "sha-1", "uuid", "duktape-reducers", "duktape-mmap", "duktape-require"]
+default = ["blake2", "sha-1", "uuid", "duktape-reducers", "duktape-mmap", "duktape-require", "deprecated-item-api"]
 duktape-require = []
 duktape-reducers = ["duktape", "cesu8"]
 duktape = []
 duktape-mmap = ["memmap"]
 windows7 = []
 git = ["git2"]
+deprecated-item-api = []
diff --git a/sit-core/src/hash.rs b/sit-core/src/hash.rs
index d3b0a0e..29c903f 100644
--- a/sit-core/src/hash.rs
+++ b/sit-core/src/hash.rs
@@ -112,6 +112,16 @@ impl HashingAlgorithm {
         }
     }
 
+    /// Returns the output length of the hash
+    pub fn len(&self) -> usize {
+        match self {
+            #[cfg(feature = "blake2")]
+            &HashingAlgorithm::Blake2b { size } => size,
+            #[cfg(feature = "sha-1")]
+            &HashingAlgorithm::SHA1 => 20,
+        }
+    }
+
 }
 
 #[cfg(test)]
diff --git a/sit-core/src/item.rs b/sit-core/src/item.rs
index d3d5adf..a30151f 100644
--- a/sit-core/src/item.rs
+++ b/sit-core/src/item.rs
@@ -2,58 +2,21 @@
 
 use serde_json::{Map, Value};
 
-use super::Reducer;
-use record::{File, OrderedFiles};
-
-#[derive(Debug, Error)]
-pub enum ReductionError<Err: ::std::error::Error + ::std::fmt::Debug> {
-    ImplementationError(Err)
-}
+use record::{RecordOwningContainer, RecordContainerReduction};
 
 /// Because of SIT's extensible nature, item can
 /// be used to represent a wild variety of entities, such
 /// as issue, documents, accounts, etc.
-pub trait Item: Sized {
-    /// Error type used by the implementation
-    type Error: ::std::error::Error + ::std::fmt::Debug;
-    /// Record type used by the implementation
-    type Record : super::Record;
-    /// Type used to list records that can be referenced as a slice of records
-    type Records : IntoIterator<Item=Self::Record>;
-    /// Iterator over lists of records
-    type RecordIter : Iterator<Item=Self::Records>;
-    /// Issue must have an ID, ideally human-readable
+pub trait Item: RecordOwningContainer {
+    /// Item must have an ID, ideally human-readable
     fn id(&self) -> &str;
-    /// Iterates through the tree of records
-    fn record_iter(&self) -> Result<Self::RecordIter, Self::Error>;
-    /// Creates and returns a new record.
-    ///
-    /// Will reference all dangling records as its parent, unless
-    /// `link_parents` is set to `false`
-    fn new_record<'f, F: File + 'f, I: Into<OrderedFiles<'f, F>>>(&self, files: I, link_parents: bool)
-       -> Result<Self::Record, Self::Error> where F::Read: 'f;
 }
 
-/// [`Issue`] trait extension that defines and implements default reduction algorithms
-///
-/// [`Issue`]: trait.Issue.html
-pub trait ItemReduction: Item {
 
-    /// Reduces item with a given [`Reducer`]
-    ///
-    /// Will insert item's `id` into the initial state
-    ///
-    /// [`Reducer`]: ../reducers/trait.Reducer.html
-    fn reduce_with_reducer<R: Reducer<State=Map<String, Value>, Item=Self::Record>>(&self, reducer: &mut R) -> Result<Map<String, Value>, ReductionError<Self::Error>> {
-        let records = self.record_iter()?;
-        let mut state: Map<String, Value> = Default::default();
+impl<T> RecordContainerReduction for T where T: Item {
+    fn initialize_state(&self, mut state: Map<String, Value>) -> Map<String, Value> {
         state.insert("id".into(), Value::String(self.id().into()));
-        Ok(records.fold(state, |acc, recs|
-            recs.into_iter().fold(acc, |acc, rec| reducer.reduce(acc, &rec))))
+        state
     }
-
-
 }
 
-impl<T> ItemReduction for T where T: Item {}
-
diff --git a/sit-core/src/lib.rs b/sit-core/src/lib.rs
index a53b8e3..7b47a6b 100644
--- a/sit-core/src/lib.rs
+++ b/sit-core/src/lib.rs
@@ -38,6 +38,9 @@ extern crate digest;
 
 extern crate relative_path;
 
+extern crate itertools;
+extern crate walkdir;
+
 // Crates necessary for testing
 #[cfg(test)] #[macro_use] extern crate assert_matches;
 #[cfg(test)] #[macro_use] extern crate proptest;
@@ -46,9 +49,12 @@ extern crate relative_path;
 pub mod path;
 pub mod hash;
 pub mod encoding;
+#[cfg(feature = "deprecated-item-api")]
 pub mod id;
 pub mod repository;
+#[cfg(feature = "deprecated-item-api")]
 pub mod item;
+#[cfg(feature = "deprecated-item-api")]
 pub use item::Item;
 pub mod record;
 pub use record::Record;
diff --git a/sit-core/src/record.rs b/sit-core/src/record.rs
index 8424e5d..e8e43ec 100644
--- a/sit-core/src/record.rs
+++ b/sit-core/src/record.rs
@@ -1,7 +1,8 @@
 //! Record is an immutable collection of files
 
 use std::io::{self, Read};
-use hash::Hasher;
+use hash::{Hasher, HashingAlgorithm};
+use std::path::PathBuf;
 
 /// Record's file
 ///
@@ -240,6 +241,16 @@ mod ordered_files_tests {
     }
 }
 
+/// Returns string split by `length` characters
+pub(crate) fn split_path<S: AsRef<str>>(s: S, length: usize) -> PathBuf {
+    use itertools::Itertools;
+    let mut path = s.as_ref().chars().chunks(length).into_iter()
+        .fold(PathBuf::new(), |acc, chunk| acc.join(chunk.into_iter().collect::<String>()));
+
+    path.pop();
+    path.join(s.as_ref())
+}
+
 /// Record is an immutable collection of files
 pub trait Record {
    /// Implementation's type for reading files
@@ -261,13 +272,112 @@ pub trait Record {
    /// [`hash`]: struct.Record.html#hash
    fn encoded_hash(&self) -> Self::Str;
 
+   /// Returns encoded record hash path split by `length` characters
+   fn split_path(&self, length: usize) -> PathBuf {
+       split_path(self.encoded_hash(), length)
+   }
+
    /// Returns enclosing item's ID
+   #[cfg(feature = "deprecated-item-api")]
    fn item_id(&self) -> Self::Str;
 
    /// Returns an iterator over files in the record
    fn file_iter(&self) -> Self::Iter;
+
+   /// Returns true if the integrity of the record is intact
+   fn integrity_intact(&self, hashing_algorithm: &HashingAlgorithm) -> bool {
+       let mut hasher = hashing_algorithm.hasher();
+       let ordered_files = OrderedFiles::from(self.file_iter());
+       match ordered_files.hash(&mut *hasher) {
+           Ok(_) => {
+               let hash = hasher.result_box();
+               self.hash().as_ref() == hash.as_slice()
+           },
+           _ => {
+               false
+           }
+       }
+   }
+}
+
+pub trait RecordContainer {
+    /// Error type used by the implementation
+    type Error: ::std::error::Error + ::std::fmt::Debug;
+    /// Record type used by the implementation
+    type Record : super::Record;
+    /// Type used to list records that can be referenced as a slice of records
+    type Records : IntoIterator<Item=Self::Record>;
+    /// Iterator over lists of records
+    type Iter : Iterator<Item=Self::Records>;
+    /// Iterates through the tree of records
+    fn record_iter(&self) -> Result<Self::Iter, Self::Error>;
+
+    fn fixed_roots<S: Into<String>, I: IntoIterator<Item = S>>(&self, roots: I) -> 
+        FixedRootsRecordContainer<Self> where Self: Sized {
+        FixedRootsRecordContainer {
+            container: self,
+            roots: roots.into_iter().map(|s| s.into()).collect(),
+        }
+    }
+}
+
+pub struct FixedRootsRecordContainer<'a, RC: RecordContainer + 'a> {
+    container: &'a RC,
+    roots: Vec<String>,
 }
 
+impl<'a, RC: RecordContainer + 'a> RecordContainer for FixedRootsRecordContainer<'a, RC> {
+    type Error = RC::Error;
+    type Record = RC::Record;
+    type Records = Vec<RC::Record>;
+    type Iter = FixedRootsRecordIterator<RC>;
+
+    fn record_iter(&self) -> Result<Self::Iter, Self::Error> {
+        Ok(FixedRootsRecordIterator { 
+            iter: self.container.record_iter()?,
+            known: vec![],
+            roots: self.roots.clone(),
+        })
+    }
+}
+
+pub struct FixedRootsRecordIterator<RC: RecordContainer> {
+    iter: RC::Iter,
+    known: Vec<String>,
+    roots: Vec<String>, 
+}
+
+impl<RC: RecordContainer> Iterator for FixedRootsRecordIterator<RC> {
+
+    type Item = Vec<RC::Record>;
+
+    fn next(&mut self) -> Option<Self::Item> {
+        match self.iter.next() {
+            None => None,
+            Some(value) => {
+                let records: Vec<_> = value.into_iter()
+                    .filter(|record| 
+                            self.roots.iter().any(|root| root == record.encoded_hash().as_ref()) ||
+                            record.file_iter().filter(|&(ref name, _)| name.as_ref().starts_with(".prev/"))
+                            .any(|(name, _)| self.known.iter().any(|known| known == &name.as_ref()[6..])))
+                    .collect();
+                for r in records.iter() {
+                    self.known.push(r.encoded_hash().as_ref().into());
+                }
+                Some(records)
+            }
+        }
+    }
+}
+
+pub trait RecordOwningContainer: RecordContainer {
+    /// Creates and returns a new record.
+    ///
+    /// Will reference all dangling records as its parent, unless
+    /// `link_parents` is set to `false`
+    fn new_record<'f, F: File + 'f, I: Into<OrderedFiles<'f, F>>>(&self, files: I, link_parents: bool)
+       -> Result<Self::Record, Self::Error> where F::Read: 'f;
+}
 
 use serde_json::{Value as JsonValue, Map as JsonMap};
 use serde::Serializer;
@@ -326,4 +436,40 @@ pub trait RecordExt: Record {
 
 }
 
-impl<T> RecordExt for T where T: Record {}
\ No newline at end of file
+impl<T> RecordExt for T where T: Record {}
+
+use reducers::Reducer;
+#[derive(Debug, Error)]
+pub enum ReductionError<Err: ::std::error::Error + ::std::fmt::Debug> {
+    ImplementationError(Err)
+}
+
+/// Default reduction algorithm
+///
+pub trait RecordContainerReduction: RecordContainer {
+
+    fn initialize_state(&self, state: JsonMap<String, JsonValue>) -> JsonMap<String, JsonValue> {
+        state
+    }
+
+    /// Reduces item with a given [`Reducer`]
+    ///
+    /// [`Reducer`]: ../reducers/trait.Reducer.html
+    fn reduce_with_reducer<R: Reducer<State=JsonMap<String, JsonValue>, Item=Self::Record>>(&self, reducer: &mut R) -> Result<JsonMap<String, JsonValue>, ReductionError<Self::Error>> {
+        let state: JsonMap<String, JsonValue> = Default::default();
+        let state = self.initialize_state(state);
+        self.reduce_with_reducer_and_state(reducer, state)
+    }
+
+    /// Reduces item with a given [`Reducer`] and state
+    ///
+    /// [`Reducer`]: ../reducers/trait.Reducer.html
+    fn reduce_with_reducer_and_state<R: Reducer<State=JsonMap<String, JsonValue>, Item=Self::Record>>(&self, reducer: &mut R, state: JsonMap<String, JsonValue>) -> Result<JsonMap<String, JsonValue>, ReductionError<Self::Error>> {
+        let records = self.record_iter()?;
+        Ok(records.fold(state, |acc, recs|
+            recs.into_iter().fold(acc, |acc, rec| reducer.reduce(acc, &rec))))
+    }
+
+}
+
+impl<'a, RC> RecordContainerReduction for FixedRootsRecordContainer<'a, RC> where RC: RecordContainer {}
diff --git a/sit-core/src/reducers/duktape.rs b/sit-core/src/reducers/duktape.rs
index 57f2983..dda89a7 100644
--- a/sit-core/src/reducers/duktape.rs
+++ b/sit-core/src/reducers/duktape.rs
@@ -7,8 +7,9 @@ use ::Record;
 use duktape;
 use std::ptr;
 use std::ffi::{CString, CStr, OsStr};
-use std::path::PathBuf;
+use std::path::{Path, PathBuf};
 use std::fs;
+use std::io;
 use path::HasPath;
 
 #[cfg(feature = "duktape-mmap")]
@@ -17,9 +18,46 @@ use memmap;
 #[cfg(feature = "cesu8")]
 use cesu8;
 
+pub trait SourceFiles {
+    type Iter : Iterator<Item = PathBuf>;
+
+    fn source_files(self) -> Result<Self::Iter, Error>;
+}
+
+impl<T> SourceFiles for T where T: IntoIterator<Item = PathBuf> {
+    type Iter = T::IntoIter;
+
+    fn source_files(self) -> Result<Self::Iter, Error> {
+        Ok(self.into_iter())
+    }
+}
+
+impl<'a, MI> SourceFiles for &'a ::Repository<MI> where MI: ::repository::ModuleIterator<PathBuf, ::repository::Error> {
+
+    type Iter = ::std::vec::IntoIter<PathBuf>;
+
+    fn source_files(self) -> Result<Self::Iter, Error> {
+        let mut files = vec![];
+
+        let reducers_path = self.path().join("reducers");
+        if reducers_path.is_dir() {
+            files.push(reducers_path);
+        }
+
+        for module_name in self.module_iter()? {
+            let module_name = module_name?;
+            let path = self.modules_path().join(module_name).join("reducers");
+            if path.is_dir() {
+                files.push(path);
+            }
+        }
+
+        Ok(files.into_iter())
+    }
+}
+
 #[derive(Debug)]
-pub struct DuktapeReducer<'a, R: Record, MI: 'a> {
-    repository: &'a ::Repository<MI>,
+pub struct DuktapeReducer<R: Record> {
     context: *mut duktape::duk_context,
     reducers: i32,
     filenames: Vec<PathBuf>,
@@ -27,7 +65,7 @@ pub struct DuktapeReducer<'a, R: Record, MI: 'a> {
     functions: Vec<Vec<u8>>,
 }
 
-unsafe impl<'a, R: Record, MI: 'a> Send for DuktapeReducer<'a, R, MI> {}
+unsafe impl<R: Record> Send for DuktapeReducer<R> {}
 
 #[derive(Debug, Error)]
 pub enum Error {
@@ -44,7 +82,7 @@ pub enum Error {
     },
 }
 
-impl<'a, R: Record, MI: 'a> Drop for DuktapeReducer<'a, R, MI> {
+impl<R: Record> Drop for DuktapeReducer<R> {
     fn drop(&mut self) {
         unsafe {
             duktape::duk_destroy_heap(self.context);
@@ -56,7 +94,7 @@ unsafe extern "C" fn fatal_handler(_udata: *mut ::std::os::raw::c_void, msg: *co
     ::std::process::exit(1);
 }
 
-impl<'a, R: Record, MI: 'a> DuktapeReducer<'a, R, MI> {
+impl<R: Record> DuktapeReducer<R> {
 
     unsafe fn load_module(context: *mut duktape::duk_hthread) -> Result<(), Error> {
         // Now, execute the function with a defined module
@@ -162,13 +200,11 @@ impl<'a, R: Record, MI: 'a> DuktapeReducer<'a, R, MI> {
     }
 }
 
-impl<'a, R: Record, MI: 'a> DuktapeReducer<'a, R, MI>
-    where MI: ::repository::ModuleIterator<PathBuf, ::repository::Error> {
-    pub fn new(repository: &'a ::Repository<MI>) -> Result<Self, Error> {
+impl<R: Record> DuktapeReducer<R> {
+    pub fn new<SF: SourceFiles>(source_files: SF) -> Result<Self, Error> {
         let context = unsafe {
             duktape::duk_create_heap(None, None, None,ptr::null_mut(), Some(fatal_handler))
         };
-        let reducers_path = repository.path().join("reducers");
         #[cfg(feature = "duktape-require")]
         let str_duktape = CString::new("Duktape").unwrap();
         #[cfg(feature = "duktape-require")]
@@ -177,57 +213,35 @@ impl<'a, R: Record, MI: 'a> DuktapeReducer<'a, R, MI>
             duktape::duk_module_duktape_init(context);
             duktape::duk_get_global_string(context, str_duktape.as_ptr());
             // function
-            duktape::duk_push_c_function(context, Some(DuktapeReducer::<'a, R, MI>::mod_search), 4);
+            duktape::duk_push_c_function(context, Some(DuktapeReducer::<R>::mod_search), 4);
             duktape::duk_put_prop_string(context, -2, str_mod_search.as_ptr());
             duktape::duk_pop(context);
         }
-        // If REPO/reducers not found, skip reading it as it would result in an I/O error
-        let mut files: Box<Iterator<Item = Result<fs::DirEntry, ::std::io::Error>>> = if reducers_path.is_dir() {
-            Box::new(fs::read_dir(reducers_path)?)
-        } else {
-            Box::new(vec![].into_iter())
-        };
-
 
         #[cfg(feature = "duktape-require")]
         let mut paths_counter = 0;
-        #[cfg(feature = "duktape-require")] {
+        #[cfg(feature = "duktape-require")] 
+        let paths_array = {
             let str_paths_prop = CString::new("paths").unwrap();
             unsafe {
                 duktape::duk_get_global_string(context, str_duktape.as_ptr());
                 duktape::duk_push_string(context, str_paths_prop.as_ptr());
                 duktape::duk_push_array(context);
-                let path = repository.path().join("reducers");
-                let str_path = CString::new(path.to_str().unwrap()).unwrap();
-                duktape::duk_push_string(context, str_path.as_ptr());
-                duktape::duk_put_prop_index(context, -2, paths_counter);
-            }
-        }
-        for module_name in repository.module_iter()? {
-            let module_name = module_name?;
-            let path = repository.modules_path().join(module_name).join("reducers");
-            if path.is_dir() {
-                #[cfg(feature = "duktape-require")] {
-                    let str_path = CString::new(path.to_str().unwrap()).unwrap();
-                    unsafe {
-                        duktape::duk_push_string(context, str_path.as_ptr());
-                        duktape::duk_put_prop_index(context, -2, paths_counter);
-                    }
-                    paths_counter += 1;
-                }
-                files = Box::new(files.chain(fs::read_dir(path)?));
+                let ptr = duktape::duk_get_heapptr(context, -1);
+                duktape::duk_def_prop(context, -3, duktape::DUK_DEFPROP_HAVE_VALUE);
+                duktape::duk_pop(context);
+                ptr
             }
-        }
-        #[cfg(feature = "duktape-require")] unsafe {
-            duktape::duk_def_prop(context, -3, duktape::DUK_DEFPROP_HAVE_VALUE);
-            duktape::duk_pop(context);
-        }
+        };
+        
+
+        #[cfg(feature = "duktape-require")]
+        let mut directories = vec![];
 
         let mut reducers = 0;
         let mut filenames = vec![];
         let mut functions = vec![];
-        let files = files.filter(Result::is_ok).map(Result::unwrap).map(|e| e.path())
-            .filter(|f| f.extension() == Some(OsStr::new("js")));
+        let files = source_files.source_files()?;
         // in test builds, we guarantee the order of files, but not in other builds as
         // it is not a great idea to rely on the order of these files
         #[cfg(test)]
@@ -235,67 +249,46 @@ impl<'a, R: Record, MI: 'a> DuktapeReducer<'a, R, MI>
         #[cfg(test)]
         files.sort();
         for file in files {
-            reducers += 1;
-            unsafe {
-                // source code
-                let mut source = String::new();
-                let mut f = fs::File::open(&file)?;
-                let _ = f.read_to_string(&mut source)?;
-                // prepare the module function
-                source = format!("function (module) {{ {} }}", source);
-                let source = CString::new(source).unwrap();
-                duktape::duk_push_string(context, source.as_ptr());
-
-                // file name
-                filenames.push(file.clone());
-                let src_file = CString::new(String::from(file.to_str().unwrap())).unwrap();
-                duktape::duk_push_string(context, src_file.as_ptr());
-
-                // compile
-                let res = duktape::duk_compile_raw(context, ptr::null_mut(), 0,
-                                         duktape::DUK_COMPILE_SAFE |
-                                         duktape::DUK_COMPILE_FUNCTION | duktape::DUK_COMPILE_STRLEN);
-
-                if res as u32 == duktape::DUK_EXEC_ERROR {
-                    let err = ::std::ffi::CStr::from_ptr(duktape::duk_safe_to_lstring(context, -1, ptr::null_mut())).to_str().unwrap();
-                    return Err(Error::CompileError { file, error: err.into() })
+            #[cfg(feature = "duktape-require")] {
+                let path = if !file.is_dir() {
+                    file.parent().unwrap_or(Path::new("/")).to_path_buf()
                 } else {
-                    // clean up safe compilation results
-                    // . . f
-                    duktape::duk_swap_top(context, -2);
-                    // . f .
-                    duktape::duk_swap(context, -3, -2);
-                    // f . .
-                    duktape::duk_pop_2(context);
-                    // f
-                    // save bytecode
-                    duktape::duk_dup_top(context);
-                    duktape::duk_dump_function(context);
-                    let mut sz = 0;
-                    let data = duktape::duk_get_buffer(context, -1, &mut sz);
-                    let mut func = vec![0; sz];
-                    ptr::copy_nonoverlapping(data, func.as_mut_ptr() as *mut _, sz);
-                    functions.push(func);
-                    duktape::duk_pop(context);
-                    // load module
-                    DuktapeReducer::<'a, R, MI>::load_module(context)?;
-                    // If module.export is not function, bail
-                    if duktape::duk_is_function(context, -1) != 1 {
-                        return Err(Error::CompileError {
-                            file,
-                            error: "module.exports should export a function".into(),
-                        })
+                    file.clone()
+                };
+                if !directories.iter().any(|d| d == &path) {
+                    directories.push(path);
+                    let str_path = CString::new(directories.last().unwrap().to_str().unwrap()).unwrap();
+                    unsafe {
+                        duktape::duk_push_heapptr(context, paths_array);
+                        duktape::duk_push_string(context, str_path.as_ptr());
+                        duktape::duk_put_prop_index(context, -2, paths_counter);
+                        duktape::duk_pop(context);
                     }
+                    paths_counter += 1;
                 }
+            }
 
-                // create reducer's state
-                duktape::duk_push_object(context);
-                duktape::duk_require_function(context, -2);
-                duktape::duk_require_object(context, -1);
+            if file.is_file() {
+                filenames.push(file.clone());
+                functions.push(unsafe { DuktapeReducer::<R>::load_source(file, context)? });
+                reducers += 1;
+            } else if file.is_dir() {
+                let js_ext = Some(OsStr::new("js"));
+                for entry in fs::read_dir(file)?.filter_map(Result::ok) {
+                    let file = entry.path();
+                    if file.extension() == js_ext {
+                        filenames.push(file);
+                        functions.push(unsafe { DuktapeReducer::<R>::load_source(entry.path(), context)? });
+                        reducers += 1;
+                    } 
+                }
+            } else {
+                let err: io::Error = io::ErrorKind::NotFound.into();
+                return Err(err.into());
             }
-        }
+
+       }
         Ok(DuktapeReducer {
-            repository,
             context,
             reducers,
             filenames,
@@ -304,6 +297,63 @@ impl<'a, R: Record, MI: 'a> DuktapeReducer<'a, R, MI>
         })
     }
 
+    unsafe fn load_source(file: PathBuf, context: *mut duktape::duk_context) -> Result<Vec<u8>, Error> {
+        let mut func = vec![];
+        // source code
+        let mut source = String::new();
+        let mut f = fs::File::open(&file)?;
+        let _ = f.read_to_string(&mut source)?;
+        // prepare the module function
+        source = format!("function (module) {{ {} }}", source);
+        let source = CString::new(source).unwrap();
+        duktape::duk_push_string(context, source.as_ptr());
+
+        let src_file = CString::new(String::from(file.to_str().unwrap())).unwrap();
+        duktape::duk_push_string(context, src_file.as_ptr());
+
+        // compile
+        let res = duktape::duk_compile_raw(context, ptr::null_mut(), 0,
+        duktape::DUK_COMPILE_SAFE |
+        duktape::DUK_COMPILE_FUNCTION | duktape::DUK_COMPILE_STRLEN);
+
+        if res as u32 == duktape::DUK_EXEC_ERROR {
+            let err = ::std::ffi::CStr::from_ptr(duktape::duk_safe_to_lstring(context, -1, ptr::null_mut())).to_str().unwrap();
+            return Err(Error::CompileError { file, error: err.into() })
+        } else {
+            // clean up safe compilation results
+            // . . f
+            duktape::duk_swap_top(context, -2);
+            // . f .
+            duktape::duk_swap(context, -3, -2);
+            // f . .
+            duktape::duk_pop_2(context);
+            // f
+            // save bytecode
+            duktape::duk_dup_top(context);
+            duktape::duk_dump_function(context);
+            let mut sz = 0;
+            let data = duktape::duk_get_buffer(context, -1, &mut sz);
+            func.resize(sz, 0);
+            ptr::copy_nonoverlapping(data, func.as_mut_ptr() as *mut _, sz);
+            duktape::duk_pop(context);
+            // load module
+            DuktapeReducer::<R>::load_module(context)?;
+            // If module.export is not function, bail
+            if duktape::duk_is_function(context, -1) != 1 {
+                return Err(Error::CompileError {
+                    file,
+                    error: "module.exports should export a function".into(),
+                })
+            }
+        }
+
+        // create reducer's state
+        duktape::duk_push_object(context);
+        duktape::duk_require_function(context, -2);
+        duktape::duk_require_object(context, -1);
+        Ok(func)
+    }
+
     /// Resets every reducer's state back to an empty object
     ///
     /// Very useful for re-using the same set of reducers for
@@ -322,7 +372,7 @@ impl<'a, R: Record, MI: 'a> DuktapeReducer<'a, R, MI>
 
 }
 
-impl<'a, R: Record, MI: 'a> Clone for DuktapeReducer<'a, R, MI> {
+impl<R: Record> Clone for DuktapeReducer<R> {
     fn clone(&self) -> Self {
         let context = unsafe {
             duktape::duk_create_heap(None, None, None,ptr::null_mut(), Some(fatal_handler))
@@ -335,7 +385,7 @@ impl<'a, R: Record, MI: 'a> Clone for DuktapeReducer<'a, R, MI> {
                 duktape::duk_config_buffer(context, -1, func.as_ptr() as *mut _, func.len());
                 duktape::duk_load_function(context);
                 // obtain the module
-                DuktapeReducer::<'a, R, MI>::load_module(context).unwrap(); // since it's a clone we assume the first load went fine
+                DuktapeReducer::<R>::load_module(context).unwrap(); // since it's a clone we assume the first load went fine
                 // transfer state
                 duktape::duk_push_null(self.context);
                 duktape::duk_copy(self.context, (i * 2 + 1) as i32, -1);
@@ -347,7 +397,6 @@ impl<'a, R: Record, MI: 'a> Clone for DuktapeReducer<'a, R, MI> {
             }
         }
         DuktapeReducer {
-            repository: self.repository,
             context,
             reducers: self.reducers,
             filenames: self.filenames.clone(),
@@ -358,7 +407,7 @@ impl<'a, R: Record, MI: 'a> Clone for DuktapeReducer<'a, R, MI> {
 }
 
 
-impl<'a, R: Record, MI: 'a> Reducer for DuktapeReducer<'a, R, MI> {
+impl<R: Record + HasPath> Reducer for DuktapeReducer<R> {
     type State = Map<String, JsonValue>;
     type Item = R;
 
@@ -396,10 +445,7 @@ impl<'a, R: Record, MI: 'a> Reducer for DuktapeReducer<'a, R, MI> {
                     #[cfg(not(windows))]
                     let name = name.as_ref();
 
-                    let path = self.repository.items_path()
-                        .join(item.item_id().as_ref())
-                        .join(item.encoded_hash().as_ref())
-                        .join(name);
+                    let path = item.path().join(name);
 
                     if fs::metadata(&path).unwrap().len() == 0 {
                         // if the file is empty, it can't be mmapped
@@ -517,7 +563,7 @@ mod tests {
     use tempdir::TempDir;
     use super::*;
     use ::Repository;
-    use item::{Item, ItemReduction};
+    use record::{RecordOwningContainer, RecordContainerReduction};
     use path::HasPath;
 
     #[test]
@@ -533,9 +579,8 @@ mod tests {
         let mut f = fs::File::create(repo.path().join("reducers/1.js")).unwrap();
         f.write(b"module.exports = function(state, record) { return {test: true} }").unwrap();
 
-        let item = repo.new_item().unwrap();
-        let _record = item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        let _record = repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         assert_eq!(state.get("test").unwrap(), &JsonValue::Bool(true));
     }
@@ -551,11 +596,10 @@ mod tests {
         let mut f = fs::File::create(repo.path().join("reducers/reducer.js")).unwrap();
         f.write(b"module.exports = function(state, record) { return 1 }").unwrap();
 
-        let item = repo.new_item().unwrap();
-        let _record = item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        let _record = repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
-            assert!(state.get("errors").is_some());
+        assert!(state.get("errors").is_some());
         let errors = state.get("errors").unwrap().as_array().unwrap();
         assert_eq!(errors[0].as_object().unwrap().get("error").unwrap(), &JsonValue::String("TypeError: invalid return value 1, expected an object".into()));
         assert_eq!(errors[0].as_object().unwrap().get("file").unwrap(), &JsonValue::String(repo.path().join("reducers").join("reducer.js").to_str().unwrap().into()));
@@ -573,9 +617,8 @@ mod tests {
         let mut f = fs::File::create(repo.path().join("reducers/reducer.js")).unwrap();
         f.write(b"module.exports = function(state, record) { return {\"hello\": record.hash}; }").unwrap();
 
-        let item = repo.new_item().unwrap();
-        let record = item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        let record = repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         assert_eq!(state.get("hello").unwrap(), &JsonValue::String(record.encoded_hash()));
     }
@@ -591,6 +634,23 @@ mod tests {
         let mut f = fs::File::create(repo.path().join("reducers/reducer.js")).unwrap();
         f.write(b"module.exports = function(state, record) { return {\"hello\": new TextDecoder('utf-8').decode(record.files.text)}; }").unwrap();
 
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+
+        assert_eq!(state.get("hello").unwrap(), &JsonValue::String("Title".into()));
+    }
+
+    #[test]
+    #[cfg(feature = "deprecated-item-api")]
+    fn record_contents_item() {
+        let mut tmp = TempDir::new("sit").unwrap().into_path();
+        tmp.push(".sit");
+        let repo = Repository::new(tmp).unwrap();
+        use std::fs;
+        use std::io::Write;
+        fs::create_dir_all(repo.path().join("reducers")).unwrap();
+        let mut f = fs::File::create(repo.path().join("reducers/reducer.js")).unwrap();
+        f.write(b"module.exports = function(state, record) { return {\"hello\": new TextDecoder('utf-8').decode(record.files.text)}; }").unwrap();
         let item = repo.new_item().unwrap();
         item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
         let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
@@ -617,14 +677,12 @@ mod tests {
          return {\"hello\": this.counter}; \
          }").unwrap();
 
-        let item = repo.new_item().unwrap();
+        // create three records
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
 
-        // create two records
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         use serde_json::Number;
         assert_eq!(state.get("hello").unwrap(), &JsonValue::Number(Number::from(3)));
@@ -643,9 +701,8 @@ mod tests {
         let mut f = fs::File::create(repo.path().join("reducers/reducer2.js")).unwrap();
         f.write(b"module.exports = function(state) { return Object.assign({\"bye\": 2}, state); }").unwrap();
 
-        let item = repo.new_item().unwrap();
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         use serde_json::Number;
         assert_eq!(state.get("hello").unwrap(), &JsonValue::Number(Number::from(1)));
@@ -666,9 +723,8 @@ mod tests {
         let mut f = fs::File::create(repo.path().join("modules/test/reducers/reducer2.js")).unwrap();
         f.write(b"module.exports = function(state) { return Object.assign({\"bye\": 2}, state); }").unwrap();
 
-        let item = repo.new_item().unwrap();
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         use serde_json::Number;
         assert_eq!(state.get("hello").unwrap(), &JsonValue::Number(Number::from(1)));
@@ -686,7 +742,7 @@ mod tests {
         fs::create_dir_all(repo.path().join("reducers")).unwrap();
         let mut f = fs::File::create(repo.path().join("reducers/reducer.js")).unwrap();
         f.write(b"module.exports = 'hello'").unwrap();
-        let res = DuktapeReducer::<::repository::Record<::repository::ModuleDirectory<PathBuf>>, ::repository::ModuleDirectory<PathBuf>>::new(&repo);
+        let res: Result<DuktapeReducer<::repository::Record>, _> = DuktapeReducer::new(&repo);
         assert!(res.is_err());
         let reducer_file = repo.path().join("reducers/reducer.js");
         let err = res.unwrap_err();
@@ -712,9 +768,8 @@ mod tests {
         let mut f = fs::File::create(repo.path().join("reducers/reducer1.js")).unwrap();
         f.write(b"module.exports = function(state) { return Object.assign({\"hello\": module.exports.data}, state); }; module.exports.data = 1;").unwrap();
 
-        let item = repo.new_item().unwrap();
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         use serde_json::Number;
         assert_eq!(state.get("hello").unwrap(), &JsonValue::Number(Number::from(1)));
@@ -731,9 +786,8 @@ mod tests {
         let mut f = fs::File::create(repo.path().join("reducers/reducer1.js")).unwrap();
         f.write(b"var a = 1; module.exports = function(state) { return Object.assign({\"hello\": a}, state); };").unwrap();
 
-        let item = repo.new_item().unwrap();
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         use serde_json::Number;
         assert_eq!(state.get("hello").unwrap(), &JsonValue::Number(Number::from(1)));
@@ -750,7 +804,7 @@ mod tests {
         fs::create_dir_all(repo.path().join("reducers")).unwrap();
         let mut f = fs::File::create(repo.path().join("reducers/reducer.js")).unwrap();
         f.write(b"function(state) { return state }").unwrap();
-        let res = DuktapeReducer::<::repository::Record<::repository::ModuleDirectory<PathBuf>>, ::repository::ModuleDirectory<PathBuf>>::new(&repo);
+        let res = DuktapeReducer::<::repository::Record>::new(&repo);
         assert!(res.is_err());
         let reducer_file = repo.path().join("reducers/reducer.js");
         let err = res.unwrap_err();
@@ -775,7 +829,7 @@ mod tests {
         fs::create_dir_all(repo.path().join("reducers")).unwrap();
         let mut f = fs::File::create(repo.path().join("reducers/reducer.js")).unwrap();
         f.write(b"module.exports = function(state) { return Object.assign{\"hello\": 1}, state); }").unwrap();
-        let res = DuktapeReducer::<::repository::Record<::repository::ModuleDirectory<PathBuf>>, ::repository::ModuleDirectory<PathBuf>>::new(&repo);
+        let res = DuktapeReducer::<::repository::Record>::new(&repo);
         assert!(res.is_err());
         let reducer_file = repo.path().join("reducers/reducer.js");
         let err = res.unwrap_err();
@@ -801,9 +855,8 @@ mod tests {
         let mut f = fs::File::create(repo.path().join("reducers").join("reducer.js")).unwrap();
         f.write(b"module.exports = function(state) { return Object.assign({\"hello\": record.a}, state); }").unwrap();
 
-        let item = repo.new_item().unwrap();
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         assert!(state.get("errors").is_some());
         let errors = state.get("errors").unwrap().as_array().unwrap();
@@ -829,28 +882,26 @@ mod tests {
          return {\"hello\": this.counter}; \
          }").unwrap();
 
-        let item = repo.new_item().unwrap();
-
-        // create two records
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        // create three records
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
 
         let mut reducer = DuktapeReducer::new(&repo).unwrap();
 
         use serde_json::Number;
 
-        let state = item.reduce_with_reducer(&mut reducer).unwrap();
+        let state = repo.reduce_with_reducer(&mut reducer).unwrap();
         assert_eq!(state.get("hello").unwrap(), &JsonValue::Number(Number::from(3)));
 
         // run it again without touching the state
-        let state = item.reduce_with_reducer(&mut reducer).unwrap();
+        let state = repo.reduce_with_reducer(&mut reducer).unwrap();
         assert_eq!(state.get("hello").unwrap(), &JsonValue::Number(Number::from(6)));
 
         // now, reset state
         reducer.reset_state();
 
-        let state = item.reduce_with_reducer(&mut reducer).unwrap();
+        let state = repo.reduce_with_reducer(&mut reducer).unwrap();
         assert_eq!(state.get("hello").unwrap(), &JsonValue::Number(Number::from(3)));
     }
 
@@ -874,20 +925,15 @@ mod tests {
          return {\"hello\": this.counter}; \
          };").unwrap();
 
-        let item1 = repo.new_item().unwrap();
-        item1.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-
-        let item2 = repo.new_item().unwrap();
-        item2.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        item2.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title 1"[..])].into_iter(), true).unwrap();
-
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
 
         let reducer = DuktapeReducer::new(&repo).unwrap();
         let mut reducer1 = reducer.clone();
         let mut reducer2 = reducer.clone();
 
-        let state1 = item1.reduce_with_reducer(&mut reducer1).unwrap();
-        let state2 = item2.reduce_with_reducer(&mut reducer2).unwrap();
+        let state1 = repo.reduce_with_reducer(&mut reducer1).unwrap();
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title 1"[..])].into_iter(), true).unwrap();
+        let state2 = repo.reduce_with_reducer(&mut reducer2).unwrap();
 
         use serde_json::Number;
         assert_eq!(state1.get("hello").unwrap(), &JsonValue::Number(Number::from(1)));
@@ -895,8 +941,8 @@ mod tests {
 
         // Now, make sure state gets copied from where it is, and not the original value:
         let mut reducer3 = reducer2.clone();
-        let state3 = item1.reduce_with_reducer(&mut reducer3).unwrap();
-        assert_eq!(state3.get("hello").unwrap(), &JsonValue::Number(Number::from(3)));
+        let state3 = repo.reduce_with_reducer(&mut reducer3).unwrap();
+        assert_eq!(state3.get("hello").unwrap(), &JsonValue::Number(Number::from(4)));
     }
 
 
@@ -916,9 +962,8 @@ mod tests {
             return Object.assign(state, {hello: new TextDecoder('utf-8').decode(record.files.text)});
         }").unwrap();
 
-        let item = repo.new_item().unwrap();
-        item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &"🙂😵😾🤔".as_bytes()[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &"🙂😵😾🤔".as_bytes()[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         assert_eq!(state.get("hello").unwrap(), &JsonValue::String("🙂😵😾🤔".into()));
     }
@@ -959,12 +1004,11 @@ mod tests {
           return state;
         }").unwrap();
 
-        let item = repo.new_item().unwrap();
-        item.new_record(vec![(".type/DetailsChanged", &b""[..]), ("text", &"🙂😵😾🤔   ".as_bytes()[..])].into_iter(), true).unwrap();
-        item.new_record(vec![(".type/Commented", &b""[..]), ("text", &"test🙂😵".as_bytes()[..])].into_iter(), true).unwrap();
+        repo.new_record(vec![(".type/DetailsChanged", &b""[..]), ("text", &"🙂😵😾🤔   ".as_bytes()[..])].into_iter(), true).unwrap();
+        repo.new_record(vec![(".type/Commented", &b""[..]), ("text", &"test🙂😵".as_bytes()[..])].into_iter(), true).unwrap();
 
         // SHOULD NOT FAIL
-        item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
     }
 
     #[cfg(feature = "duktape-require")]
@@ -981,9 +1025,8 @@ mod tests {
         let mut f = fs::File::create(repo.path().join("reducers/reducer/index.js")).unwrap();
         f.write(b"module.exports = function(state, record) { return {\"hello\": record.hash}; }").unwrap();
 
-        let item = repo.new_item().unwrap();
-        let record = item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        let record = repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         assert_eq!(state.get("hello").unwrap(), &JsonValue::String(record.encoded_hash()));
     }
@@ -1004,7 +1047,7 @@ mod tests {
 
         let err_str = "Error: module not found: \"index.js\"";
 
-        assert_matches!(DuktapeReducer::<::repository::Record<::repository::ModuleDirectory<PathBuf>>, ::repository::ModuleDirectory<PathBuf>>::new(&repo),
+        assert_matches!(DuktapeReducer::<::repository::Record>::new(&repo),
         Err(Error::ExecutionError { ref error }) if error == err_str);
     }
 
@@ -1022,7 +1065,7 @@ mod tests {
         f.write(b"module.exports = require(\"reducer/index.js\");").unwrap();
 
         let err_str = "Error: module not found: \"reducer/index.js\"";
-        assert_matches!(DuktapeReducer::<::repository::Record<::repository::ModuleDirectory<PathBuf>>, ::repository::ModuleDirectory<PathBuf>>::new(&repo),
+        assert_matches!(DuktapeReducer::<::repository::Record>::new(&repo),
         Err(Error::ExecutionError { ref error }) if error == err_str);
     }
 
@@ -1044,7 +1087,8 @@ mod tests {
 
         let err_str = "TypeError: cannot resolve module id: ../reducer.js";
 
-        assert_matches!(DuktapeReducer::<::repository::Record<::repository::ModuleDirectory<PathBuf>>, ::repository::ModuleDirectory<PathBuf>>::new(&repo),
+
+        assert_matches!(DuktapeReducer::<::repository::Record>::new(&repo),
         Err(Error::ExecutionError { ref error }) if error == err_str);
     }
 
@@ -1061,7 +1105,8 @@ mod tests {
         f.write(b"module.exports = require(\"/reducer.js\");").unwrap();
 
         let err_str = "TypeError: cannot resolve module id: /reducer.js";
-        assert_matches!(DuktapeReducer::<::repository::Record<::repository::ModuleDirectory<PathBuf>>, ::repository::ModuleDirectory<PathBuf>>::new(&repo),
+
+        assert_matches!(DuktapeReducer::<::repository::Record>::new(&repo),
         Err(Error::ExecutionError { ref error }) if error == err_str);
     }
 
@@ -1079,13 +1124,35 @@ mod tests {
         let mut f = fs::File::create(repo.modules_path().join("test").join("reducers").join("reducer").join("index.js")).unwrap();
         f.write(b"module.exports = function(state, record) { return {\"hello\": record.hash}; }").unwrap();
 
-        let item = repo.new_item().unwrap();
-        let record = item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        let record = repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         assert_eq!(state.get("hello").unwrap(), &JsonValue::String(record.encoded_hash()));
     }
 
+    #[cfg(feature = "duktape-require")]
+    #[test]
+    fn cross_module_require() {
+        let mut tmp = TempDir::new("sit").unwrap().into_path();
+        tmp.push(".sit");
+        let repo = Repository::new(tmp).unwrap();
+        use std::fs;
+        use std::io::Write;
+        fs::create_dir_all(repo.modules_path().join("test").join("reducers")).unwrap();
+        let mut f = fs::File::create(repo.modules_path().join("test").join("reducers").join("reducer.js")).unwrap();
+        f.write(b"module.exports = require(\"reducer/index.js\");").unwrap();
+        fs::create_dir_all(repo.modules_path().join("test1").join("reducers").join("reducer")).unwrap();
+        let mut f = fs::File::create(repo.modules_path().join("test1").join("reducers").join("reducer").join("index.js")).unwrap();
+        f.write(b"module.exports = function(state, record) { return {\"hello\": record.hash}; }").unwrap();
+
+        repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let result: Result<DuktapeReducer<::repository::Record>, _> = DuktapeReducer::new(&repo);
+        assert!(result.is_err());
+        let err = result.unwrap_err();
+        let err_str = "Error: module not found: \"reducer/index.js\"";
+        assert_matches!(err, Error::ExecutionError { ref error } if error == err_str);
+    }
+
     #[cfg(feature = "duktape-require")]
     #[test]
     fn require_in_linked_module() {
@@ -1104,9 +1171,8 @@ mod tests {
         let mut f = fs::File::create(module_path.join("reducers").join("reducer").join("index.js")).unwrap();
         f.write(b"module.exports = function(state, record) { return {\"hello\": record.hash}; }").unwrap();
 
-        let item = repo.new_item().unwrap();
-        let record = item.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
-        let state = item.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
+        let record = repo.new_record(vec![(".type/SummaryChanged", &b""[..]), ("text", &b"Title"[..])].into_iter(), true).unwrap();
+        let state = repo.reduce_with_reducer(&mut DuktapeReducer::new(&repo).unwrap()).unwrap();
 
         assert_eq!(state.get("hello").unwrap(), &JsonValue::String(record.encoded_hash()));
     }
diff --git a/sit-core/src/repository.rs b/sit-core/src/repository.rs
index 57e67cb..920d883 100644
--- a/sit-core/src/repository.rs
+++ b/sit-core/src/repository.rs
@@ -18,20 +18,30 @@ use serde_json;
 
 use super::hash::HashingAlgorithm;
 use super::encoding::Encoding;
+#[cfg(feature = "deprecated-item-api")]
 use super::id::IdGenerator;
 
 use std::collections::HashMap;
 
-use std::marker::PhantomData;
-
 /// Current repository format version
 const VERSION: &str = "1";
+/// Current repository features
+const FEATURES: &[&str] = &[FEATURE_FLAT_RECORDS];
+const FEATURE_FLAT_RECORDS: &str = "flat-records";
+
+fn default_features() -> Vec<String> {
+    FEATURES.iter().map(|s| s.to_string()).collect()
+}
+fn no_features() -> Vec<String> { vec![] }
+
 /// Repository's config file name
 const CONFIG_FILE: &str = "config.json";
 /// Repository's issues path (deprecated)
 const DEPRECATED_ISSUES_PATH: &str = "issues";
+/// Repository's items path (deprecated)
+const DEPRECATED_ITEMS_PATH: &str = "items";
 /// Repository's items path
-const ITEMS_PATH: &str = "items";
+const RECORDS_PATH: &str = "records";
 /// Repository's modules path
 const MODULES_PATH: &str = "modules";
 
@@ -51,7 +61,11 @@ pub struct Repository<MI> {
     modules_path: PathBuf,
     /// Path to items. Mainly to avoid creating this path
     /// on demand for every operation that would require it
+    #[cfg(feature = "deprecated-item-api")]
     items_path: PathBuf,
+    /// Path to records. Mainly to avoid creating this path
+    /// on demand for every operation that would require it
+    records_path: PathBuf,
     /// Configuration
     config: Config,
     /// Module iterator
@@ -121,10 +135,15 @@ pub struct Config {
     /// Encoding used
     encoding: Encoding,
     /// ID generator
+    ///
+    #[cfg(feature = "deprecated-item-api")]
     id_generator: IdGenerator,
     /// Repository version
     #[default = "String::from(VERSION)"]
     version: String,
+    #[default = "default_features()"]
+    #[serde(default = "no_features")]
+    features: Vec<String>,
     #[serde(flatten)]
     extra: HashMap<String, serde_json::Value>,
 }
@@ -155,6 +174,7 @@ impl Config {
 #[derive(PartialEq, Debug)]
 pub enum Upgrade {
     IssuesToItems,
+    ItemsToFlatRecords,
 }
 
 use std::fmt::{self, Display};
@@ -163,6 +183,7 @@ impl Display for Upgrade {
     fn fmt(&self, f: &mut fmt::Formatter) -> Result<(), fmt::Error> {
         match self {
             &Upgrade::IssuesToItems => write!(f, "renaming issues/ to items/"),
+            &Upgrade::ItemsToFlatRecords => write!(f, "migrating items' records to flat records namespace"),
         }
     }
 }
@@ -197,6 +218,13 @@ pub enum Error {
     OtherError(String),
 }
 
+impl From<glob::PatternError> for Error {
+    fn from(err: glob::PatternError) -> Self {
+        use ::std::error::Error as StandardError;
+        Error::OtherError(format!("glob pattern error: {}", err.description()))
+    }
+}
+
 #[allow(unused_variables,dead_code)]
 mod default_files {
     include!(concat!(env!("OUT_DIR"), "/default_files.rs"));
@@ -232,9 +260,11 @@ impl Repository<ModuleDirectory<PathBuf>> {
         Repository::new_with_config(path, Config {
             hashing_algorithm: Default::default(),
             encoding: Encoding::default(),
+            #[cfg(feature = "deprecated-item-api")]
             id_generator: IdGenerator::default(),
             version: String::from(VERSION),
             extra: HashMap::new(),
+            features: default_features(),
         })
     }
 
@@ -247,15 +277,20 @@ impl Repository<ModuleDirectory<PathBuf>> {
         } else {
             let mut config_path = path.clone();
             config_path.push(CONFIG_FILE);
-            let mut items_path = path.clone();
-            items_path.push(ITEMS_PATH);
-            fs::create_dir_all(&items_path)?;
+            #[cfg(feature = "deprecated-item-api")] let items_path = {
+                let items_path = path.join(DEPRECATED_ITEMS_PATH);
+                items_path
+            };
+            let records_path = path.join(RECORDS_PATH);
+            fs::create_dir_all(&records_path)?;
             let modules_path = path.join(MODULES_PATH);
             let module_iterator = ModuleDirectory(modules_path.clone());
             let repo = Repository {
                 path,
                 config_path,
+                #[cfg(feature = "deprecated-item-api")]
                 items_path,
+                records_path,
                 config,
                 modules_path,
                 module_iterator,
@@ -281,32 +316,67 @@ impl Repository<ModuleDirectory<PathBuf>> {
         let path: PathBuf = path.into();
         let mut config_path = path.clone();
         config_path.push(CONFIG_FILE);
-        let issues_path = path.join(DEPRECATED_ISSUES_PATH);
-        let items_path = path.join(ITEMS_PATH);
         let modules_path = path.join(MODULES_PATH);
-        if issues_path.is_dir() && !items_path.is_dir() {
-            if upgrades.as_ref().contains(&Upgrade::IssuesToItems) {
-                fs::rename(&issues_path, &items_path)?;
-            } else {
-                return Err(Error::UpgradeRequired(Upgrade::IssuesToItems));
+        let items_path = path.join(DEPRECATED_ITEMS_PATH);
+        let records_path = path.join(RECORDS_PATH);
+        let file = fs::File::open(&config_path)?;
+        let mut config: Config = serde_json::from_reader(file)?;
+        let upgraded = {
+            let mut _upgraded = false;
+            // items -> issues migration
+            {
+                let issues_path = path.join(DEPRECATED_ISSUES_PATH);
+                if issues_path.is_dir() && !items_path.is_dir() {
+                    if upgrades.as_ref().contains(&Upgrade::IssuesToItems) {
+                        fs::rename(&issues_path, &items_path)?;
+                        _upgraded = true;
+                    } else {
+                        return Err(Error::UpgradeRequired(Upgrade::IssuesToItems));
+                    }
+                }
+                if issues_path.is_dir() && items_path.is_dir() {
+                    if upgrades.as_ref().contains(&Upgrade::IssuesToItems) {
+                        for item in fs::read_dir(&issues_path)?.filter(Result::is_ok).map(Result::unwrap) {
+                            fs::rename(item.path(), items_path.join(item.file_name()))?;
+                        }
+                        fs::remove_dir_all(&issues_path)?;
+                        _upgraded = true;
+                    } else {
+                        return Err(Error::UpgradeRequired(Upgrade::IssuesToItems));
+                    }
+                }
             }
-        }
-        if issues_path.is_dir() && items_path.is_dir() {
-            if upgrades.as_ref().contains(&Upgrade::IssuesToItems) {
-                for item in fs::read_dir(&issues_path)?.filter(Result::is_ok).map(Result::unwrap) {
-                    fs::rename(item.path(), items_path.join(item.file_name()))?;
+
+            // flat records namespace
+            if upgrades.as_ref().contains(&Upgrade::ItemsToFlatRecords) {
+                fs::create_dir_all(&records_path)?;
+                let glob_pattern = format!("{}/*/*", items_path.to_str().unwrap());
+                let glob = glob::glob(&glob_pattern)?;
+                for path in glob.filter_map(Result::ok).filter(|p| p.is_dir()) {
+                    let mut components = path.components();
+                    let record = components.next_back().unwrap();
+                    let split_path = ::record::split_path(record.as_os_str().to_str().unwrap(), 2);
+                    let mut split_path_ = split_path.clone();
+                    split_path_.pop();
+                    fs::create_dir_all(records_path.join(split_path_))?;
+                    fs::rename(&path, records_path.join(&split_path))?;
+                    let mut f = fs::File::create(&path)?;
+                    f.write(format!("../../{}/{}", RECORDS_PATH, split_path.to_str().unwrap()).as_bytes())?;
+                }
+                config.version = VERSION.into();
+                if config.features.iter().find(|f| f.as_str() == FEATURE_FLAT_RECORDS).is_none() {
+                    config.features.push(FEATURE_FLAT_RECORDS.into());
                 }
-                fs::remove_dir_all(&issues_path)?;
+                _upgraded = true;
             } else {
-                return Err(Error::UpgradeRequired(Upgrade::IssuesToItems));
+                let record_as_dir_present = items_path.is_dir() && walkdir::WalkDir::new(&items_path).min_depth(2).max_depth(2)
+                    .into_iter().filter_entry(|e| e.file_type().is_dir()).filter_map(Result::ok).next().is_some();
+                if record_as_dir_present || config.features.iter().find(|f| f.as_str() == FEATURE_FLAT_RECORDS).is_none() {
+                    return Err(Error::UpgradeRequired(Upgrade::ItemsToFlatRecords));
+                }
             }
-        }
-        // dropping issues_path so it can no longer be used
-        // by mistake
-        drop(issues_path);
-        fs::create_dir_all(&items_path)?;
-        let file = fs::File::open(&config_path)?;
-        let config: Config = serde_json::from_reader(file)?;
+            _upgraded
+        };
         if config.version != VERSION {
             return Err(Error::InvalidVersion { expected: String::from(VERSION), got: config.version });
         }
@@ -314,12 +384,17 @@ impl Repository<ModuleDirectory<PathBuf>> {
         let repository = Repository {
             path,
             config_path,
+            #[cfg(feature = "deprecated-item-api")]
             items_path,
+            records_path,
             config,
             modules_path,
             module_iterator,
             integrity_check: true,
         };
+        if upgraded {
+            repository.save()?;
+        }
         Ok(repository)
     }
 
@@ -331,7 +406,10 @@ impl Repository<ModuleDirectory<PathBuf>> {
         path.push(dir);
         loop {
             match path.parent() {
-                Some(parent) if Repository::open(&parent).is_ok() => return Some(parent.into()),
+                Some(parent) => match Repository::open(&parent) {
+                    Ok(_) | Err(Error::UpgradeRequired(_)) => return Some(parent.into()),
+                    _ => (),
+                },
                 _ => (),
             }
             if !path.is_dir() {
@@ -344,10 +422,9 @@ impl Repository<ModuleDirectory<PathBuf>> {
                 // try assuming current path + `dir`
                 path.push(dir);
             } else {
-                if Repository::open(&path).is_ok() {
-                    break;
-                } else {
-                    return None;
+                match Repository::open(&path) {
+                    Ok(_) | Err(Error::UpgradeRequired(_)) => break,
+                    _ => return None,
                 }
             }
         }
@@ -363,7 +440,6 @@ impl<'a, MI> HasPath for Repository<MI> {
 }
 
 impl<MI> Repository<MI> {
-
     /// Returns a new instance of this Repository with an additional module iterator
     /// chained to the existing one
     pub fn with_module_iterator<MI1>(self, module_iterator: MI1) -> Repository<(MI, MI1)> {
@@ -371,7 +447,9 @@ impl<MI> Repository<MI> {
             path: self.path,
             config_path: self.config_path,
             modules_path: self.modules_path,
+            #[cfg(feature = "deprecated-item-api")]
             items_path: self.items_path,
+            records_path: self.records_path,
             config: self.config,
             module_iterator: (self.module_iterator, module_iterator),
             integrity_check: self.integrity_check,
@@ -384,7 +462,9 @@ impl<MI> Repository<MI> {
             path: self.path,
             config_path: self.config_path,
             modules_path: self.modules_path,
+            #[cfg(feature = "deprecated-item-api")]
             items_path: self.items_path,
+            records_path: self.records_path,
             config: self.config,
             module_iterator,
             integrity_check: self.integrity_check,
@@ -408,7 +488,9 @@ impl<MI> Repository<MI> {
             path: self.path,
             config_path: self.config_path,
             modules_path: self.modules_path,
+            #[cfg(feature = "deprecated-item-api")]
             items_path: self.items_path,
+            records_path: self.records_path,
             config: self.config,
             module_iterator: self.module_iterator,
             integrity_check: value,
@@ -438,10 +520,16 @@ impl<MI> Repository<MI> {
     }
 
     /// Returns items path
+    #[cfg(feature = "deprecated-item-api")]
     pub fn items_path(&self) -> &Path {
         self.items_path.as_path()
     }
 
+    /// Returns records path
+    pub fn records_path(&self) -> &Path {
+        self.records_path.as_path()
+    }
+
     /// Returns repository's config
     pub fn config(&self) -> &Config {
         &self.config
@@ -452,12 +540,14 @@ impl<MI> Repository<MI> {
         &mut self.config
     }
 
-
+    #[cfg(feature = "deprecated-item-api")]
     /// Returns an unordered (as in "order not defined") item iterator
     pub fn item_iter(&self) -> Result<ItemIter<MI>, Error> {
+        fs::create_dir_all(self.items_path())?;
         Ok(ItemIter { repository: self, dir: fs::read_dir(&self.items_path)?, integrity_check: self.integrity_check })
     }
 
+    #[cfg(feature = "deprecated-item-api")]
     /// Creates and returns a new item with a unique ID
     pub fn new_item(&self) -> Result<Item<MI>, Error> {
         self.new_named_item(self.config.id_generator.generate())
@@ -465,21 +555,45 @@ impl<MI> Repository<MI> {
 
     /// Creates and returns a new item with a specific name. Will fail
     /// if there's an item with the same name.
+    #[cfg(feature = "deprecated-item-api")]
     pub fn new_named_item<S: Into<String>>(&self, name: S) -> Result<Item<MI>, Error> {
+        fs::create_dir_all(self.items_path())?;
         let id: String = name.into();
-        let mut path = self.items_path.clone();
-        path.push(&id);
-        fs::create_dir(path)?;
+        let path = self.items_path().join(&id);
+        fs::create_dir(&path)?;
         let id = OsString::from(id);
         Ok(Item {
             repository: self,
             integrity_check: self.integrity_check,
-            path: self.items_path().join(&id),
+            path,
             id,
         })
     }
 
+    /// Finds a record by name (if there is one)
+    pub fn record<S: AsRef<str>>(&self, name: S) -> Option<Record> {
+        let path = self.records_path().join(::record::split_path(name, 2));
+        let path = path.resolve_dir().unwrap_or(path);
+        if path.is_dir() && path.strip_prefix(self.records_path()).is_ok() {
+            let hash = self.config.encoding.decode(path.file_name().unwrap().to_str().unwrap().as_bytes());
+            if hash.is_err() {
+                return None
+            }
+            let record = Record {
+                hash: hash.unwrap(),
+                encoding: self.config.encoding.clone(),
+                path,
+                #[cfg(feature = "deprecated-item-api")]
+                item: "".into(),
+            };
+            Some(record)
+        } else {
+            None
+        }
+    }
+
     /// Finds an item by name (if there is one)
+    #[cfg(feature = "deprecated-item-api")]
     pub fn item<S: AsRef<str>>(&self, name: S) -> Option<Item<MI>> {
         let path = self.items_path().join(name.as_ref());
         if path.exists() && path.strip_prefix(self.items_path()).is_ok() {
@@ -507,8 +621,82 @@ impl<MI> Repository<MI> {
     pub fn modules_path(&self) -> &Path {
         &self.modules_path
     }
+
+    pub fn new_record_in<'f, P: AsRef<Path>, F: File + 'f, I: Into<OrderedFiles<'f, F>>>(&self, path: P, files: I, link_parents: bool) ->
+    Result<Record, Error> where F::Read: 'f {
+        let tempdir = TempDir::new_in(&self.path, "sit")?;
+        let mut hasher = self.config.hashing_algorithm.hasher();
+
+        let files: OrderedFiles<F> = files.into();
+
+        // Link parents if requested
+        let files = if link_parents {
+            let records = self.record_iter()?.last().unwrap_or(vec![]);
+            let parents: OrderedFiles<_> = records.iter().map(|rec| (format!(".prev/{}", rec.encoded_hash()), &b""[..])).into();
+            files + parents
+        } else {
+            files.boxed()
+        };
+
+        files.hash_and(&mut *hasher, |n| -> Result<fs::File, Error> {
+            let path = RelativePath::new(n).normalize();
+            if path.components().any(|c| match c {
+                RelativeComponent::Normal(_) => false,
+                _ => true,
+            }) {
+                return Err(Error::PathPrefixError);
+            }
+            let actual_path = path.to_path(tempdir.path());
+            let mut dir = actual_path.clone();
+            dir.pop();
+            fs::create_dir_all(dir)?;
+            let file = fs::File::create(actual_path)?;
+            Ok(file)
+        }, |mut f, c| -> Result<fs::File, Error> { f.write(c).map(|_| f).map_err(|e| e.into()) })?;
+
+
+        let hash = hasher.result_box();
+        let path = path.as_ref().join(::record::split_path(self.config.encoding.encode(&hash), 2));
+        if path.exists() {
+            fs::remove_dir_all(tempdir.into_path())?;
+        } else {
+            if cfg!(windows) {
+                // We have to handle Windows separately here because of how renaming works differently
+                // on Windows. From `std::fs::rename` documentation:
+                //
+                //     This function currently corresponds to the `rename` function on Unix
+                //     and the `MoveFileEx` function with the `MOVEFILE_REPLACE_EXISTING` flag on Windows.
+                //
+                //     Because of this, the behavior when both `from` and `to` exist differs. On
+                //     Unix, if `from` is a directory, `to` must also be an (empty) directory. If
+                //     `from` is not a directory, `to` must also be not a directory. In contrast,
+                //     on Windows, `from` can be anything, but `to` must *not* be a directory.
+                //
+                // So, we are avoiding creating the last directory component in the path on Windows:
+                fs::create_dir_all(path.parent().unwrap())?;
+            } else {
+                fs::create_dir_all(&path)?;
+            }
+            fs::rename(tempdir.into_path(), &path)?;
+        }
+        Ok(Record {
+            hash,
+            #[cfg(feature = "deprecated-item-api")]
+            item: "".into(),
+            path,
+            encoding: self.config.encoding.clone(),
+        })
+    }
 }
 
+impl<MI> RecordOwningContainer for Repository<MI> {
+
+    fn new_record<'f, F: File + 'f, I: Into<OrderedFiles<'f, F>>>(&self, files: I, link_parents: bool) -> Result<Record, Error> where F::Read: 'f {
+        self.new_record_in(&self.records_path, files, link_parents)
+    }
+}
+
+
 impl<MI> Repository<MI> where MI: ModuleIterator<PathBuf, Error>
 {
     /// Returns an iterator over the list of modules (directories under `modules` directory)
@@ -517,18 +705,67 @@ impl<MI> Repository<MI> where MI: ModuleIterator<PathBuf, Error>
     }
 }
 
+use record::RecordContainerReduction;
+impl<MI> RecordContainerReduction for Repository<MI> { }
+
+impl<MI> RecordContainer for Repository<MI> {
+    type Error = Error;
+    type Record = Record;
+    type Records = Vec<Record>;
+    type Iter = RepositoryRecordIterator;
+
+    fn record_iter(&self) -> Result<Self::Iter, Self::Error> {
+        let path = self.records_path().resolve_dir().unwrap_or(self.records_path().into());
+        let iter = GenericRecordIterator::new(self.config.hashing_algorithm.clone(),
+                                              self.config.encoding.clone(),
+                                              path,
+                                              None);
+        Ok(RepositoryRecordIterator {
+            iter,
+            integrity_check: self.integrity_check,
+        })
+    }
+
+}
+
+
+pub struct RepositoryRecordIterator {
+    iter: GenericRecordIterator,
+    integrity_check: bool,
+}
+
+impl Iterator for RepositoryRecordIterator {
+    type Item = Vec<Record>;
+
+    fn next(&mut self) -> Option<Self::Item> {
+        self.iter.next().map(|vec| {
+            vec.into_iter().map(|(path, hash)|
+                Record {
+                    hash,
+                    #[cfg(feature = "deprecated-item-api")]
+                    item: "".into(),
+                    path,
+                    encoding: self.iter.encoding.clone(),
+            }).filter(|r| self.integrity_check == false || r.integrity_intact(&self.iter.hashing_algorithm)).collect() }
+        )
+    }
+
+}
+
 impl<MI> PartialEq for Repository<MI> {
     fn eq(&self, rhs: &Repository<MI>) -> bool {
         (self as *const Repository<MI>) == (rhs as *const Repository<MI>)
     }
 }
 
+#[cfg(feature = "deprecated-item-api")]
 use super::Item as ItemTrait;
-
+#[cfg(feature = "deprecated-item-api")]
 use std::ffi::OsString;
 
 /// An item residing in a repository
 #[derive(Debug, PartialEq)]
+#[cfg(feature = "deprecated-item-api")]
 pub struct Item<'a, MI: 'a> {
     repository: &'a Repository<MI>,
     id: OsString,
@@ -539,12 +776,14 @@ pub struct Item<'a, MI: 'a> {
 use record::{File, OrderedFiles};
 use relative_path::{RelativePath, Component as RelativeComponent};
 
+#[cfg(feature = "deprecated-item-api")]
 impl<'a, MI: 'a> HasPath for Item<'a, MI> {
     fn path(&self) -> &Path {
         self.path.as_path()
     }
 }
 
+#[cfg(feature = "deprecated-item-api")]
 impl<'a, MI: 'a> Item<'a, MI> {
 
     /// Returns the status of integrity check
@@ -568,109 +807,142 @@ impl<'a, MI: 'a> Item<'a, MI> {
         }
     }
 
-
     pub fn new_record_in<'f, P: AsRef<Path>, F: File + 'f, I: Into<OrderedFiles<'f, F>>>(&self, path: P, files: I, link_parents: bool) ->
-           Result<<Item<'a, MI> as ItemTrait>::Record, <Item<'a, MI> as ItemTrait>::Error> where F::Read: 'f {
-        let tempdir = TempDir::new_in(&self.repository.path,"sit")?;
-        let mut hasher = self.repository.config.hashing_algorithm.hasher();
-
-        let files: OrderedFiles<F> = files.into();
-
-        // Link parents if requested
-        let files = if link_parents {
-            let records = self.record_iter()?.last().unwrap_or(vec![]);
-            let parents: OrderedFiles<_> = records.iter().map(|rec| (format!(".prev/{}", rec.encoded_hash()), &b""[..])).into();
-            files + parents
-        } else {
-            files.boxed()
-        };
+           Result<<Item<'a, MI> as RecordContainer>::Record, <Item<'a, MI> as RecordContainer>::Error> where F::Read: 'f {
+        self.repository.new_record_in(path, files, link_parents)
+    }
 
-        files.hash_and(&mut *hasher, |n| -> Result<fs::File, Error> {
-            let path = RelativePath::new(n).normalize();
-            if path.components().any(|c| match c {
-                RelativeComponent::Normal(_) => false,
-                _ => true,
-            }) {
-                return Err(Error::PathPrefixError);
-            }
-            let actual_path = path.to_path(tempdir.path());
-            let mut dir = actual_path.clone();
-            dir.pop();
-            fs::create_dir_all(dir)?;
-            let file = fs::File::create(actual_path)?;
-            Ok(file)
-        }, |mut f, c| -> Result<fs::File, Error> { f.write(c).map(|_| f).map_err(|e| e.into()) })?;
+}
 
+use record::RecordContainer;
 
-        let hash = hasher.result_box();
-        let path = path.as_ref().join(PathBuf::from(self.repository.config.encoding.encode(&hash)));
-        fs::rename(tempdir.into_path(), &path)?;
-        Ok(Record {
-            hash,
+#[cfg(feature = "deprecated-item-api")]
+impl<'a, MI: 'a> RecordContainer for Item<'a, MI> {
+    type Error = Error;
+    type Record = Record;
+    type Records = Vec<Record>;
+    type Iter = ItemRecordIterator;
+
+    fn record_iter(&self) -> Result<Self::Iter, Self::Error> {
+        let path = self.path().resolve_dir().unwrap_or(self.path().into());
+        let iter = GenericRecordIterator::new(self.repository.config.hashing_algorithm.clone(),
+                                              self.repository.config.encoding.clone(),
+                                              path,
+                                              Some(1));
+        Ok(ItemRecordIterator {
+            iter,
             item: self.id.clone(),
-            repository: self.repository,
-            path,
+            integrity_check: self.integrity_check,
         })
     }
 
 }
-impl<'a, MI: 'a> ItemTrait for Item<'a, MI> {
 
-    type Error = Error;
-    type Record = Record<'a, MI>;
-    type Records = Vec<Record<'a, MI>>;
-    type RecordIter = ItemRecordIter<'a, MI>;
+use record::RecordOwningContainer;
+#[cfg(feature = "deprecated-item-api")]
+impl<'a, MI: 'a> RecordOwningContainer for Item<'a, MI> {
+
+     fn new_record<'f, F: File + 'f, I: Into<OrderedFiles<'f, F>>>(&self, files: I, link_parents: bool) -> Result<Self::Record, Self::Error> where F::Read: 'f {
+        let record = self.new_record_in(&self.repository.records_path, files, link_parents)?;
+        // TODO: should we remove the record if creating a link file failed?
+        let path = self.repository.items_path.join(self.id());
+        fs::create_dir_all(&path)?;
+        let record_path = ::record::split_path(record.encoded_hash(), 2);
+        let record_path_s = record_path.to_str().unwrap();
+        #[cfg(windows)] // replace backslashes with slashes
+        let record_path_s = record_path_s.replace("\\", "/");
+        let mut f = fs::File::create(path.join(record.encoded_hash()))?;
+        f.write(format!("../../{}/{}", RECORDS_PATH, record_path_s).as_bytes())?;
+        Ok(record)
+    }
+
+}
+
+#[cfg(feature = "deprecated-item-api")]
+impl<'a, MI: 'a> ItemTrait for Item<'a, MI> {
 
     fn id(&self) -> &str {
         self.id.to_str().unwrap()
     }
 
-    fn record_iter(&self) -> Result<Self::RecordIter, Self::Error> {
-        let path = self.repository.items_path.join(PathBuf::from(&self.id()));
-        let dir = fs::read_dir(&path)?.filter(|r| r.is_ok())
-            .map(|e| e.unwrap())
-            .collect();
-        Ok(ItemRecordIter {
-            item: self.id.clone(),
-            repository: self.repository,
-            dir,
-            parents: vec![],
-            integrity_check: self.integrity_check,
-        })
-    }
+}
+
+
+#[cfg(feature = "deprecated-item-api")]
+pub struct ItemRecordIterator {
+    iter: GenericRecordIterator,
+    item: OsString,
+    integrity_check: bool,
+}
 
-    fn new_record<'f, F: File + 'f, I: Into<OrderedFiles<'f, F>>>(&self, files: I, link_parents: bool) -> Result<Self::Record, Self::Error> where F::Read: 'f {
-       self.new_record_in(self.repository.items_path.join(PathBuf::from(self.id())), files, link_parents)
+#[cfg(feature = "deprecated-item-api")]
+impl Iterator for ItemRecordIterator {
+    type Item = Vec<Record>;
+
+    fn next(&mut self) -> Option<Self::Item> {
+        self.iter.next().map(|vec| {
+            vec.into_iter().map(|(path, hash)|
+                Record {
+                    hash,
+                    item: self.item.clone(),
+                    path,
+                    encoding: self.iter.encoding.clone(),
+            })
+                .filter(|r| self.integrity_check == false || r.integrity_intact(&self.iter.hashing_algorithm))
+                .collect() }
+        )
     }
 
 }
 
-/// An iterator over records in an item
-pub struct ItemRecordIter<'a, MI: 'a> {
-    item: OsString,
-    repository: &'a Repository<MI>,
-    dir: Vec<fs::DirEntry>,
+use walkdir;
+
+/// An iterator over records
+struct GenericRecordIterator {
+    hashing_algorithm: HashingAlgorithm,
+    encoding: Encoding,
+    path: PathBuf,
+    dir: Vec<walkdir::DirEntry>,
     parents: Vec<String>,
-    integrity_check: bool,
 }
 
-impl<'a, MI: 'a> Iterator for ItemRecordIter<'a, MI> {
-    type Item = Vec<Record<'a, MI>>;
+impl GenericRecordIterator {
+    fn new(hashing_algorithm: HashingAlgorithm, encoding: Encoding, path: PathBuf,
+           depth: Option<usize>) -> Self {
+        let depth = depth.or_else(|| {
+            let mut depth = hashing_algorithm.len() * 4 / encoding.bit_width();
+            if hashing_algorithm.len() * 4 % encoding.bit_width() != 0 {
+                depth +=1;
+            }
+            Some(depth)
+        }).unwrap();
+        let dir: Vec<_> = walkdir::WalkDir::new(&path).min_depth(depth).max_depth(depth)
+            .into_iter().filter_map(Result::ok).collect();
+        GenericRecordIterator {
+            encoding,
+            hashing_algorithm,
+            dir,
+            path,
+            parents: vec![],
+        }
+    }
+}
+
+impl Iterator for GenericRecordIterator {
+    type Item = Vec<(PathBuf, Vec<u8>)>;
 
     fn next(&mut self) -> Option<Self::Item> {
-        let item = match self.repository.item(self.item.to_str().unwrap()) {
-            None => return None,
-            Some(item) => item,
-        };
-        let item_path = item.path();
         // TODO: if https://github.com/rust-lang/rust/issues/43244 is finalized, try to use drain_filter instead
         let (filtered, dir): (Vec<_>, Vec<_>) = ::std::mem::replace(&mut self.dir, vec![]).into_iter()
             .partition(|e| {
-                let path = e.path().resolve_dir().unwrap_or(e.path());
+                let path = e.path().resolve_dir().unwrap_or(e.path().to_path_buf());
                 if !path.is_dir() {
                     return false
                 }
-                let valid_name = self.repository.config.encoding.decode(e.file_name().to_str().unwrap().as_bytes()).is_ok();
+
+                let name = e.file_name().to_str().unwrap();
+
+                let valid_name = self.encoding.decode(name.as_bytes()).is_ok();
                 if !valid_name {
                     return false;
                 }
@@ -681,47 +953,38 @@ impl<'a, MI: 'a> Iterator for ItemRecordIter<'a, MI> {
                     Ok(dir) => {
                         dir.filter_map(Result::ok)
                             // only use links pointing to actual directories
-                            .filter(|l| item_path.join(l.file_name()).is_dir())
+                            .filter(|l| {
+                                #[cfg(feature ="deprecated-item-api")]
+                                let is_dir = {
+                                    let p = self.path.join(l.file_name().to_str().unwrap());
+                                    p.resolve_dir().unwrap_or(p).is_dir()
+                                };
+                                #[cfg(not(feature ="deprecated-item-api"))]
+                                let is_dir = false;
+                                is_dir || {
+                                    let p = self.path.join(::record::split_path(l.file_name().to_str().unwrap(), 2));
+                                    p.resolve_dir().unwrap_or(p).is_dir()
+                                }
+                            })
                             // has to be already processed
                             .all(|l| self.parents.iter().any(|p| p.as_str() == l.file_name().to_str().unwrap()))
-
                     }
                 };
 
                 has_all_valid_parents
             });
-        let result: Vec<_> = {
-            let mapped = filtered.iter()
-                .map(|e| {
-                    let path = item_path.join(e.file_name());
-                    Record {
-                        hash: self.repository.config.encoding.decode(e.file_name().to_str().unwrap().as_bytes()).unwrap(),
-                        item: self.item.clone(),
-                        repository: self.repository,
-                        path: path.resolve_dir().unwrap_or(path),
-                    }
-                });
-            if self.integrity_check {
-                mapped.filter(|r| {
-                    let mut hasher = self.repository.config.hashing_algorithm.hasher();
-                    let ordered_files = OrderedFiles::from(r.file_iter());
-                    match ordered_files.hash(&mut *hasher) {
-                        Ok(_) => {
-                            let hash = hasher.result_box();
-                            r.hash == hash
-                        },
-                        _ => false
-                    }
-                }).collect()
-            } else {
-                mapped.collect()
-            }
-        };
+        let result: Vec<_> = filtered.iter()
+            .map(|e| {
+                let name = e.file_name().to_str().unwrap();
+                let decoded_name = self.encoding.decode(name.as_bytes()).unwrap();
+                (e.path().resolve_dir().unwrap_or(e.path().to_path_buf()), decoded_name)
+            }).collect();
         self.dir = dir;
         if result.len() == 0 {
             return None
         }
-        self.parents.append(&mut result.iter().map(|r| r.encoded_hash()).collect());
+        let encoding = self.encoding.clone();
+        self.parents.append(&mut result.iter().map(|(_, rhash)| encoding.encode(rhash)).collect());
         Some(result)
     }
 }
@@ -729,12 +992,14 @@ impl<'a, MI: 'a> Iterator for ItemRecordIter<'a, MI> {
 
 /// Unordered (as in "order not defined') item iterator
 /// within a repository
+#[cfg(feature = "deprecated-item-api")]
 pub struct ItemIter<'a, MI: 'a> {
     repository: &'a Repository<MI>,
     dir: fs::ReadDir,
     integrity_check: bool,
 }
 
+#[cfg(feature = "deprecated-item-api")]
 impl<'a, MI: 'a> Iterator for ItemIter<'a, MI> {
     type Item = Item<'a, MI>;
 
@@ -761,16 +1026,17 @@ impl<'a, MI: 'a> Iterator for ItemIter<'a, MI> {
 
 use super::Record as RecordTrait;
 
-/// A record within an item
-#[derive(Debug)]
-pub struct Record<'a, MI: 'a> {
+/// A record
+#[derive(Debug, Clone)]
+pub struct Record {
     hash: Vec<u8>,
+    #[cfg(feature = "deprecated-item-api")]
     item: OsString,
-    repository: &'a Repository<MI>,
+    encoding: Encoding,
     path: PathBuf,
 }
 
-impl<'a, MI: 'a> HasPath for Record<'a, MI> {
+impl HasPath for Record {
 
     /// Returns path to the record
     fn path(&self) -> &Path {
@@ -782,7 +1048,7 @@ impl<'a, MI: 'a> HasPath for Record<'a, MI> {
 
 use serde::{Serialize, Serializer};
 
-impl<'a, MI: 'a> Serialize for Record<'a, MI> {
+impl Serialize for Record {
     fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error> where S: Serializer {
         use record::RecordExt;
         self.serde_serialize(serializer)
@@ -790,24 +1056,24 @@ impl<'a, MI: 'a> Serialize for Record<'a, MI> {
 }
 
 
-impl<'a, MI: 'a> PartialEq for Record<'a, MI> {
-   fn eq(&self, other: &Record<'a, MI>) -> bool {
+impl PartialEq for Record {
+   fn eq(&self, other: &Record) -> bool {
        self.hash == other.hash
    }
 }
 
-impl<'a, MI: 'a> RecordTrait for Record<'a, MI> {
+impl RecordTrait for Record {
     type Read = ::std::fs::File;
     type Str = String;
     type Hash = Vec<u8>;
-    type Iter = RecordFileIterator<'a>;
+    type Iter = RecordFileIterator;
 
     fn hash(&self) -> Self::Hash {
         self.hash.clone()
     }
 
     fn encoded_hash(&self) -> Self::Str {
-        self.repository.config.encoding.encode(&self.hash)
+        self.encoding.encode(&self.hash)
     }
 
     fn file_iter(&self) -> Self::Iter {
@@ -816,22 +1082,21 @@ impl<'a, MI: 'a> RecordTrait for Record<'a, MI> {
         RecordFileIterator {
             glob: glob::glob(&glob_pattern).expect("invalid glob pattern"),
             prefix: self.path().into(),
-            phantom: PhantomData,
         }
     }
+    #[cfg(feature = "deprecated-item-api")]
     fn item_id(&self) -> Self::Str {
         self.item.clone().into_string().unwrap()
     }
 }
 
 /// An iterator over files in a record
-pub struct RecordFileIterator<'a> {
+pub struct RecordFileIterator {
     glob: glob::Paths,
     prefix: PathBuf,
-    phantom: PhantomData<&'a ()>,
 }
 
-impl<'a> Iterator for RecordFileIterator<'a> {
+impl Iterator for RecordFileIterator {
     type Item = (String, fs::File);
 
     fn next(&mut self) -> Option<Self::Item> {
@@ -870,7 +1135,10 @@ mod tests {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
         let repo = Repository::new(&tmp).unwrap();
-        assert_eq!(repo.item_iter().unwrap().count(), 0); // no items in a new repo
+        #[cfg(feature = "deprecated-item-api")] {
+            assert_eq!(repo.item_iter().unwrap().count(), 0); // no items in a new repo
+        }
+        assert_eq!(repo.record_iter().unwrap().count(), 0); // no records in a new repo
         assert_eq!(repo.path(), tmp);
     }
 
@@ -886,7 +1154,8 @@ mod tests {
     }
 
     #[test]
-    fn open_repo() {
+    #[cfg(feature = "deprecated-item-api")]
+    fn repo_persists_items() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
         let repo = Repository::new(&tmp).unwrap();
@@ -900,6 +1169,22 @@ mod tests {
         assert_eq!(items.pop().unwrap().id(), item.id());
     }
 
+    #[test]
+    fn repo_records_records() {
+        let mut tmp = TempDir::new("sit").unwrap().into_path();
+        tmp.push(".sit");
+        let repo = Repository::new(&tmp).unwrap();
+        // create a record
+        let record = repo.new_record(vec![("test/it", &[1u8][..])].into_iter(), false).unwrap();
+        let repo = Repository::open(&tmp).unwrap();
+        // load records
+        let mut records: Vec<Vec<_>> = repo.record_iter().unwrap().collect();
+        assert_eq!(records.len(), 1);
+        // check equality of the item's ID
+        assert_eq!(records.pop().unwrap().pop().unwrap().hash(), record.hash());
+    }
+
+
     #[test]
     fn find_repo() {
         let tmp = TempDir::new("sit").unwrap().into_path();
@@ -921,6 +1206,18 @@ mod tests {
         assert!(Repository::find_in_or_above(".sit", &deep_subdir).is_none());
     }
 
+    #[test]
+    fn find_upgradable_repo() {
+        let tmp = TempDir::new("sit").unwrap().into_path();
+        let sit = tmp.join(".sit");
+        // create repo w/o flat-records
+        let mut repo = Repository::new(&sit).unwrap();
+        repo.config.features = vec![];
+        repo.save().unwrap();
+        let deep_subdir = tmp.join("a/b/c/d");
+        let repo = Repository::find_in_or_above(".sit", &deep_subdir);
+        assert!(repo.is_some());
+    }
 
     #[test]
     fn find_repo_in_itself() {
@@ -938,6 +1235,7 @@ mod tests {
 
 
     #[test]
+    #[cfg(feature = "deprecated-item-api")]
     fn new_item() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
@@ -952,6 +1250,7 @@ mod tests {
     }
 
     #[test]
+    #[cfg(feature = "deprecated-item-api")]
     fn new_named_item() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
@@ -966,6 +1265,7 @@ mod tests {
     }
 
     #[test]
+    #[cfg(feature = "deprecated-item-api")]
     fn new_named_item_dup() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
@@ -981,6 +1281,7 @@ mod tests {
     }
 
     #[test]
+    #[cfg(feature = "deprecated-item-api")]
     fn find_item() {
          let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
@@ -1002,6 +1303,7 @@ mod tests {
     /// This test ensures that item symlinks expressed as text files (for system
     /// without symlinks) will be interpreted as symlinks
     #[test]
+    #[cfg(feature = "deprecated-item-api")]
     fn item_path_link() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
@@ -1030,24 +1332,25 @@ mod tests {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
         let repo = Repository::new(&tmp).unwrap();
-        // create an item
-        let item = repo.new_item().unwrap();
         // create a record
-        let record = item.new_record(vec![("test", &b"hello"[..])].into_iter(), true).unwrap();
+        let record = repo.new_record(vec![("test", &b"hello"[..])].into_iter(), true).unwrap();
         // move the record
         fs::rename(record.path(), tmp.join(record.encoded_hash())).unwrap();
         // link it
-        let mut f = fs::File::create(item.path().join(record.encoded_hash())).unwrap();
-        f.write(format!("../../{}", record.encoded_hash()).as_bytes()).unwrap();
+        let mut f = fs::File::create(repo.records_path().join(record.split_path(2))).unwrap();
+        f.write(format!("../../../../../../../../../../../../../../../../{}",
+                        record.encoded_hash()).as_bytes()).unwrap();
+        println!("{:?}", repo.path());
         // iterate for it
-        let mut record_iter = item.record_iter().unwrap();
+        let mut record_iter = repo.record_iter().unwrap();
         assert_eq!(record_iter.next().unwrap().get(0).unwrap().encoded_hash(), record.encoded_hash());
         assert!(record_iter.next().is_none());
     }
 
 
     #[test]
-    fn new_record() {
+    #[cfg(feature = "deprecated-item-api")]
+    fn new_item_record() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
         let repo = Repository::new(&tmp).unwrap();
@@ -1065,9 +1368,45 @@ mod tests {
         assert!(file.read_to_string(&mut string).is_ok());
         assert_eq!(string, "hello");
         // list records
-        let mut records: Vec<Record<_>> = item.record_iter().unwrap().flat_map(|v| v).collect();
+        let mut records: Vec<Record> = item.record_iter().unwrap().flat_map(|v| v).collect();
+        assert_eq!(records.len(), 1);
+        assert_eq!(records.pop().unwrap().hash(), record.hash());
+    }
+
+    #[test]
+    fn new_record() {
+        let mut tmp = TempDir::new("sit").unwrap().into_path();
+        tmp.push(".sit");
+        let repo = Repository::new(&tmp).unwrap();
+        // create a record
+        let record = repo.new_record(vec![("test", &b"hello"[..])].into_iter(), true).unwrap();
+        // peek into the record
+        let mut files: Vec<_> = record.file_iter().collect();
+        assert_eq!(files.len(), 1);
+        let (name, mut file) = files.pop().unwrap();
+        assert_eq!(name, "test");
+        use std::io::Read;
+        let mut string = String::new();
+        assert!(file.read_to_string(&mut string).is_ok());
+        assert_eq!(string, "hello");
+        // list records
+        let mut records: Vec<Record> = repo.record_iter().unwrap().flat_map(|v| v).collect();
         assert_eq!(records.len(), 1);
         assert_eq!(records.pop().unwrap().hash(), record.hash());
+        // find record
+        assert_eq!(repo.record(record.encoded_hash()).unwrap().hash(), record.hash());
+    }
+
+    #[test]
+    fn record_split_path() {
+        let mut tmp = TempDir::new("sit").unwrap().into_path();
+        tmp.push(".sit");
+        let repo = Repository::new(&tmp).unwrap();
+        // create a record
+        let record = repo.new_record(vec![("test", &b"hello"[..])].into_iter(), true).unwrap();
+        let path = record.split_path(2);
+        assert_eq!(path, Path::new("7T/VN/NJ/XP/VZ/PZ/FJ/W5/WO/UI/FY/CR/2X/TN/5T/7TVNNJXPVZPZFJW5WOUIFYCR2XTN5TNG"));
+        assert_eq!(record.path().strip_prefix(repo.records_path()).unwrap(), path);
     }
 
     #[test]
@@ -1075,28 +1414,27 @@ mod tests {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
         let repo = Repository::new(&tmp).unwrap();
-        // create an item
-        let mut item = repo.new_item().unwrap();
         // create a record
-        let record = item.new_record(vec![("test", &b"hello"[..])].into_iter(), true).unwrap();
+        let record = repo.new_record(vec![("test", &b"hello"[..])].into_iter(), true).unwrap();
         // tamper with the record
-        let mut file = fs::File::create(repo.items_path().join(item.id()).join(record.encoded_hash()).join("file")).unwrap();
+        let mut file = fs::File::create(record.path().join("file")).unwrap();
         file.write(b"test").unwrap();
         drop(file);
         // list records
-        let records: Vec<Record<_>> = item.record_iter().unwrap().flat_map(|v| v).collect();
+        let records: Vec<Record> = repo.record_iter().unwrap().flat_map(|v| v).collect();
         // invalid record should not be listed
         assert_eq!(records.len(), 0);
         // disable integrity check
-        item.set_integrity_check(false);
-        let mut records: Vec<Record<_>> = item.record_iter().unwrap().flat_map(|v| v).collect();
+        let repo = repo.clone().with_integrity_check(false);
+        let mut records: Vec<Record> = repo.record_iter().unwrap().flat_map(|v| v).collect();
         // now there should be a record
         assert_eq!(records.len(), 1);
         assert_eq!(records.pop().unwrap().hash(), record.hash());
     }
 
     #[test]
-    fn record_integrity_check_propagates_from_repository() {
+    #[cfg(feature = "deprecated-item-api")]
+    fn item_record_integrity_check_propagates_from_repository() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
         let mut repo = Repository::new(&tmp).unwrap();
@@ -1107,11 +1445,30 @@ mod tests {
         // create a record
         let record = item.new_record(vec![("test", &b"hello"[..])].into_iter(), true).unwrap();
         // tamper with the record
-        let mut file = fs::File::create(repo.items_path().join(item.id()).join(record.encoded_hash()).join("file")).unwrap();
+        let mut file = fs::File::create(repo.items_path().join(item.id()).join(record.encoded_hash()).resolve_dir().unwrap().join("file")).unwrap();
+        file.write(b"test").unwrap();
+        drop(file);
+        // list records
+        let mut records: Vec<Record> = item.record_iter().unwrap().flat_map(|v| v).collect();
+        // now there should be a record
+        assert_eq!(records.len(), 1);
+        assert_eq!(records.pop().unwrap().hash(), record.hash());
+    }
+
+    #[test]
+    fn record_integrity_check_propagates_from_repository() {
+        let mut tmp = TempDir::new("sit").unwrap().into_path();
+        tmp.push(".sit");
+        let mut repo = Repository::new(&tmp).unwrap();
+        repo.set_integrity_check(false);
+        // create a record
+        let record = repo.new_record(vec![("test", &b"hello"[..])].into_iter(), true).unwrap();
+        // tamper with the record
+        let mut file = fs::File::create(repo.records_path().join(record.split_path(2)).resolve_dir().unwrap().join("file")).unwrap();
         file.write(b"test").unwrap();
         drop(file);
         // list records
-        let mut records: Vec<Record<_>> = item.record_iter().unwrap().flat_map(|v| v).collect();
+        let mut records: Vec<Record> = repo.record_iter().unwrap().flat_map(|v| v).collect();
         // now there should be a record
         assert_eq!(records.len(), 1);
         assert_eq!(records.pop().unwrap().hash(), record.hash());
@@ -1122,35 +1479,30 @@ mod tests {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
         let repo = Repository::new(&tmp).unwrap();
-        // create an item
-        let item = repo.new_item().unwrap();
         // attempt to create a record with an invalid filename
-        assert_matches!(item.new_record(vec![(".", &b"hello"[..])].into_iter(), false), Err(Error::IoError(_)));
-        assert_matches!(item.new_record(vec![("../test", &b"hello"[..])].into_iter(), false), Err(Error::PathPrefixError));
-        assert_matches!(item.new_record(vec![("something/../../test", &b"hello"[..])].into_iter(), false), Err(Error::PathPrefixError));
+        assert_matches!(repo.new_record(vec![(".", &b"hello"[..])].into_iter(), false), Err(Error::IoError(_)));
+        assert_matches!(repo.new_record(vec![("../test", &b"hello"[..])].into_iter(), false), Err(Error::PathPrefixError));
+        assert_matches!(repo.new_record(vec![("something/../../test", &b"hello"[..])].into_iter(), false), Err(Error::PathPrefixError));
         // however, these are alright
-        assert_matches!(item.new_record(vec![("something/../test", &b"hello"[..])].into_iter(), false), Ok(_));
-        assert_matches!(item.new_record(vec![("./test1", &b"hello"[..])].into_iter(), false), Ok(_));
+        assert_matches!(repo.new_record(vec![("something/../test", &b"hello"[..])].into_iter(), false), Ok(_));
+        assert_matches!(repo.new_record(vec![("./test1", &b"hello"[..])].into_iter(), false), Ok(_));
         // root is normalized, too
-        let record = item.new_record(vec![("/test2", &b"hello"[..])].into_iter(), false).unwrap();
+        let record = repo.new_record(vec![("/test2", &b"hello"[..])].into_iter(), false).unwrap();
         assert_eq!(record.file_iter().next().unwrap().name(), "test2");
     }
 
-
     #[test]
     fn new_record_parents_linking() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
         let repo = Repository::new(&tmp).unwrap();
-        // create an item
-        let item = repo.new_item().unwrap();
         // create a few top records
-        let record1 = item.new_record(vec![("test", &[1u8][..])].into_iter(), false).unwrap();
+        let record1 = repo.new_record(vec![("test", &[1u8][..])].into_iter(), false).unwrap();
         let record1link = format!(".prev/{}", record1.encoded_hash());
-        let record2 = item.new_record(vec![("test", &[2u8][..])].into_iter(), false).unwrap();
+        let record2 = repo.new_record(vec![("test", &[2u8][..])].into_iter(), false).unwrap();
         let record2link = format!(".prev/{}", record2.encoded_hash());
         // now attempt to create a record that should link both together
-        let record = item.new_record(vec![("test", &[3u8][..])].into_iter(), true).unwrap();
+        let record = repo.new_record(vec![("test", &[3u8][..])].into_iter(), true).unwrap();
         assert!(record.file_iter().any(|(name, _)| name == *&record1link));
         assert!(record.file_iter().any(|(name, _)| name == *&record2link));
     }
@@ -1160,20 +1512,18 @@ mod tests {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
         let repo = Repository::new(&tmp).unwrap();
-        // create an item
-        let item = repo.new_item().unwrap();
         // create a few top records
-        let record1 = item.new_record(vec![("test", &[1u8][..])].into_iter(), false).unwrap();
-        let record2 = item.new_record(vec![("test", &[2u8][..])].into_iter(), false).unwrap();
+        let record1 = repo.new_record(vec![("test", &[1u8][..])].into_iter(), false).unwrap();
+        let record2 = repo.new_record(vec![("test", &[2u8][..])].into_iter(), false).unwrap();
         // now attempt to create a record that should link both together
-        let record3 = item.new_record(vec![("test", &[3u8][..])].into_iter(), true).unwrap();
+        let record3 = repo.new_record(vec![("test", &[3u8][..])].into_iter(), true).unwrap();
         // and another top record
-        let record4 = item.new_record(vec![("test", &[4u8][..])].into_iter(), false).unwrap();
+        let record4 = repo.new_record(vec![("test", &[4u8][..])].into_iter(), false).unwrap();
         // and another linking record
-        let record5 = item.new_record(vec![("test", &[5u8][..])].into_iter(), true).unwrap();
+        let record5 = repo.new_record(vec![("test", &[5u8][..])].into_iter(), true).unwrap();
 
         // now, look at their ordering
-        let mut records: Vec<_> = item.record_iter().unwrap().collect();
+        let mut records: Vec<_> = repo.record_iter().unwrap().collect();
         let row_3 = records.pop().unwrap();
         let row_2 = records.pop().unwrap();
         let row_1 = records.pop().unwrap();
@@ -1196,20 +1546,18 @@ mod tests {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
         let repo = Repository::new(&tmp).unwrap();
-        // create an item
-        let item = repo.new_item().unwrap();
         // create a top record
-        let record1 = item.new_record(vec![("test", &[1u8][..])].into_iter(), false).unwrap();
+        let record1 = repo.new_record(vec![("test", &[1u8][..])].into_iter(), false).unwrap();
         // create a record right below it
-        let record2 = item.new_record(vec![("test", &[2u8][..])].into_iter(), true).unwrap();
+        let record2 = repo.new_record(vec![("test", &[2u8][..])].into_iter(), true).unwrap();
         // now attempt to create a record that should link both together
-        let record3 = item.new_record(vec![("test", &[3u8][..]),
+        let record3 = repo.new_record(vec![("test", &[3u8][..]),
                                            (&format!(".prev/{}", record1.encoded_hash()), &[][..]),
                                            (&format!(".prev/{}", record2.encoded_hash()), &[][..]),
         ].into_iter(), false).unwrap();
 
         // now, look at their ordering
-        let mut records: Vec<_> = item.record_iter().unwrap().collect();
+        let mut records: Vec<_> = repo.record_iter().unwrap().collect();
         let row_3 = records.pop().unwrap();
         let row_2 = records.pop().unwrap();
         let row_1 = records.pop().unwrap();
@@ -1225,7 +1573,6 @@ mod tests {
         assert!(row_3.iter().any(|r| r == &record3));
     }
 
-
     #[test]
     fn partial_ordering() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
@@ -1233,15 +1580,13 @@ mod tests {
 
         // first repo
         let repo1 = Repository::new(&tmp).unwrap();
-        // create an item
-        let item1 = repo1.new_item().unwrap();
         // create a few top records
-        let _record0 = item1.new_record(vec![("test", &[2u8][..])].into_iter(), false).unwrap();
+        let _record0 = repo1.new_record(vec![("test", &[2u8][..])].into_iter(), false).unwrap();
         // this record will link only to one top record
-        let record1 = item1.new_record(vec![("test", &[3u8][..])].into_iter(), true).unwrap();
-        let record2 = item1.new_record(vec![("test", &[1u8][..])].into_iter(), false).unwrap();
+        let record1 = repo1.new_record(vec![("test", &[3u8][..])].into_iter(), true).unwrap();
+        let record2 = repo1.new_record(vec![("test", &[1u8][..])].into_iter(), false).unwrap();
         // now attempt to create a record that should link both together
-        let record3 = item1.new_record(vec![("test", &[3u8][..])].into_iter(), true).unwrap();
+        let record3 = repo1.new_record(vec![("test", &[3u8][..])].into_iter(), true).unwrap();
 
 
         let mut tmp1 = TempDir::new("sit").unwrap().into_path();
@@ -1249,25 +1594,23 @@ mod tests {
 
         // second repo
         let repo2 = Repository::new(&tmp1).unwrap();
-        // create an item
-        let item2 = repo2.new_item().unwrap();
         // replicate one of the top records only
-        let record2_2 = item2.new_record(record2.file_iter(), false).unwrap();
+        let record2_2 = repo2.new_record(record2.file_iter(), false).unwrap();
 
         // now copy record3 that linked both top records in the first repo
         // to the second repo
-        let record3_2 = item2.new_record(record3.file_iter(), false).unwrap();
+        let record3_2 = repo2.new_record(record3.file_iter(), false).unwrap();
         // ensure their hashes match
         assert_eq!(record3_2.hash(), record3.hash());
 
         // now copy record1 that linked both top records in the first repo
         // to the second repo
-        let record1_2 = item2.new_record(record1.file_iter(), false).unwrap();
+        let record1_2 = repo2.new_record(record1.file_iter(), false).unwrap();
         // ensure their hashes match
         assert_eq!(record1_2.hash(), record1.hash());
 
         // now, look at the records in the second item
-        let mut records: Vec<_> = item2.record_iter().unwrap().collect();
+        let mut records: Vec<_> = repo2.record_iter().unwrap().collect();
         let row_2 = records.pop().unwrap();
         let row_1 = records.pop().unwrap();
         assert_eq!(records.len(), 0);
@@ -1287,14 +1630,14 @@ mod tests {
     fn record_deterministic_hashing() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
-        let repo = Repository::new(&tmp).unwrap();
-        let item1 = repo.new_item().unwrap();
-        let record1 = item1.new_record(vec![("z/a", &[2u8][..]), ("test", &[1u8][..])].into_iter(), false).unwrap();
-        let item2 = repo.new_item().unwrap();
-        let record2 = item2.new_record(vec![("test", &[1u8][..]), ("z/a", &[2u8][..])].into_iter(), false).unwrap();
+        let repo1 = Repository::new(tmp.join("1")).unwrap();
+        let repo2 = Repository::new(tmp.join("2")).unwrap();
+        let repo3 = Repository::new(tmp.join("3")).unwrap();
+
+        let record1 = repo1.new_record(vec![("z/a", &[2u8][..]), ("test", &[1u8][..])].into_iter(), false).unwrap();
+        let record2 = repo2.new_record(vec![("test", &[1u8][..]), ("z/a", &[2u8][..])].into_iter(), false).unwrap();
         assert_eq!(record1.hash(), record2.hash());
-        let item3 = repo.new_item().unwrap();
-        let record3 = item3.new_record(vec![("test", &[1u8][..]), ("z\\a", &[2u8][..])].into_iter(), false).unwrap();
+        let record3 = repo3.new_record(vec![("test", &[1u8][..]), ("z\\a", &[2u8][..])].into_iter(), false).unwrap();
         assert_eq!(record3.hash(), record2.hash());
     }
 
@@ -1306,9 +1649,8 @@ mod tests {
         tmp1.pop();
 
         let repo = Repository::new(&tmp).unwrap();
-        let item = repo.new_item().unwrap();
-        let _record1 = item.new_record(vec![("z/a", &[2u8][..]), ("test", &[1u8][..])].into_iter(), false).unwrap();
-        let record2 = item.new_record_in(&tmp1, vec![("a", &[2u8][..])].into_iter(), true).unwrap();
+        let _record1 = repo.new_record(vec![("z/a", &[2u8][..]), ("test", &[1u8][..])].into_iter(), false).unwrap();
+        let record2 = repo.new_record_in(&tmp1, vec![("a", &[2u8][..])].into_iter(), true).unwrap();
 
         // lets test that record2 can iterate over correct files
         let files: Vec<_> = record2.file_iter().collect();
@@ -1316,7 +1658,7 @@ mod tests {
 
 
         // record2 can't be found as it is outside of the standard naming scheme
-        let records: Vec<Vec<_>> = item.record_iter().unwrap().collect();
+        let records: Vec<Vec<_>> = repo.record_iter().unwrap().collect();
         assert_eq!(records.len(), 1);
         assert_eq!(records[0].len(), 1);
 
@@ -1327,10 +1669,11 @@ mod tests {
         #[cfg(windows)]
         drop(files);
 
-        ::std::fs::rename(record2.path(), repo.items_path().join(item.id()).join(record2.encoded_hash())).unwrap();
+        fs::create_dir_all(repo.records_path().join(record2.split_path(2)).parent().unwrap()).unwrap();
+        fs::rename(record2.path(), repo.records_path().join(record2.split_path(2))).unwrap();
 
         // and now it can be
-        let records: Vec<Vec<_>> = item.record_iter().unwrap().collect();
+        let records: Vec<Vec<_>> = repo.record_iter().unwrap().collect();
         assert_eq!(records.len(), 2);
         assert_eq!(records[0].len(), 1);
         assert_eq!(records[0].len(), 1);
@@ -1338,22 +1681,28 @@ mod tests {
     }
 
     #[test]
+    #[cfg(feature = "deprecated-item-api")]
     fn issues_to_items_upgrade() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
         tmp.push(".sit");
         let mut tmp1 = tmp.clone();
         tmp1.pop();
 
-        let repo = Repository::new(&tmp).unwrap();
+        let mut repo = Repository::new(&tmp).unwrap();
+        {
+           repo.config.features = vec![];
+        }
+        repo.save().unwrap();
         let _item = repo.new_item().unwrap();
         assert_eq!(repo.item_iter().unwrap().count(), 1);
 
+
         ::std::fs::rename(repo.items_path(), repo.path().join("issues")).unwrap();
         let repo = Repository::open(&tmp);
         assert!(repo.is_err());
         assert_matches!(repo.unwrap_err(), Error::UpgradeRequired(Upgrade::IssuesToItems));
 
-        let repo = Repository::open_and_upgrade(&tmp, &[Upgrade::IssuesToItems]).unwrap();
+        let mut repo = Repository::open_and_upgrade(&tmp, &[Upgrade::IssuesToItems, Upgrade::ItemsToFlatRecords]).unwrap();
         assert!(!repo.path().join("issues").exists());
         assert_eq!(repo.item_iter().unwrap().count(), 1);
 
@@ -1361,20 +1710,140 @@ mod tests {
         // both issues/ and items/ are present
         // this can happen when merging a patch that changes .sit/issues
         // (prepared before the migration)
+        {
+            repo.config.features = vec![];
+        }
+        repo.save().unwrap();
+
         let item = repo.new_item().unwrap();
         ::std::fs::create_dir_all(repo.path().join("issues")).unwrap();
         ::std::fs::rename(repo.items_path().join(item.id()), repo.path().join("issues").join(item.id())).unwrap();
 
+
         let repo = Repository::open(&tmp);
         assert!(repo.is_err());
         assert_matches!(repo.unwrap_err(), Error::UpgradeRequired(Upgrade::IssuesToItems));
 
-        let repo = Repository::open_and_upgrade(&tmp, &[Upgrade::IssuesToItems]).unwrap();
+        let repo = Repository::open_and_upgrade(&tmp, &[Upgrade::IssuesToItems, Upgrade::ItemsToFlatRecords]).unwrap();
         assert!(!repo.path().join("issues").exists());
         assert_eq!(repo.item_iter().unwrap().count(), 2);
 
     }
 
+    #[test]
+    #[cfg(feature = "deprecated-item-api")]
+    fn layout_v2_upgrade() {
+        let mut tmp = TempDir::new("sit").unwrap().into_path();
+        tmp.push(".sit");
+        let mut tmp1 = tmp.clone();
+        tmp1.pop();
+
+        let mut repo = Repository::new(&tmp).unwrap();
+        {
+           repo.config.features = vec![];
+        }
+        repo.save().unwrap();
+        let item = repo.new_item().unwrap();
+        assert_eq!(repo.item_iter().unwrap().count(), 1);
+        let record = item.new_record(vec![("test", &[0u8][..])].into_iter(), false).unwrap();
+
+        // move the record back to items/
+        fs::remove_file(item.path().join(record.encoded_hash())).unwrap();
+        fs::rename(record.path(), item.path().join(record.encoded_hash())).unwrap();
+        // the record can still be found, but not in records/
+        let record1 = item.record_iter().unwrap().next().unwrap().pop().unwrap();
+        assert_eq!(record1.path(), item.path().join(record1.encoded_hash()));
+
+        let repo = Repository::open(&tmp);
+        assert!(repo.is_err());
+        assert_matches!(repo.unwrap_err(), Error::UpgradeRequired(Upgrade::ItemsToFlatRecords));
+
+        let repo = Repository::open_and_upgrade(&tmp, &[Upgrade::ItemsToFlatRecords]).unwrap();
+        let item = repo.item(item.id()).unwrap();
+        let record1 = item.record_iter().unwrap().next().unwrap().pop().unwrap();
+        // Record is back where it belongs
+        use dunce;
+        assert_eq!(dunce::canonicalize(record1.path()).unwrap(), dunce::canonicalize(repo.records_path().join(::record::split_path(record1.encoded_hash(), 2))).unwrap());
+
+        // In a decentralized scenarios, some v1 updates might come at a point past the upgrade,
+        // meaning v1 items will be injected into v2 repositories (because of delays or somebody
+        // using an older version of SIT)
+        // We need to ensure that the items will be continuously migrated.
+
+        let new_item = repo.new_item().unwrap();
+        let new_record = new_item.new_record(vec![("test", &[1u8][..])].into_iter(), false).unwrap();
+
+        // move the record back to items/
+        fs::remove_file(new_item.path().join(new_record.encoded_hash())).unwrap();
+        fs::rename(new_record.path(), new_item.path().join(new_record.encoded_hash())).unwrap();
+
+        let repo = Repository::open(&tmp);
+        assert!(repo.is_err());
+        assert_matches!(repo.unwrap_err(), Error::UpgradeRequired(Upgrade::ItemsToFlatRecords));
+
+        let repo = Repository::open_and_upgrade(&tmp, &[Upgrade::ItemsToFlatRecords]).unwrap();
+        let new_record_2 = repo.record(new_record.encoded_hash()).unwrap();
+
+        assert_eq!(new_record.hash(), new_record_2.hash());
+
+        let new_item_2 = repo.item(new_item.id()).unwrap();
+        let new_record_2_1 = new_item_2.record_iter().unwrap().next().unwrap().pop().unwrap();
+
+        assert_eq!(new_record_2_1.hash(), new_record_2.hash());
+    }
+    
+    #[test]
+    fn fixed_roots() {
+        let mut tmp = TempDir::new("sit").unwrap().into_path();
+        tmp.push(".sit");
+        let repo = Repository::new(&tmp).unwrap();
+
+        // create two top records
+        let record1 = repo.new_record(vec![("test", &[1u8][..])].into_iter(), false).unwrap();
+        let record2 = repo.new_record(vec![("test", &[2u8][..])].into_iter(), false).unwrap();
+        // create a record referring only to one root
+        let record3 = repo.new_record(vec![("test", &[3u8][..]),
+                                           (&format!(".prev/{}", record1.encoded_hash()), &[][..]),
+        ].into_iter(), false).unwrap();
+        // create a record referring only to another root
+        let record4 = repo.new_record(vec![("test", &[3u8][..]),
+                                           (&format!(".prev/{}", record2.encoded_hash()), &[][..]),
+        ].into_iter(), false).unwrap();
+
+        let mut subset1 = repo.fixed_roots(vec![record1.encoded_hash()]).record_iter().unwrap();
+        let first = subset1.next().unwrap();
+        assert_eq!(first, vec![record1.clone()]);
+        let next = subset1.next().unwrap();
+        assert_eq!(next, vec![record3.clone()]);
+
+        let mut subset2 = repo.fixed_roots(vec![record2.encoded_hash()]).record_iter().unwrap();
+        let first = subset2.next().unwrap();
+        assert_eq!(first, vec![record2.clone()]);
+        let next = subset2.next().unwrap();
+        assert_eq!(next, vec![record4.clone()]);
+
+        // fixed roots, same level of roots
+        let mut subset3 = repo.fixed_roots(vec![record1.encoded_hash(), record2.encoded_hash()]).record_iter().unwrap();
+        let first = subset3.next().unwrap();
+        assert_eq!(first.len(), 2);
+        assert!(first.iter().any(|e| e.encoded_hash() == record1.encoded_hash()));
+        assert!(first.iter().any(|e| e.encoded_hash() == record2.encoded_hash()));
+        let next = subset3.next().unwrap();
+        assert_eq!(next.len(), 2);
+        assert!(next.iter().any(|e| e.encoded_hash() == record3.encoded_hash()));
+        assert!(next.iter().any(|e| e.encoded_hash() == record4.encoded_hash()));
+
+        // fixed roots, different levels of roots
+        let mut subset4 = repo.fixed_roots(vec![record1.encoded_hash(), record4.encoded_hash()]).record_iter().unwrap();
+        let first = subset4.next().unwrap();
+        assert_eq!(first.len(), 1);
+        assert!(first.iter().any(|e| e.encoded_hash() == record1.encoded_hash()));
+        let next = subset4.next().unwrap();
+        assert_eq!(next.len(), 2);
+        assert!(next.iter().any(|e| e.encoded_hash() == record3.encoded_hash()));
+        assert!(next.iter().any(|e| e.encoded_hash() == record4.encoded_hash()));
+    }
+
     #[test]
     fn modules() {
         let mut tmp = TempDir::new("sit").unwrap().into_path();
diff --git a/sit-web/Cargo.toml b/sit-web/Cargo.toml
index dd17896..acdc8c6 100644
--- a/sit-web/Cargo.toml
+++ b/sit-web/Cargo.toml
@@ -34,4 +34,6 @@ include_dir = "0.1"
 fs_extra = "1.1"
 
 [features]
+default = ["deprecated-items"]
 windows7 = ["sit-core/windows7"]
+deprecated-items = ["sit-core/deprecated-item-api"]
diff --git a/sit-web/src/webapp.rs b/sit-web/src/webapp.rs
index 4df09bb..b22453c 100644
--- a/sit-web/src/webapp.rs
+++ b/sit-web/src/webapp.rs
@@ -64,8 +64,8 @@ use std::path::PathBuf;
 use std::fs;
 use std::net::ToSocketAddrs;
 
-use sit_core::{Repository, reducers::duktape::DuktapeReducer, record::OrderedFiles,
-               path::{HasPath, ResolvePath}};
+use sit_core::{Repository, repository, reducers::duktape::{self, DuktapeReducer}, record::OrderedFiles,
+               record::{RecordContainer, RecordContainerReduction, RecordOwningContainer}, path::{HasPath, ResolvePath}};
 use std::io::Cursor;
 
 use mime_guess::get_mime_type_str;
@@ -123,6 +123,141 @@ struct Config {
     readonly: bool,
 }
 
+
+fn new_record<C: RecordOwningContainer, MI>(container: &C, request: &Request, repo: &Repository<MI>, config: &sit_core::cfg::Configuration) -> Result<C::Record, String> {
+    let mut multipart = get_multipart_input(request).expect("multipart request");
+    let mut link = true;
+    let mut used_files = vec![];
+
+    loop {
+        let part = multipart.next();
+        if part.is_none() {
+            break;
+        }
+        let mut field = part.unwrap();
+        loop {
+            let path = {
+                let mut file = field.data.as_file().expect("files only");
+                let saved_file = file.save().temp().into_result().expect("can't save file");
+                saved_file.path
+            };
+            if field.name.starts_with(".prev/") {
+                link = false;
+            }
+            used_files.push((field.name.clone(), path));
+            match field.next_entry_inplace() {
+                Ok(Some(_)) => continue,
+                Ok(None) => break,
+                Err(e) => panic!(e),
+            }
+        }
+    }
+
+    let files: OrderedFiles<_> = used_files.iter().map(|(n, p)| (n.clone(), fs::File::open(p).expect("can't open saved file"))).into();
+    let files_: OrderedFiles<_> = used_files.iter().map(|(n, p)| (n.clone(), fs::File::open(p).expect("can't open saved file"))).into();
+
+    let files: OrderedFiles<_> = if config.signing.enabled {
+        use std::ffi::OsString;
+        use std::io::Write;
+        let program = super::gnupg(&config).unwrap();
+        let key = match config.signing.key.clone() {
+            Some(key) => Some(OsString::from(key)),
+            None => None,
+        };
+
+        let mut command = ::std::process::Command::new(program);
+
+        command
+            .stdin(::std::process::Stdio::piped())
+            .stdout(::std::process::Stdio::piped())
+            .arg("--sign")
+            .arg("--armor")
+            .arg("--detach-sign")
+            .arg("-o")
+            .arg("-");
+
+        if key.is_some() {
+            let _ = command.arg("--default-key").arg(key.unwrap());
+        }
+
+        let mut child = command.spawn().expect("failed spawning gnupg");
+
+        {
+            let mut stdin = child.stdin.as_mut().expect("Failed to open stdin");
+            let mut hasher = repo.config().hashing_algorithm().hasher();
+            files_.hash(&mut *hasher).expect("failed hashing files");
+            let hash = hasher.result_box();
+            let encoded_hash = repo.config().encoding().encode(&hash);
+            stdin.write_all(encoded_hash.as_bytes()).expect("Failed to write to stdin");
+        }
+
+        let output = child.wait_with_output().expect("failed to read stdout");
+
+        if !output.status.success() {
+            eprintln!("Error: {}", String::from_utf8_lossy(&output.stderr));
+            return Err(String::from_utf8_lossy(&output.stderr).into());
+        } else {
+            let sig: OrderedFiles<_> = vec![(String::from(".signature"), Cursor::new(output.stdout))].into();
+            files + sig
+        }
+
+    } else {
+        files.boxed()
+    };
+
+    let record = container.new_record(files, link).expect("can't create record");
+
+    for (_, file) in used_files {
+        fs::remove_file(file).expect("can't remove file");
+    }
+
+    Ok(record)
+}
+
+fn reduce<MI, RCR: RecordContainerReduction<Record = repository::Record>>
+    (repo: &Repository<MI>, container: &RCR, request: &Request, query_expr: String) -> Response
+    where MI: repository::ModuleIterator<PathBuf, repository::Error> {
+    if let Some(vals) = request.get_param("reducers") {
+        let reducers_path = repo.path().join("reducers");
+        let reducers = vals.split(",").map(PathBuf::from)
+            .map(|p| if p.is_file() {
+                p
+            } else if reducers_path.join(&p).resolve_dir().unwrap().is_dir() {
+                let dir = reducers_path.join(&p).resolve_dir().unwrap();
+                dir
+            } else {
+                p
+            });
+        return reduce__(container, request, query_expr, reducers)
+    } else {
+        return reduce__(container, request, query_expr, repo)
+    }
+    // implementation
+    fn reduce__<RCR: RecordContainerReduction<Record = repository::Record>, SF: duktape::SourceFiles>
+        (container: &RCR, request: &Request, query_expr: String, source_files: SF) -> Response {
+            use jmespath;
+            let reducer = sit_core::reducers::duktape::DuktapeReducer::new(source_files).unwrap();
+            let query = match jmespath::compile(&query_expr) {
+                Ok(query) => query,
+                _ => return Response::empty_400(),
+            };
+            fn reduce_<RCR: RecordContainerReduction<Record = repository::Record>>
+                (container: &RCR, query: jmespath::Expression, mut reducer: duktape::DuktapeReducer<repository::Record>, state: serde_json::Value)-> Response {
+                    let state = container.initialize_state(state.as_object().unwrap().to_owned());
+                    let reduced = container.reduce_with_reducer_and_state(&mut reducer, state).unwrap();
+                    let data = jmespath::Variable::from(serde_json::Value::Object(reduced));
+                    let result = query.search(&data).unwrap();
+                    Response::json(&result)
+            }
+            if let Some(state) = request.get_param("state") {
+                reduce_(container, query, reducer, serde_json::from_str(&state).unwrap())
+            } else {
+                reduce_(container, query, reducer, serde_json::Value::Object(Default::default()))
+            }
+    }
+}
+
+
 pub fn start<A: ToSocketAddrs, MI: 'static + Send + Sync>(addr: A, config: sit_core::cfg::Configuration, repo: Repository<MI>, readonly: bool, overlays: Vec<&str>)
     where MI: sit_core::repository::ModuleIterator<PathBuf, sit_core::repository::Error> {
     let mut overlays: Vec<_> = overlays.iter().map(|o| PathBuf::from(o)).collect();
@@ -155,12 +290,13 @@ pub fn start<A: ToSocketAddrs, MI: 'static + Send + Sync>(addr: A, config: sit_c
         (GET) (/config) => {
            Response::json(&repo_config)
         },
-        (GET) (/api/items/{filter_expr: String}/{query_expr: String}) => {
+        (GET) (/api/items/{filter_expr: String}/{query_expr: String}) => { // DEPRECATED
+        #[cfg(feature = "deprecated-items")] {
             use jmespath;
-            use sit_core::item::ItemReduction;
+            use sit_core::record::RecordContainerReduction;
             let items: Vec<_> = repo.item_iter().expect("can't list items").collect();
             let mut reducer = Arc::new(Mutex::new(sit_core::reducers::duktape::DuktapeReducer::new(&repo).unwrap()));
-            let tl_reducer: ThreadLocal<RefCell<DuktapeReducer<sit_core::repository::Record<MI>, MI>>> = ThreadLocal::new();
+            let tl_reducer: ThreadLocal<RefCell<DuktapeReducer<sit_core::repository::Record>>>= ThreadLocal::new();
 
             let filter_defined = filter_expr != "";
             let filter = if filter_defined {
@@ -198,10 +334,15 @@ pub fn start<A: ToSocketAddrs, MI: 'static + Send + Sync>(addr: A, config: sit_c
                   })
                  .filter(Option::is_some).collect();
             Response::json(&result)
+          }
+        #[cfg(not(feature = "deprecated-items"))] {
+             Response::not_found()
+        }
         },
-        (GET) (/api/item/{id: String}/{query_expr: String}) => {
+        (GET) (/api/item/{id: String}/{query_expr: String}) => { // DEPRECATED 
+        #[cfg(feature = "deprecated-items")] {
             use jmespath;
-            use sit_core::item::ItemReduction;
+            use sit_core::record::RecordContainerReduction;
             use sit_core::Item;
             let mut reducer = sit_core::reducers::duktape::DuktapeReducer::new(&repo).unwrap();
             let query = match jmespath::compile(&query_expr) {
@@ -216,8 +357,20 @@ pub fn start<A: ToSocketAddrs, MI: 'static + Send + Sync>(addr: A, config: sit_c
             let data = jmespath::Variable::from(serde_json::Value::Object(reduced));
             let result = query.search(&data).unwrap();
             Response::json(&result)
+        }
+        #[cfg(not(feature = "deprecated-items"))] {
+             Response::not_found()
+        }
         },
-        (GET) (/api/item/{id: String}/{record: String}/files) => {
+        (GET) (/api/{roots: String}/reduce/{query_expr: String}) => {
+            let container = repo.fixed_roots(roots.split(","));
+            reduce(&repo, &container, &request, query_expr)
+        },
+        (GET) (/api/reduce/{query_expr: String}) => {
+            reduce(&repo, &repo, &request, query_expr)
+        },
+        (GET) (/api/item/{id: String}/{record: String}/files) => { // DEPRECATED
+        #[cfg(feature = "deprecated-items")] {
             use sit_core::{Record, Item};
             let item = match repo.item_iter().unwrap().find(|i| i.id() == id) {
                 Some(item) => item,
@@ -229,14 +382,33 @@ pub fn start<A: ToSocketAddrs, MI: 'static + Send + Sync>(addr: A, config: sit_c
             };
             let files: Vec<_> = record.file_iter().map(|(name, _)| name).collect();
             Response::json(&files)
+        }
+        #[cfg(not(feature = "deprecated-items"))] {
+             Response::not_found()
+        }
+        },
+        (GET) (/api/record/{record: String}/files) => {
+            use sit_core::Record;
+            let record = match repo.record(record) {
+               Some(record) => record,
+               None => return Response::empty_404(),
+            };
+            let files: Vec<_> = record.file_iter().map(|(name, _)| name).collect();
+            Response::json(&files)
         },
         (POST) (/api/item) => {
+        #[cfg(feature = "deprecated-items")] { // DEPRECATED
            if readonly { return Response::empty_404(); }
            use sit_core::Item;
            let item = repo.new_item().expect("can't create item");
            Response::json(&item.id())
+        }
+        #[cfg(not(feature = "deprecated-items"))] {
+             Response::not_found()
+        }
         },
-        (POST) (/api/item/{id: String}/records) => {
+        (POST) (/api/item/{id: String}/records) => { // DEPRECATED
+        #[cfg(feature = "deprecated-items")] {
            if readonly { return Response::empty_404(); }
            use sit_core::{Item, Record};
            let mut item = match repo.item_iter().unwrap().find(|i| i.id() == id) {
@@ -244,93 +416,23 @@ pub fn start<A: ToSocketAddrs, MI: 'static + Send + Sync>(addr: A, config: sit_c
                 None => return Response::empty_404(),
            };
 
-           let mut multipart = get_multipart_input(&request).expect("multipart request");
-           let mut link = true;
-           let mut used_files = vec![];
-
-           loop {
-              let mut part = multipart.next();
-              if part.is_none() {
-                 break;
-              }
-              let mut field = part.unwrap();
-              loop {
-                 let path = {
-                     let mut file = field.data.as_file().expect("files only");
-                     let saved_file = file.save().temp().into_result().expect("can't save file");
-                     saved_file.path
-                 };
-                 if field.name.starts_with(".prev/") {
-                    link = false;
-                 }
-                 used_files.push((field.name.clone(), path));
-                 match field.next_entry_inplace() {
-                     Ok(Some(_)) => continue,
-                     Ok(None) => break,
-                     Err(e) => panic!(e),
-                 }
-              }
+           match new_record(&item, &request, &repo, &config) {
+               Ok(record) => Response::json(&record.encoded_hash()),
+               Err(_) => Response::text("Error").with_status_code(500),
            }
+        }
+        #[cfg(not(feature = "deprecated-items"))] {
+             Response::not_found()
+        }
+        },
+        (POST) (/api/records) => {
+           if readonly { return Response::empty_404(); }
+           use sit_core::Record;
 
-           let files: OrderedFiles<_> = used_files.iter().map(|(n, p)| (n.clone(), fs::File::open(p).expect("can't open saved file"))).into();
-           let files_: OrderedFiles<_> = used_files.iter().map(|(n, p)| (n.clone(), fs::File::open(p).expect("can't open saved file"))).into();
-
-           let files: OrderedFiles<_> = if config.signing.enabled {
-              use std::ffi::OsString;
-              use std::io::Write;
-              let program = super::gnupg(&config).unwrap();
-              let key = match config.signing.key.clone() {
-                  Some(key) => Some(OsString::from(key)),
-                  None => None,
-              };
-
-              let mut command = ::std::process::Command::new(program);
-
-              command
-                   .stdin(::std::process::Stdio::piped())
-                   .stdout(::std::process::Stdio::piped())
-                   .arg("--sign")
-                   .arg("--armor")
-                   .arg("--detach-sign")
-                   .arg("-o")
-                   .arg("-");
-
-              if key.is_some() {
-                   let _ = command.arg("--default-key").arg(key.unwrap());
-              }
-
-              let mut child = command.spawn().expect("failed spawning gnupg");
-
-              {
-                  let mut stdin = child.stdin.as_mut().expect("Failed to open stdin");
-                  let mut hasher = repo.config().hashing_algorithm().hasher();
-                  files_.hash(&mut *hasher).expect("failed hashing files");
-                  let hash = hasher.result_box();
-                  let encoded_hash = repo.config().encoding().encode(&hash);
-                  stdin.write_all(encoded_hash.as_bytes()).expect("Failed to write to stdin");
-              }
-
-              let output = child.wait_with_output().expect("failed to read stdout");
-
-              if !output.status.success() {
-                  eprintln!("Error: {}", String::from_utf8_lossy(&output.stderr));
-                  return Response::text(String::from_utf8_lossy(&output.stderr)).with_status_code(500);
-              } else {
-                 let sig: OrderedFiles<_> = vec![(String::from(".signature"), Cursor::new(output.stdout))].into();
-                 files + sig
-             }
-
-          } else {
-              files.boxed()
-          };
-
-          let record = item.new_record(files, link).expect("can't create record");
-
-          for (_, file) in used_files {
-            fs::remove_file(file).expect("can't remove file");
-          }
-
-          Response::json(&record.encoded_hash())
+           match new_record(&repo, &request, &repo, &config) {
+               Ok(record) => Response::json(&record.encoded_hash()),
+               Err(_) => Response::text("Error").with_status_code(500),
+           }
         },
         _ => {
         // Serve repository content
diff --git a/sit/Cargo.toml b/sit/Cargo.toml
index 9688438..391cbaf 100644
--- a/sit/Cargo.toml
+++ b/sit/Cargo.toml
@@ -27,6 +27,7 @@ atty = "0.2"
 thread_local = "0.3"
 derive-error = "0.0"
 directories = "1.0"
+itertools = "0.7"
 sit-core = { path = "../sit-core", version = "0.5.0-pre", features = ["git"] }
 
 [dev-dependencies]
@@ -35,4 +36,6 @@ git2 = { version = "0.7", default-features = false }
 remove_dir_all = "0.5"
 
 [features]
+default = ["deprecated-items"]
 windows7 = ["sit-core/windows7"]
+deprecated-items = ["sit-core/deprecated-item-api"]
diff --git a/sit/src/command_integrity.rs b/sit/src/command_integrity.rs
index ee7559a..c2c70ce 100644
--- a/sit/src/command_integrity.rs
+++ b/sit/src/command_integrity.rs
@@ -1,27 +1,46 @@
-use sit_core::{Item, Record, Repository};
+use sit_core::{Record, Repository, record::RecordContainer, hash::HashingAlgorithm};
+#[cfg(feature = "deprecated-items")]
 use rayon::prelude::*;
 
-pub fn command<MI: Send + Sync>(repo: Repository<MI>) -> i32 {
-    let items: Vec<_> = repo.item_iter().expect("can't list items").collect();
-    let valid = items.into_par_iter()
-        .map(|mut item| {
-            item.set_integrity_check(false);
-            let all_records: Vec<_> = item.record_iter().expect("can't list records").flat_map(|v| v).collect();
-            item.set_integrity_check(true);
-            let checked_records: Vec<_> = item.record_iter().expect("can't list records").flat_map(|v| v).collect();
-            let invalid_records: Vec<_> = all_records.into_iter()
-                .filter(|r| !checked_records.iter().any(|r_| r_.hash() == r.hash()))
-                .collect();
-            let valid = invalid_records.is_empty();
-            for record in invalid_records {
-                println!("{} {}", item.id(), record.encoded_hash());
-            }
-            valid
-        })
-        .reduce(|| true, |a, b| a && b);
-    if valid {
+pub fn command<MI: Send + Sync>(mut repo: Repository<MI>) -> i32 {
+    repo.set_integrity_check(false);
+    let hashing_algorithm = repo.config().hashing_algorithm().clone();
+    #[cfg(not(feature = "deprecated-items"))]
+    let invalid_records_in_items: Vec<String> = vec![];
+    #[cfg(feature = "deprecated-items")]
+    let (valid_items, invalid_records_in_items): (_, Vec<_>) = {
+        let items: Vec<_> = repo.item_iter().expect("can't list items").collect();
+        let results: Vec<_> = items.into_par_iter()
+            .flat_map(|item| {
+                 invalid_records(item, &hashing_algorithm).expect("can't list records")
+            }).collect();
+        let valid = results.is_empty();
+        for record in results.iter() {
+            println!("{} {}", record.item_id(), record.encoded_hash());
+        }
+        (valid, results.iter().map(|record| record.encoded_hash()).collect())
+    };
+    #[cfg(not(feature = "deprecated-items"))]
+    let valid_items = true;
+    let invalid_records = invalid_records(repo, &hashing_algorithm).expect("can't list records");
+    let valid = invalid_records.is_empty();
+    for record in invalid_records.iter().filter(|r| !invalid_records_in_items.iter().any(|r_| r_ == &r.encoded_hash())) {
+        println!("{}", record.encoded_hash());
+    }
+    if valid_items && valid {
         0
     } else {
         1
     }
-}
\ No newline at end of file
+}
+
+fn invalid_records<RC: RecordContainer>(container: RC, hashing_algorithm: &HashingAlgorithm) -> Result<Vec<RC::Record>, RC::Error> {
+    let all_records = container.record_iter()?;
+    for record in container.record_iter()?.flat_map(|v| v) {
+        eprintln!("{} {:?}", record.encoded_hash().as_ref(), record.integrity_intact(hashing_algorithm));
+    }
+    Ok(all_records.flat_map(|v| v)
+        .filter(|r| !r.integrity_intact(hashing_algorithm))
+        .collect())
+}
+
diff --git a/sit/src/command_items.rs b/sit/src/command_items.rs
index b290e7f..66cdf80 100644
--- a/sit/src/command_items.rs
+++ b/sit/src/command_items.rs
@@ -1,5 +1,5 @@
 use clap::ArgMatches;
-use sit_core::{self, reducers::duktape::DuktapeReducer, Repository, item::ItemReduction, cfg::Configuration};
+use sit_core::{self, reducers::duktape::DuktapeReducer, Repository, record::RecordContainerReduction, cfg::Configuration};
 use serde_json;
 use rayon::prelude::*;
 use super::get_named_expression;
@@ -32,8 +32,8 @@ pub fn command<MI: Send + Sync>(matches: &ArgMatches, repo: &Repository<MI>, con
     let filter = jmespath::compile(&filter_expr).expect("can't compile filter expression");
     let query = jmespath::compile(&query_expr).expect("can't compile query expression");
 
-    let tl_reducer : ThreadLocal<RefCell<DuktapeReducer<sit_core::repository::Record<MI>, MI>>> = ThreadLocal::new();
-    let reducer = Arc::new(Mutex::new(DuktapeReducer::new(&repo).unwrap()));
+    let tl_reducer : ThreadLocal<RefCell<DuktapeReducer<sit_core::repository::Record>>> = ThreadLocal::new();
+    let reducer = Arc::new(Mutex::new(DuktapeReducer::new(repo).unwrap()));
 
     items.into_par_iter()
         .map(|item| {
diff --git a/sit/src/command_record.rs b/sit/src/command_record.rs
index 5d72dd0..2573caf 100644
--- a/sit/src/command_record.rs
+++ b/sit/src/command_record.rs
@@ -5,8 +5,8 @@ use dunce;
 use serde_json;
 use sit_core::cfg::{self, Configuration};
 use sit_core::{
-    record::{BoxedOrderedFiles, OrderedFiles},
-    Item, Record, Repository,
+    record::{BoxedOrderedFiles, OrderedFiles, RecordOwningContainer},
+    Record, Repository
 };
 use std::env;
 use std::ffi::OsString;
@@ -14,17 +14,29 @@ use std::fs;
 use std::io::{self, Cursor, ErrorKind, Write};
 use std::path::{Path, PathBuf};
 use walkdir::{self as walk, WalkDir};
+use itertools::Itertools;
+
+#[cfg(feature = "deprecated-items")]
+pub const FILES_ARG: &str = "[Item ID (DEPRECATED)] FILES";
+#[cfg(not(feature = "deprecated-items"))]
+pub const FILES_ARG: &str = "FILES";
+
+#[cfg(feature = "deprecated-items")]
+pub const FILES_ARG_HELP: &str = "Optional item identifier followed by a collection of files or folders the record will be built from";
+#[cfg(not(feature = "deprecated-items"))]
+pub const FILES_ARG_HELP: &str = "Collection of files or folders the record will be built from";
 
 fn record_files(
-    matches: &ArgMatches,
+    matches: &ArgMatches, offset: usize,
     utc: DateTime<Utc>,
     config: &Configuration,
 ) -> Result<BoxedOrderedFiles<'static>, io::Error> {
     let files = matches
-        .values_of("FILES")
+        .values_of(FILES_ARG)
         .unwrap_or(clap::Values::default());
 
     let files: OrderedFiles<_> = files
+        .dropping(offset)
         .into_iter()
         .map(|name| {
             let path = PathBuf::from(&name);
@@ -157,72 +169,112 @@ pub fn command<P: AsRef<Path>, P1: AsRef<Path>, MI>(matches: &ArgMatches, repo:
         }
     }
 
-    let id = matches.value_of("id").unwrap();
-    match repo.item(id) {
-        None => {
-            eprintln!("Item {} not found", id);
+    #[cfg(feature = "deprecated-items")]
+    let offset = {
+        let item = matches.value_of(FILES_ARG)
+            // file with such a name doesn't exist
+            .and_then(|maybe_id|
+                if Path::new(maybe_id).exists() {
+                    None
+                } else {
+                    Some(maybe_id)
+                })
+            // item with such a name exists
+            .and_then(|id| repo.item(id));
+
+        let first_is_file = matches.value_of(FILES_ARG)
+            .and_then(|name|
+                if Path::new(name).exists() {
+                    Some(name)
+                } else {
+                    None
+                });
+
+        let val = matches.value_of(FILES_ARG).unwrap_or("<unknown>");
+
+        if matches.value_of(FILES_ARG).is_some() && item.is_none() && first_is_file.is_none() {
+            eprintln!("Item or file {} not found", val);
+            return 1;
+        }
+        if item.is_some() && first_is_file.is_some() {
+            eprintln!("Ambiguity detected: {} is both a file and an item identifier", val);
             return 1;
         }
-        Some(item) => {
-            let utc: DateTime<Utc> = Utc::now();
+        if item.is_some() {
+            1
+        } else {
+            0
+        }
+    };
+    #[cfg(not(feature = "deprecated-items"))]
+    let offset = 0;
 
-            let signing = matches.is_present("sign") || config.signing.enabled;
+    let utc: DateTime<Utc> = Utc::now();
 
-            let files = record_files(matches, utc, &config).expect("failed collecting files");
+    let signing = matches.is_present("sign") || config.signing.enabled;
 
-            let files = if signing {
-                use std::ffi::OsString;
-                let program = super::gnupg(matches, &config).expect("can't find GnuPG");
-                let key = match matches.value_of("signing-key").map(String::from).or_else(|| config.signing.key.clone()) {
-                    Some(key) => Some(OsString::from(key)),
-                    None => None,
-                };
-                let mut command = ::std::process::Command::new(program);
-
-                command
-                    .stdin(::std::process::Stdio::piped())
-                    .stdout(::std::process::Stdio::piped())
-                    .arg("--sign")
-                    .arg("--armor")
-                    .arg("--detach-sign")
-                    .arg("-o")
-                    .arg("-");
-
-                if key.is_some() {
-                    let _ = command.arg("--default-key").arg(key.unwrap());
-                }
+    let files = record_files(matches, offset, utc, &config).expect("failed collecting files");
 
-                let mut child = command.spawn().expect("failed spawning gnupg");
+    let files = if signing {
+        use std::ffi::OsString;
+        let program = super::gnupg(matches, &config).expect("can't find GnuPG");
+        let key = match matches.value_of("signing-key").map(String::from).or_else(|| config.signing.key.clone()) {
+            Some(key) => Some(OsString::from(key)),
+            None => None,
+        };
+        let mut command = ::std::process::Command::new(program);
 
-                {
-                    let mut stdin = child.stdin.as_mut().expect("Failed to open stdin");
-                    let mut hasher = repo.config().hashing_algorithm().hasher();
-                    files.hash(&mut *hasher).expect("failed hashing files");
-                    let hash = hasher.result_box();
-                    let encoded_hash = repo.config().encoding().encode(&hash);
-                    stdin.write_all(encoded_hash.as_bytes()).expect("Failed to write to stdin");
-                }
+        command
+            .stdin(::std::process::Stdio::piped())
+            .stdout(::std::process::Stdio::piped())
+            .arg("--sign")
+            .arg("--armor")
+            .arg("--detach-sign")
+            .arg("-o")
+            .arg("-");
 
-                let output = child.wait_with_output().expect("failed to read stdout");
+        if key.is_some() {
+            let _ = command.arg("--default-key").arg(key.unwrap());
+        }
 
-                if !output.status.success() {
-                    eprintln!("Error: {}", String::from_utf8_lossy(&output.stderr));
-                    return 1;
-                } else {
-                    let files = record_files(matches, utc, &config).expect("failed collecting files");
-                    let signature_file: OrderedFiles<(String, _)> = vec![(String::from(".signature"), Cursor::new(output.stdout))].into();
-                    files + signature_file
-                }
+        let mut child = command.spawn().expect("failed spawning gnupg");
 
-            } else {
-                files
-            };
+        {
+            let mut stdin = child.stdin.as_mut().expect("Failed to open stdin");
+            let mut hasher = repo.config().hashing_algorithm().hasher();
+            files.hash(&mut *hasher).expect("failed hashing files");
+            let hash = hasher.result_box();
+            let encoded_hash = repo.config().encoding().encode(&hash);
+            stdin.write_all(encoded_hash.as_bytes()).expect("Failed to write to stdin");
+        }
 
-            let record = item.new_record(files, true).expect("can't create a record");
+        let output = child.wait_with_output().expect("failed to read stdout");
 
-            println!("{}", record.encoded_hash());
+        if !output.status.success() {
+            eprintln!("Error: {}", String::from_utf8_lossy(&output.stderr));
+            return 1;
+        } else {
+            let files = record_files(matches, offset, utc, &config).expect("failed collecting files");
+            let signature_file: OrderedFiles<(String, _)> = vec![(String::from(".signature"), Cursor::new(output.stdout))].into();
+            files + signature_file
         }
-    }
+
+    } else {
+        files
+    };
+
+    let record = if offset == 1 { // item
+        let item = matches.value_of(FILES_ARG)
+            .and_then(|id| repo.item(id))
+            .unwrap();
+
+        item.new_record(files, true).expect("can't create a record")
+    } else { // repo
+        repo.new_record(files, true).expect("can't create a record")
+    };
+
+    println!("{}", record.encoded_hash());
+
     return 0;
 }
 
diff --git a/sit/src/command_records.rs b/sit/src/command_records.rs
index 9245361..7fe3fd0 100644
--- a/sit/src/command_records.rs
+++ b/sit/src/command_records.rs
@@ -1,104 +1,115 @@
 use clap::ArgMatches;
-use sit_core::{Repository, Record, Item, cfg::Configuration, record::OrderedFiles, path::HasPath};
+use sit_core::{Repository, Record, cfg::Configuration, record::RecordContainer, record::OrderedFiles, path::HasPath};
 use serde_json;
 use super::get_named_expression;
 use jmespath;
 use super::gnupg;
+use serde;
 
-pub fn command<MI>(matches: &ArgMatches, repo: &Repository<MI>, config: Configuration) -> i32 {
-    let id = matches.value_of("id").unwrap();
-    match repo.item(id) {
-        None => {
-            eprintln!("Item {} not found", id);
-            return 1;
-        },
-        Some(item) => {
-            let records = item.record_iter().expect("can't lis records");
-
-            let filter_expr = matches.value_of("named-filter")
-                .and_then(|name|
-                    get_named_expression(name, &repo, ".records/filters", &config.records.filters))
-                .or_else(|| matches.value_of("filter").or_else(|| Some("type(@) == 'object'")).map(String::from))
-                .unwrap();
-
-            let filter_defined = matches.is_present("named-filter") || matches.is_present("filter");
-
-            let query_expr = matches.value_of("named-query")
-                .and_then(|name|
-                    get_named_expression(name, &repo, ".records/queries", &config.records.queries))
-                .or_else(|| matches.value_of("query").or_else(|| Some("hash")).map(String::from))
-                .unwrap();
-
-            let filter = jmespath::compile(&filter_expr).expect("can't compile filter expression");
-            let query = jmespath::compile(&query_expr).expect("can't compile query expression");
-
-            for record in records {
-                for rec in record {
-                    // convert to JSON
-                    let json = serde_json::to_string(&rec).unwrap();
-                    // ...and back so that we can treat the record as a plain JSON
-                    let mut json: serde_json::Value = serde_json::from_str(&json).unwrap();
-                    if let serde_json::Value::Object(ref mut map) = json {
-                        let verify = matches.is_present("verify") && rec.path().join(".signature").is_file();
-
-                        if verify {
-                            let program = gnupg(matches, &config).expect("can't find GnuPG");
-                            let mut command = ::std::process::Command::new(program);
-
-                            command
-                                .stdin(::std::process::Stdio::piped())
-                                .stdout(::std::process::Stdio::piped())
-                                .stderr(::std::process::Stdio::piped())
-                                .arg("--verify")
-                                .arg(rec.path().join(".signature"))
-                                .arg("-");
-
-                            let mut child = command.spawn().expect("failed spawning gnupg");
-
-                            {
-                                let files: OrderedFiles<_> = rec.file_iter().into();
-                                let files = files - ".signature";
-                                let mut hasher = repo.config().hashing_algorithm().hasher();
-                                files.hash(&mut *hasher).expect("failed hashing files");
-                                let hash = hasher.result_box();
-                                let encoded_hash = repo.config().encoding().encode(&hash);
-                                use std::io::Write;
-                                let mut stdin = child.stdin.as_mut().expect("Failed to open stdin");
-                                stdin.write_all(encoded_hash.as_bytes()).expect("Failed to write to stdin");
-                            }
-
-                            let output = child.wait_with_output().expect("failed to read stdout");
-
-                            if !output.status.success() {
-                                let mut status = serde_json::Map::new();
-                                status.insert("success".into(), serde_json::Value::Bool(false));
-                                status.insert("output".into(), serde_json::Value::String(String::from_utf8_lossy(&output.stderr).into()));
-                                map.insert("verification".into(), serde_json::Value::Object(status));
-                            } else {
-                                let mut status = serde_json::Map::new();
-                                status.insert("success".into(), serde_json::Value::Bool(true));
-                                status.insert("output".into(), serde_json::Value::String(String::from_utf8_lossy(&output.stderr).into()));
-                                map.insert("verification".into(), serde_json::Value::Object(status));
-                            }
-
-                        }
+pub fn command<MI>(matches: &ArgMatches, repo: Repository<MI>, config: Configuration) -> i32 {
+    #[cfg(feature = "deprecated-items")] {
+        if matches.is_present("id") {
+            let id = matches.value_of("id").unwrap();
+            match repo.item(id) {
+                None => {
+                    eprintln!("Item {} not found", id);
+                    return 1;
+                },
+                Some(item) => {
+                    return list(matches, &item, &repo, config);
+                }
+            }
+        }
+    }
+    list(matches, &repo, &repo, config)
+}
+
+fn list<R: RecordContainer, MI>(matches: &ArgMatches, iter: &R, repo: &Repository<MI>, config: Configuration) -> i32
+    where <R as RecordContainer>::Record: serde::Serialize + HasPath {
+    let records = iter.record_iter().expect("can't list records");
+
+    let filter_expr = matches.value_of("named-filter")
+        .and_then(|name|
+            get_named_expression(name, &repo, ".records/filters", &config.records.filters))
+        .or_else(|| matches.value_of("filter").or_else(|| Some("type(@) == 'object'")).map(String::from))
+        .unwrap();
+
+    let filter_defined = matches.is_present("named-filter") || matches.is_present("filter");
+
+    let query_expr = matches.value_of("named-query")
+        .and_then(|name|
+            get_named_expression(name, &repo, ".records/queries", &config.records.queries))
+        .or_else(|| matches.value_of("query").or_else(|| Some("hash")).map(String::from))
+        .unwrap();
+
+    let filter = jmespath::compile(&filter_expr).expect("can't compile filter expression");
+    let query = jmespath::compile(&query_expr).expect("can't compile query expression");
 
+    for record in records {
+        for rec in record {
+            // convert to JSON
+            let json = serde_json::to_string(&rec).unwrap();
+            // ...and back so that we can treat the record as a plain JSON
+            let mut json: serde_json::Value = serde_json::from_str(&json).unwrap();
+            if let serde_json::Value::Object(ref mut map) = json {
+                let verify = matches.is_present("verify") && rec.path().join(".signature").is_file();
+
+                if verify {
+                    let program = gnupg(matches, &config).expect("can't find GnuPG");
+                    let mut command = ::std::process::Command::new(program);
+
+                    command
+                        .stdin(::std::process::Stdio::piped())
+                        .stdout(::std::process::Stdio::piped())
+                        .stderr(::std::process::Stdio::piped())
+                        .arg("--verify")
+                        .arg(rec.path().join(".signature"))
+                        .arg("-");
+
+                    let mut child = command.spawn().expect("failed spawning gnupg");
+
+                    {
+                        let files: OrderedFiles<_> = rec.file_iter().into();
+                        let files = files - ".signature";
+                        let mut hasher = repo.config().hashing_algorithm().hasher();
+                        files.hash(&mut *hasher).expect("failed hashing files");
+                        let hash = hasher.result_box();
+                        let encoded_hash = repo.config().encoding().encode(&hash);
+                        use std::io::Write;
+                        let mut stdin = child.stdin.as_mut().expect("Failed to open stdin");
+                        stdin.write_all(encoded_hash.as_bytes()).expect("Failed to write to stdin");
                     }
 
-                    let data = jmespath::Variable::from(json);
-                    let result = if filter_defined {
-                        filter.search(&data).unwrap().as_boolean().unwrap()
+                    let output = child.wait_with_output().expect("failed to read stdout");
+
+                    if !output.status.success() {
+                        let mut status = serde_json::Map::new();
+                        status.insert("success".into(), serde_json::Value::Bool(false));
+                        status.insert("output".into(), serde_json::Value::String(String::from_utf8_lossy(&output.stderr).into()));
+                        map.insert("verification".into(), serde_json::Value::Object(status));
                     } else {
-                        true
-                    };
-                    if result {
-                        let view = query.search(&data).unwrap();
-                        if view.is_string() {
-                            println!("{}", view.as_string().unwrap());
-                        } else {
-                            println!("{}", serde_json::to_string_pretty(&view).unwrap());
-                        }
+                        let mut status = serde_json::Map::new();
+                        status.insert("success".into(), serde_json::Value::Bool(true));
+                        status.insert("output".into(), serde_json::Value::String(String::from_utf8_lossy(&output.stderr).into()));
+                        map.insert("verification".into(), serde_json::Value::Object(status));
                     }
+
+                }
+
+            }
+
+            let data = jmespath::Variable::from(json);
+            let result = if filter_defined {
+                filter.search(&data).unwrap().as_boolean().unwrap()
+            } else {
+                true
+            };
+            if result {
+                let view = query.search(&data).unwrap();
+                if view.is_string() {
+                    println!("{}", view.as_string().unwrap());
+                } else {
+                    println!("{}", serde_json::to_string_pretty(&view).unwrap());
                 }
             }
         }
diff --git a/sit/src/command_reduce.rs b/sit/src/command_reduce.rs
index 31d2508..6bbd1a2 100644
--- a/sit/src/command_reduce.rs
+++ b/sit/src/command_reduce.rs
@@ -1,38 +1,89 @@
-use clap::ArgMatches;
-use sit_core::{self, Repository, item::ItemReduction, cfg::Configuration};
+use clap::{ArgMatches, Values};
+use sit_core::{self, Repository, record::RecordContainerReduction, repository, cfg::Configuration,
+               reducers::duktape, path::{HasPath, ResolvePath}};
+
 use serde_json;
 use super::get_named_expression;
 use jmespath;
 use std::path::PathBuf;
 
-pub fn command<MI>(matches: &ArgMatches, repo: &Repository<MI>, config: Configuration) -> i32
-    where MI: sit_core::repository::ModuleIterator<PathBuf, sit_core::repository::Error> {
-    let id = matches.value_of("id").unwrap();
-    match repo.item(id) {
-        None => {
-            eprintln!("Item {} not found", id);
-            return 1;
-        },
-        Some(item) => {
-            let query_expr = matches.value_of("named-query")
-                .and_then(|name|
-                    get_named_expression(name, &repo, ".items/queries", &config.items.queries))
-                .or_else(|| matches.value_of("query").or_else(|| Some("@")).map(String::from))
-                .unwrap();
-
-            let query = jmespath::compile(&query_expr).expect("can't compile query expression");
-
-            let mut reducer = sit_core::reducers::duktape::DuktapeReducer::new(&repo).unwrap();
-            let result = item.reduce_with_reducer(&mut reducer).expect("can't reduce item");
-            let data = jmespath::Variable::from(serde_json::Value::Object(result));
-            let view = query.search(&data).unwrap();
-            if view.is_string() {
-                println!("{}", view.as_string().unwrap());
+pub fn command<MI>(matches: &ArgMatches, repo: Repository<MI>, config: Configuration) -> i32
+    where MI: repository::ModuleIterator<PathBuf, repository::Error> {
+    if let Some(vals) = matches.values_of_os("reducer") {
+        let reducers_path = repo.path().join("reducers");
+        let reducers = vals.map(PathBuf::from)
+            .map(|p| if p.is_file() {
+                p
+            } else if reducers_path.join(&p).resolve_dir().unwrap().is_dir() {
+                let dir = reducers_path.join(&p).resolve_dir().unwrap();
+                dir
             } else {
-                println!("{}", serde_json::to_string_pretty(&view).unwrap());
-            }
+                p
+            });
+        command_impl(matches, &repo, config, reducers)
+    } else {
+        command_impl(matches, &repo, config, &repo)
+    }
+}
+
+fn command_impl<MI, SF>(matches: &ArgMatches, repo: &Repository<MI>, config: Configuration, source_files: SF) -> i32
+    where MI: repository::ModuleIterator<PathBuf, repository::Error>, SF: duktape::SourceFiles {
+
+    let fixed_roots = matches.values_of("root");
+    let state = matches.value_of("state").map(serde_json::from_str).filter(Result::is_ok).map(Result::unwrap);
+
+    #[cfg(feature = "deprecated-items")] {
+        if let Some(id) = matches.value_of("id") {
+            match repo.item(id) {
+                None => {
+                    eprintln!("Item {} not found", id);
+                    return 1;
+                },
+                Some(item) => {
+                    let query_expr = matches.value_of("named-query")
+                        .and_then(|name|
+                            get_named_expression(name, repo, ".items/queries", &config.items.queries))
+                        .or_else(|| matches.value_of("query").or_else(|| Some("@")).map(String::from))
+                        .unwrap();
 
+                    reduce(&query_expr, &item, source_files, fixed_roots, state);
+                    return 0;
+                }
+            }
         }
     }
+
+    let query_expr = matches.value_of("named-query")
+        .and_then(|name|
+            get_named_expression(name, repo, ".queries", &config.items.queries))
+        .or_else(|| matches.value_of("query").or_else(|| Some("@")).map(String::from))
+        .unwrap();
+
+    reduce(&query_expr, repo, source_files, fixed_roots, state);
+
     return 0;
 }
+
+fn reduce<RCR: RecordContainerReduction<Record = repository::Record>, SF: duktape::SourceFiles>
+    (query_expr: &str, container: &RCR, source_files: SF, roots: Option<Values>, state: Option<serde_json::Value>) {
+    let mut reducer = sit_core::reducers::duktape::DuktapeReducer::new(source_files).unwrap();
+    let query = jmespath::compile(&query_expr).expect("can't compile query expression");
+    let state = container.initialize_state(match state {
+        None => Default::default(),
+        Some(s) => s.as_object().unwrap().to_owned(),
+    });
+    let result = match roots {
+        None => container.reduce_with_reducer_and_state(&mut reducer, state).expect("can't reduce"),
+        Some(fixed_roots) => {
+            let container = container.fixed_roots(fixed_roots);
+            container.reduce_with_reducer_and_state(&mut reducer, state).expect("can't reduce")
+        },
+    };
+    let data = jmespath::Variable::from(serde_json::Value::Object(result));
+    let view = query.search(&data).unwrap();
+    if view.is_string() {
+        println!("{}", view.as_string().unwrap());
+    } else {
+        println!("{}", serde_json::to_string_pretty(&view).unwrap());
+    }
+}
diff --git a/sit/src/main.rs b/sit/src/main.rs
index 95f58c1..a4ee1c6 100644
--- a/sit/src/main.rs
+++ b/sit/src/main.rs
@@ -57,6 +57,7 @@ extern crate thread_local;
 
 #[macro_use] extern crate derive_error;
 extern crate directories;
+extern crate itertools;
 
 use std::collections::HashMap;
 pub fn get_named_expression<S: AsRef<str>, MI>(name: S, repo: &sit_core::Repository<MI>,
@@ -89,6 +90,19 @@ use module_iter::ScriptModule;
 
 use sit_core::path::HasPath;
 
+trait ConditionalChain : Sized {
+    fn conditionally<F: Fn(Self) -> Self>(self, cond: bool, f: F) -> Self {
+        if cond {
+            f(self)
+        } else {
+            self
+        }
+    }
+}
+
+impl<T> ConditionalChain for T where T : Sized {
+}
+
 fn main() {
     exit(main_with_result(true));
 }
@@ -145,7 +159,12 @@ fn main_with_result(allow_external_subcommands: bool) -> i32 {
             .about("(Re)-populate default files in the repository (such as reducers)"))
         .subcommand(SubCommand::with_name("path")
             .settings(&[clap::AppSettings::ColoredHelp, clap::AppSettings::ColorAuto])
-            .about("Prints the path to the repository"))
+            .arg(Arg::with_name("record")
+                .long("record")
+                .short("r")
+                .takes_value(true)
+                .help("Path to the record"))
+            .about("Prints the path to the repository and its individual components"))
         .subcommand(SubCommand::with_name("rebuild")
             .settings(&[clap::AppSettings::ColoredHelp, clap::AppSettings::ColorAuto])
             .about("Rebuild a repository")
@@ -164,48 +183,46 @@ fn main_with_result(allow_external_subcommands: bool) -> i32 {
                      .takes_value(true)
                      .long_help("Execute this command on every record before re-hashing it. \
                      The directory is passed as the first argument.")))
-        .subcommand(SubCommand::with_name("item")
+        .conditionally(cfg!(feature = "deprecated-items"), |app|
+        app.subcommand(SubCommand::with_name("item")
             .settings(&[clap::AppSettings::ColoredHelp, clap::AppSettings::ColorAuto])
             .about("Creates a new item")
             .arg(Arg::with_name("id")
                      .long("id")
                      .takes_value(true)
                      .required(false)
-                     .help("Specify item identifier, otherwise generate automatically")))
-        .subcommand(SubCommand::with_name("items")
-            .settings(&[clap::AppSettings::ColoredHelp, clap::AppSettings::ColorAuto])
-            .about("Lists items")
-            .arg(Arg::with_name("filter")
-                     .conflicts_with("named-filter")
-                     .long("filter")
-                     .short("f")
-                     .takes_value(true)
-                     .help("Filter items with a JMESPath query"))
-            .arg(Arg::with_name("query")
-                     .conflicts_with("named-query")
-                     .long("query")
-                     .short("q")
-                     .takes_value(true)
-                     .help("Render a result of a JMESPath query over the item (defaults to `id`)"))
-            .arg(Arg::with_name("named-filter")
-                     .conflicts_with("filter")
-                     .long("named-filter")
-                     .short("F")
-                     .takes_value(true)
-                     .help("Filter items with a named JMESPath query"))
-            .arg(Arg::with_name("named-query")
-                     .conflicts_with("query")
-                     .long("named-query")
-                     .short("Q")
-                     .takes_value(true)
-                     .help("Render a result of a named JMESPath query over the item")))
+                     .help("Specify item identifier, otherwise generate automatically"))))
+        .conditionally(cfg!(feature = "deprecated-items"), |app|
+        app.subcommand(SubCommand::with_name("items")
+               .settings(&[clap::AppSettings::ColoredHelp, clap::AppSettings::ColorAuto])
+               .about("Lists items (DEPRECATED)")
+               .arg(Arg::with_name("filter")
+                   .conflicts_with("named-filter")
+                   .long("filter")
+                   .short("f")
+                   .takes_value(true)
+                   .help("Filter items with a JMESPath query"))
+               .arg(Arg::with_name("query")
+                   .conflicts_with("named-query")
+                   .long("query")
+                   .short("q")
+                   .takes_value(true)
+                   .help("Render a result of a JMESPath query over the item (defaults to `id`)"))
+               .arg(Arg::with_name("named-filter")
+                   .conflicts_with("filter")
+                   .long("named-filter")
+                   .short("F")
+                   .takes_value(true)
+                   .help("Filter items with a named JMESPath query"))
+               .arg(Arg::with_name("named-query")
+                   .conflicts_with("query")
+                   .long("named-query")
+                   .short("Q")
+                   .takes_value(true)
+                   .help("Render a result of a named JMESPath query over the item"))))
         .subcommand(SubCommand::with_name("record")
             .settings(&[clap::AppSettings::ColoredHelp, clap::AppSettings::ColorAuto])
             .about("Creates a new record")
-            .arg(Arg::with_name("id")
-                     .takes_value(true)
-                     .required(true)
-                     .help("Item identifier"))
             .arg(Arg::with_name("type")
                 .short("t")
                 .long("type")
@@ -236,17 +253,17 @@ fn main_with_result(allow_external_subcommands: bool) -> i32 {
                 .requires("sign")
                 .takes_value(true)
                 .help("Specify gnupg command (`gpg` by default or overridden by config's signing.gnupg)"))
-            .arg(Arg::with_name("FILES")
+            .arg(Arg::with_name(command_record::FILES_ARG)
                      .multiple(true)
                      .takes_value(true)
-                     .help("Collection of files or folders the record will be built from")))
+                     .help(command_record::FILES_ARG_HELP)))
         .subcommand(SubCommand::with_name("records")
             .settings(&[clap::AppSettings::ColoredHelp, clap::AppSettings::ColorAuto])
             .about("Lists records")
-            .arg(Arg::with_name("id")
+            .conditionally(cfg!(feature = "deprecated-items"), |app|
+            app.arg(Arg::with_name("id")
                      .takes_value(true)
-                     .required(true)
-                     .help("Item identifier"))
+                     .help("Item identifier (DEPRECATED)")))
             .arg(Arg::with_name("filter")
                      .conflicts_with("named-filter")
                      .long("filter")
@@ -281,23 +298,48 @@ fn main_with_result(allow_external_subcommands: bool) -> i32 {
                      .takes_value(true)
                      .help("Render a result of a named JMESPath query over the record")))
         .subcommand(SubCommand::with_name("reduce")
-            .about("Reduce item records")
-            .arg(Arg::with_name("id")
+            .about("Reduce records")
+            .conditionally(cfg!(feature = "deprecated-items"), |app|
+            app.arg(Arg::with_name("id")
                      .takes_value(true)
-                     .required(true)
-                     .help("Item identifier"))
+                     .help("Item identifier (DEPRECATED)")))
+            .arg(Arg::with_name("reducer")
+                 .short("r")
+                 .long("reducer")
+                 .takes_value(true)
+                 .multiple(true)
+                 .help("Specifies custom reducers to be used (instead of default ones in reducers/)"))
+            .arg(Arg::with_name("root")
+                 .long("root")
+                 .short("R")
+                 .takes_value(true)
+                 .multiple(true)
+                 .help("Specifies fixed roots to begin the reduction from"))
+            .arg(Arg::with_name("format")
+                 .short("f")
+                 .long("format")
+                 .default_value("json")
+                 .possible_values(&["json"])
+                 .help("State's format"))
+            .arg(Arg::with_name("state")
+                 .short("s")
+                 .long("state")
+                 .takes_value(true)
+                 .validator(|v| serde_json::from_str(&v).map_err(|e| format!("JSON parsing error: {}", e))
+                                .and_then(|v: serde_json::Value| if v.is_object() { Ok(()) } else { Err(format!("Expected JSON object, got {}", v)) }))
+                 .help("Initial state"))
             .arg(Arg::with_name("query")
                      .conflicts_with("named-query")
                      .long("query")
                      .short("q")
                      .takes_value(true)
-                     .help("Render a result of a JMESPath query over the item (defaults to `@`)"))
+                     .help("Render a result of a JMESPath query (defaults to `@`)"))
             .arg(Arg::with_name("named-query")
                      .conflicts_with("query")
                      .long("named-query")
                      .short("Q")
                      .takes_value(true)
-                     .help("Render a result of a named JMESPath query over the item")))
+                     .help("Render a result of a named JMESPath query")))
         .subcommand(SubCommand::with_name("config")
             .about("Prints configuration file")
             .arg(Arg::with_name("kind")
@@ -445,9 +487,22 @@ fn main_with_result(allow_external_subcommands: bool) -> i32 {
             if let Some(_) = matches.subcommand_matches("populate-files") {
                 repo.populate_default_files().expect("can't populate default files");
                 return 0;
-            } else if let Some(_) = matches.subcommand_matches("path") {
-                println!("{}", repo.path().to_str().unwrap());
-                return 0;
+            } else if let Some(matches) = matches.subcommand_matches("path") {
+                if let Some(id) = matches.value_of("record") {
+                    match repo.record(id) {
+                        None => {
+                            eprintln!("Record {} not found", id);
+                            return 1;
+                        },
+                        Some(record) => {
+                            println!("{}", record.path().to_str().unwrap());
+                            return 0;
+                        }
+                    }
+                } else {
+                    println!("{}", repo.path().to_str().unwrap());
+                    return 0;
+                }
             } else if let Some(matches) = matches.subcommand_matches("item") {
                 return command_item::command(matches, &repo);
             }
@@ -461,11 +516,11 @@ fn main_with_result(allow_external_subcommands: bool) -> i32 {
             }
 
             if let Some(matches) = matches.subcommand_matches("records") {
-                return command_records::command(matches, &repo, config);
+                return command_records::command(matches, repo, config);
             }
 
             if let Some(matches) = matches.subcommand_matches("reduce") {
-                return command_reduce::command(matches, &repo, config);
+                return command_reduce::command(matches, repo, config);
             }
 
             if let Some(matches) = matches.subcommand_matches("config") {
diff --git a/sit/src/rebuild.rs b/sit/src/rebuild.rs
index 008704c..d6cab09 100644
--- a/sit/src/rebuild.rs
+++ b/sit/src/rebuild.rs
@@ -2,7 +2,7 @@ use std::path::PathBuf;
 use std::fs;
 use std::ffi::OsString;
 use fs_extra;
-use sit_core::{Repository, Item, Record, path::HasPath};
+use sit_core::{Repository, Item, Record, record::RecordOwningContainer, record::RecordContainer, path::HasPath};
 use pbr::ProgressBar;
 use tempdir::TempDir;
 use glob;
@@ -19,7 +19,7 @@ pub fn rebuild_repository<S: Into<PathBuf>>(src: S, dest: S, on_record: Option<S
     let src = Repository::open(src).expect("can't open source repository");
     let dest = Repository::new_with_config(dest, src.config().clone())
         .expect("can't create destination repository");
-    // Copy all files and directories except for `config` and `items`
+    // Copy all files and directories except for `config`, `items` and `records`
     print!("Copying all supplementary files: ");
     let dir = fs::read_dir(src.path()).expect("can't read source repository record");
     dir.filter(Result::is_ok)
@@ -28,7 +28,8 @@ pub fn rebuild_repository<S: Into<PathBuf>>(src: S, dest: S, on_record: Option<S
             let file_name = f.file_name();
             let name = file_name.to_str().unwrap();
             name != "config.json" &&
-                name != "items"
+            name != "items" &&
+            name != "records"
         })
         .for_each(|f| {
             let file_name = f.file_name();
diff --git a/sit/tests/command_integrity.rs b/sit/tests/command_integrity.rs
index a2fbd0f..af7a75d 100644
--- a/sit/tests/command_integrity.rs
+++ b/sit/tests/command_integrity.rs
@@ -1,11 +1,16 @@
 extern crate cli_test_dir;
+extern crate sit_core;
 
+use sit_core::{Repository, path::HasPath};
+#[cfg(feature = "deprecated-items")]
+use sit_core::path::ResolvePath;
 use cli_test_dir::*;
 
 /// Should list records with failed integrity check
 #[test]
-fn integrity_failure() {
-    let dir = TestDir::new("sit", "integrity_failure");
+#[cfg(feature = "deprecated-items")]
+fn integrity_failure_item() {
+    let dir = TestDir::new("sit", "integrity_failure_item");
     dir.cmd()
         .arg("init")
         .expect_success();
@@ -21,7 +26,7 @@ fn integrity_failure() {
     // at this point, integrity check should not fail
     dir.cmd().arg("integrity").expect_success();
     // now, lets tamper with the record
-    dir.create_file(dir.path(".sit/items").join(id.trim()).join(record.trim()).join("tamper"), "");
+    dir.create_file(dir.path(".sit/items").join(id.trim()).join(record.trim()).resolve_dir().unwrap().join("tamper"), "");
     // now, integrity check should fail
     // (we event set -i/--disable-integrity-check to make sure the command works with integrity check
     //  suppressed from the command line)
@@ -29,10 +34,37 @@ fn integrity_failure() {
     assert_eq!(output, format!("{} {}\n", id.trim(), record.trim()));
 }
 
+/// Should list records with failed integrity check
+#[test]
+fn integrity_failure() {
+    let dir = TestDir::new("sit", "integrity_failure");
+    dir.cmd()
+        .arg("init")
+        .expect_success();
+    // create a record
+    let record = String::from_utf8(dir.cmd()
+        .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
+        .args(&["record", "--no-author", "-t", "Sometype"])
+        .expect_success().stdout).unwrap();
+    // at this point, integrity check should not fail
+    dir.cmd().arg("integrity").expect_success();
+    // now, lets tamper with the record
+    let repo = Repository::open(dir.path(".sit")).unwrap();
+    let rec = repo.record(record.trim()).unwrap();
+    dir.create_file(rec.path().join("tamper"), "");
+    // now, integrity check should fail
+    // (we event set -i/--disable-integrity-check to make sure the command works with integrity check
+    //  suppressed from the command line)
+    let output = String::from_utf8(dir.cmd().args(&["-i", "integrity"]).expect_failure().stdout).unwrap();
+    assert_eq!(output, format!("{}\n", record.trim()));
+}
+
+
 /// Should not list records with failed integrity check unless it is disabled
 #[test]
-fn integrity_check_flag() {
-    let dir = TestDir::new("sit", "integrity_pass");
+#[cfg(feature = "deprecated-items")]
+fn integrity_check_flag_item() {
+    let dir = TestDir::new("sit", "integrity_pass_item");
     dir.cmd()
         .arg("init")
         .expect_success();
@@ -46,7 +78,7 @@ fn integrity_check_flag() {
         .args(&["record", id.trim(), "--no-author", "-t", "Sometype"])
         .expect_success().stdout).unwrap();
     // now, lets tamper with the record
-    dir.create_file(dir.path(".sit/items").join(id.trim()).join(record.trim()).join("tamper"), "");
+    dir.create_file(dir.path(".sit/items").join(id.trim()).join(record.trim()).resolve_dir().unwrap().join("tamper"), "");
     // now, the record should not appear
     let output = String::from_utf8(dir.cmd().args(&["records", id.trim()]).expect_success().stdout).unwrap();
     assert_eq!(output, "");
@@ -57,3 +89,30 @@ fn integrity_check_flag() {
      let output = String::from_utf8(dir.cmd().env("SIT_DISABLE_INTEGRITY_CHECK", "1").args(&["records", id.trim()]).expect_success().stdout).unwrap();
     assert_eq!(output, format!("{}\n", record.trim()));
 }
+
+/// Should not list records with failed integrity check unless it is disabled
+#[test]
+fn integrity_check_flag() {
+    let dir = TestDir::new("sit", "integrity_pass");
+    dir.cmd()
+        .arg("init")
+        .expect_success();
+    // create a record
+    let record = String::from_utf8(dir.cmd()
+        .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
+        .args(&["record", "--no-author", "-t", "Sometype"])
+        .expect_success().stdout).unwrap();
+    // now, lets tamper with the record
+    let repo = Repository::open(dir.path(".sit")).unwrap();
+    let rec = repo.record(record.trim()).unwrap();
+    dir.create_file(rec.path().join("tamper"), "");
+    // now, the record should not appear
+    let output = String::from_utf8(dir.cmd().args(&["records"]).expect_success().stdout).unwrap();
+    assert_eq!(output, "");
+    // but if we disable integrity check:
+    let output = String::from_utf8(dir.cmd().args(&["-i", "records"]).expect_success().stdout).unwrap();
+    assert_eq!(output, format!("{}\n", record.trim()));
+    // or if we disable it through env:
+     let output = String::from_utf8(dir.cmd().env("SIT_DISABLE_INTEGRITY_CHECK", "1").args(&["records"]).expect_success().stdout).unwrap();
+    assert_eq!(output, format!("{}\n", record.trim()));
+}
diff --git a/sit/tests/command_item.rs b/sit/tests/command_item.rs
index 03fb540..45e0b2f 100644
--- a/sit/tests/command_item.rs
+++ b/sit/tests/command_item.rs
@@ -1,11 +1,15 @@
 extern crate cli_test_dir;
 extern crate sit_core;
 
+
+#[cfg(feature = "deprecated-items")]
 use cli_test_dir::*;
+#[cfg(feature = "deprecated-items")]
 use sit_core::{Repository, Item};
 
 /// Should create an item
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item() {
     let dir = TestDir::new("sit", "item");
     dir.cmd()
@@ -21,6 +25,7 @@ fn item() {
 
 /// Should create a named item
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item_named() {
     let dir = TestDir::new("sit", "item_named");
     dir.cmd()
@@ -38,6 +43,7 @@ fn item_named() {
 /// Should fail if creating a named item with a duplicate name
 /// (item with such name already exists)
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item_existing() {
     let dir = TestDir::new("sit", "existing");
     dir.cmd()
diff --git a/sit/tests/command_items.rs b/sit/tests/command_items.rs
index 0a614d3..4e1e8c5 100644
--- a/sit/tests/command_items.rs
+++ b/sit/tests/command_items.rs
@@ -1,14 +1,17 @@
 extern crate cli_test_dir;
 extern crate sit_core;
 
-use sit_core::{Repository, Item};
-
+#[cfg(feature = "deprecated-items")]
+use sit_core::{Repository, record::RecordOwningContainer};
+#[cfg(feature = "deprecated-items")]
 use cli_test_dir::*;
 
+#[cfg(feature = "deprecated-items")]
 include!("includes/config.rs");
 
 /// Should list no items if there are none
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn no_items() {
     let dir = TestDir::new("sit", "no_items");
     dir.cmd()
@@ -20,6 +23,7 @@ fn no_items() {
 
 /// Should list an item if there's one
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item() {
     let dir = TestDir::new("sit", "item");
     dir.cmd()
@@ -32,6 +36,7 @@ fn item() {
 
 /// Should apply filter
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item_filter() {
     let dir = TestDir::new("sit", "filter");
     dir.cmd()
@@ -46,6 +51,7 @@ fn item_filter() {
 
 /// Should apply named filter
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item_named_filter() {
     let dir = TestDir::new("sit", "named_filter");
     dir.cmd()
@@ -61,6 +67,7 @@ fn item_named_filter() {
 
 /// Should apply named filter
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item_named_user_filter() {
     let dir = TestDir::new("sit", "named_user_filter");
     dir.cmd()
@@ -80,6 +87,7 @@ fn item_named_user_filter() {
 
 /// Should prefer repo named filter over user named filer
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item_repo_over_named_user_filter() {
     let dir = TestDir::new("sit", "named_repo_over_user_filter");
     dir.cmd()
@@ -101,6 +109,7 @@ fn item_repo_over_named_user_filter() {
 
 /// Should apply query
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item_query() {
     let dir = TestDir::new("sit", "query");
     dir.cmd()
@@ -120,6 +129,7 @@ fn item_query() {
 
 /// Should apply named query
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item_named_query() {
     let dir = TestDir::new("sit", "named_query");
     dir.cmd()
@@ -140,6 +150,7 @@ fn item_named_query() {
 
 /// Should apply named user query
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item_named_user_query() {
     let dir = TestDir::new("sit", "named_user_query");
     dir.cmd()
@@ -164,6 +175,7 @@ fn item_named_user_query() {
 
 /// Should prefer repo named query over user user named query
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item_repo_over_named_user_query() {
     let dir = TestDir::new("sit", "repo_over_named_user_query");
     dir.cmd()
diff --git a/sit/tests/command_path.rs b/sit/tests/command_path.rs
index 9626d8e..2ebf56c 100644
--- a/sit/tests/command_path.rs
+++ b/sit/tests/command_path.rs
@@ -1,5 +1,7 @@
+extern crate sit_core;
 extern crate cli_test_dir;
 
+use sit_core::{Repository, path::HasPath};
 use cli_test_dir::*;
 use std::fs;
 
@@ -34,3 +36,21 @@ fn path_sit_dir() {
     assert_eq!(path.trim(), dir.path("1").join(".sit").to_str().unwrap());
 }
 
+/// `sit path --record <id>` should print path to a record
+#[test]
+fn record_path() {
+    let dir = TestDir::new("sit", "record_path");
+    dir.cmd()
+        .arg("init")
+        .expect_success();
+    // create a record
+    let record = String::from_utf8(dir.cmd()
+        .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
+        .args(&["record", "--no-author", "-t", "Sometype"])
+        .expect_success().stdout).unwrap();
+    let path = String::from_utf8(dir.cmd().args(&["path", "--record", record.trim()]).expect_success().stdout).unwrap();
+    let repo = Repository::open(dir.path(".sit")).unwrap();
+    let rec = repo.record(record.trim()).unwrap();
+    assert_eq!(path.trim(), rec.path().to_str().unwrap());
+}
+
diff --git a/sit/tests/command_record.rs b/sit/tests/command_record.rs
index e42785e..b6a181c 100644
--- a/sit/tests/command_record.rs
+++ b/sit/tests/command_record.rs
@@ -5,15 +5,17 @@ extern crate chrono;
 extern crate which;
 
 use cli_test_dir::*;
-use sit_core::{Repository, Item, record::RecordExt};
+use sit_core::{Repository, record::RecordContainer, record::RecordExt};
 use std::process;
 
 include!("includes/config.rs");
 
-/// Should derive authorship from the config file
+/// Should allow recording for an item
 #[test]
-fn record_authorship() {
-    let dir = TestDir::new("sit", "record_no_authorship_local_git");
+#[cfg(feature = "deprecated-items")]
+fn item_record() {
+    use sit_core::path::ResolvePath;
+    let dir = TestDir::new("sit", "item_record");
     dir.cmd()
         .arg("init")
         .expect_success();
@@ -21,12 +23,30 @@ fn record_authorship() {
         .arg("item")
         .expect_success().stdout).unwrap().trim().into();
     user_config(&dir, r#"{"author": {"name": "Test", "email": "test@test.com"}}"#);
-    dir.cmd()
+    let record: String = String::from_utf8(dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
         .args(&["record", &id, "-t", "Sometype"])
+        .expect_success().stdout).unwrap().trim().into();
+    let rec_file = dir.path(".sit").join("items").join(id).join(record);
+    assert!(rec_file.is_file());
+    assert!(rec_file.resolve_dir().unwrap().is_dir());
+}
+
+/// Should derive authorship from the config file
+#[test]
+fn record_authorship() {
+    let dir = TestDir::new("sit", "record_no_authorship_local_git");
+    dir.cmd()
+        .arg("init")
         .expect_success();
-    verify_authors(&dir, &id,"Test <test@test.com>");
+    user_config(&dir, r#"{"author": {"name": "Test", "email": "test@test.com"}}"#);
+    dir.cmd()
+        .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
+        .env("USERPROFILE", dir.path(".").to_str().unwrap())
+        .args(&["record", "-t", "Sometype"])
+        .expect_success();
+    verify_authors(&dir, "Test <test@test.com>");
 }
 
 
@@ -37,14 +57,11 @@ fn record_no_authorship_no_git() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id = dir.cmd()
-        .arg("item")
-        .expect_success().stdout;
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", ::std::str::from_utf8(&id).unwrap(), "-t","Sometype"])
+        .args(&["record", "-t","Sometype"])
         .expect_failure();
 }
 
@@ -55,18 +72,14 @@ fn record_no_authorship_no_author() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-author", "-t", "Sometype"])
+        .args(&["record", "--no-author", "-t", "Sometype"])
         .expect_success();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id).unwrap();
-    let mut records = item.record_iter().unwrap();
+    let mut records = repo.record_iter().unwrap();
     let record = records.next().unwrap().pop().unwrap();
     assert!(record.file(".authors").is_none());
 }
@@ -78,18 +91,14 @@ fn record_no_aux() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-aux"])
+        .args(&["record", "--no-aux"])
         .expect_success();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id).unwrap();
-    let mut records = item.record_iter().unwrap();
+    let mut records = repo.record_iter().unwrap();
     let record = records.next().unwrap().pop().unwrap();
     assert!(record.file(".timestamp").is_none());
     assert!(record.file(".authors").is_none());
@@ -103,17 +112,14 @@ fn record_no_authorship_local_git() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     dir.create_file(".git/config", "[user]\nname=Test\nemail=test@test.com");
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "-t", "Sometype"])
+        .args(&["record", "-t", "Sometype"])
         .expect_success();
-    verify_authors(&dir, &id,"Test <test@test.com>");
+    verify_authors(&dir, "Test <test@test.com>");
 }
 
 /// Should derive authorship from $HOME/.gitconfig if it is otherwise unavailable
@@ -123,17 +129,14 @@ fn record_no_authorship_user_git() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     dir.create_file(".gitconfig","[user]\nname=Test\nemail=test@test.com");
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "-t","Sometype"])
+        .args(&["record", "-t","Sometype"])
         .expect_success();
-    verify_authors(&dir, &id,"Test <test@test.com>");
+    verify_authors(&dir, "Test <test@test.com>");
 }
 
 /// Should prefer .git/config over $HOME/.gitconfig if authorship information is unavailable otherwise
@@ -143,18 +146,15 @@ fn record_no_authorship_local_over_user_git() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     dir.create_file(".gitconfig","[user]\nname=Test\nemail=test@test.com");
     dir.create_file(".git/config","[user]\nname=User\nemail=user@test.com");
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "-t","Sometype"])
+        .args(&["record",  "-t","Sometype"])
         .expect_success();
-    verify_authors(&dir, &id,"User <user@test.com>");
+    verify_authors(&dir, "User <user@test.com>");
 }
 
 /// Should record a timestamp
@@ -164,18 +164,14 @@ fn record_should_record_timestamp() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-author", "-t","Sometype"])
+        .args(&["record", "--no-author", "-t","Sometype"])
         .expect_success();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id).unwrap();
-    let mut records = item.record_iter().unwrap();
+    let mut records = repo.record_iter().unwrap();
     let record = records.next().unwrap().pop().unwrap();
     let mut s = String::new();
     use std::io::Read;
@@ -193,18 +189,14 @@ fn record_should_not_record_timestamp() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-author", "--no-timestamp", "-t","Sometype"])
+        .args(&["record", "--no-author", "--no-timestamp", "-t","Sometype"])
         .expect_success();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id).unwrap();
-    let mut records = item.record_iter().unwrap();
+    let mut records = repo.record_iter().unwrap();
     let record = records.next().unwrap().pop().unwrap();
     assert!(record.file(".timestamp").is_none());
 }
@@ -216,15 +208,12 @@ fn record_should_not_record_if_files_are_missing() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     dir.create_file("exists","");
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-author", "-t","Sometype", "exists", "missing"])
+        .args(&["record", "--no-author", "-t","Sometype", "exists", "missing"])
         .expect_failure();
 }
 
@@ -235,15 +224,12 @@ fn record_should_fail_if_no_type() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     dir.create_file("file", "");
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-author", "file"])
+        .args(&["record", "--no-author", "file"])
         .expect_success();
 }
 
@@ -254,19 +240,15 @@ fn record_dot_type_sufficiency() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     dir.create_file(".type/MyType","");
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are no configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-author", ".type/MyType"])
+        .args(&["record", "--no-author", ".type/MyType"])
         .expect_success();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id).unwrap();
-    let mut records = item.record_iter().unwrap();
+    let mut records = repo.record_iter().unwrap();
     let record = records.next().unwrap().pop().unwrap();
     assert!(record.file(".type/MyType").is_some());
 }
@@ -279,20 +261,16 @@ fn record_should_merge_types() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     dir.create_file(".type/MyType","");
     dir.create_file(".type/OurType","");
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-author", "-t","Sometype,SomeOtherType",".type/MyType", ".type/OurType"])
+        .args(&["record", "--no-author", "-t","Sometype,SomeOtherType",".type/MyType", ".type/OurType"])
         .expect_success();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id).unwrap();
-    let mut records = item.record_iter().unwrap();
+    let mut records = repo.record_iter().unwrap();
     let record = records.next().unwrap().pop().unwrap();
     assert!(record.file(".type/Sometype").is_some());
     assert!(record.file(".type/SomeOtherType").is_some());
@@ -307,20 +285,16 @@ fn record_should_record_files() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     dir.create_file("file1","file1");
     dir.create_file("files/file2","file2");
     no_user_config(&dir);
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-author", "-t","Sometype","file1", "files/file2"])
+        .args(&["record", "--no-author", "-t","Sometype","file1", "files/file2"])
         .expect_success();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id).unwrap();
-    let mut records = item.record_iter().unwrap();
+    let mut records = repo.record_iter().unwrap();
     let record = records.next().unwrap().pop().unwrap();
     let mut s = String::new();
     use std::io::Read;
@@ -338,18 +312,14 @@ fn record_should_record_files_and_directories() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
     dir.create_file("file1","file1");
     dir.create_file("files/file2","file2");
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
-        .args(&["record", &id, "--no-author", "-t","Sometype","file1", "files"])
+        .args(&["record", "--no-author", "-t","Sometype","file1", "files"])
         .expect_success();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id).unwrap();
-    let mut records = item.record_iter().unwrap();
+    let mut records = repo.record_iter().unwrap();
     let record = records.next().unwrap().pop().unwrap();
     let mut s = String::new();
     use std::io::Read;
@@ -398,19 +368,15 @@ fn record_should_sign_if_configured() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
 
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("GNUPGHOME", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-author", "-t","Sometype"])
+        .args(&["record", "--no-author", "-t","Sometype"])
         .expect_success();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id).unwrap();
-    let mut records = item.record_iter().unwrap();
+    let mut records = repo.record_iter().unwrap();
     let record = records.next().unwrap().pop().unwrap();
     assert!(record.file(".signature").is_some());
 }
@@ -450,28 +416,23 @@ fn record_should_sign_if_instructed_cmdline() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
 
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("GNUPGHOME", dir.path(".").to_str().unwrap())
-        .args(&["record", "--sign",  "--signing-key", "test@test.com", &id, "--no-author", "-t","Sometype"])
+        .args(&["record", "--sign",  "--signing-key", "test@test.com", "--no-author", "-t","Sometype"])
         .expect_success();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id).unwrap();
-    let mut records = item.record_iter().unwrap();
+    let mut records = repo.record_iter().unwrap();
     let record = records.next().unwrap().pop().unwrap();
     assert!(record.file(".signature").is_some());
 }
 
 
-fn verify_authors<S0: AsRef<str>, S: AsRef<str>>(dir: &TestDir, id: S0, expected: S) {
+fn verify_authors<S: AsRef<str>>(dir: &TestDir, expected: S) {
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id).unwrap();
-    let mut records = item.record_iter().unwrap();
+    let mut records = repo.record_iter().unwrap();
     let record = records.next().unwrap().pop().unwrap();
     let mut s = String::new();
     use std::io::Read;
diff --git a/sit/tests/command_records.rs b/sit/tests/command_records.rs
index ad922c3..0925658 100644
--- a/sit/tests/command_records.rs
+++ b/sit/tests/command_records.rs
@@ -5,7 +5,7 @@ extern crate remove_dir_all;
 
 use std::process;
 
-use sit_core::{Repository, Item};
+use sit_core::{Repository, record::RecordOwningContainer, path::ResolvePath};
 
 use cli_test_dir::*;
 use remove_dir_all::*;
@@ -19,11 +19,23 @@ fn no_records() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
-    let output = String::from_utf8(dir.cmd().args(&["records", id.trim()]).expect_success().stdout).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["records"]).expect_success().stdout).unwrap();
     assert_eq!(output, "");
 }
 
+/// Should list a record for item if there's one
+#[test]
+#[cfg(feature = "deprecated-items")]
+fn record_for_item() {
+    let dir = TestDir::new("sit", "rec_item_record");
+    dir.cmd()
+        .arg("init")
+        .expect_success();
+    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
+    let record = String::from_utf8(dir.cmd().args(&["record", id.trim(), "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["records", id.trim()]).expect_success().stdout).unwrap();
+    assert_eq!(output, record);
+}
 
 /// Should list a record if there's one
 #[test]
@@ -32,9 +44,8 @@ fn record() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
-    let record = String::from_utf8(dir.cmd().args(&["record", id.trim(), "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
-    let output = String::from_utf8(dir.cmd().args(&["records", id.trim()]).expect_success().stdout).unwrap();
+    let record = String::from_utf8(dir.cmd().args(&["record", "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["records" ]).expect_success().stdout).unwrap();
     assert_eq!(output, record);
 }
 
@@ -46,11 +57,10 @@ fn filter() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
-    let record = String::from_utf8(dir.cmd().args(&["record", id.trim(), "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
-    let record1 = String::from_utf8(dir.cmd().args(&["record", id.trim(), "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
+    let record = String::from_utf8(dir.cmd().args(&["record", "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
+    let record1 = String::from_utf8(dir.cmd().args(&["record", "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
     // filter out item we just created
-    let output = String::from_utf8(dir.cmd().args(&["records", id.trim(), "-f", &format!("hash != '{}'", record.trim())]).expect_success().stdout).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["records", "-f", &format!("hash != '{}'", record.trim())]).expect_success().stdout).unwrap();
     assert_eq!(output, record1);
 }
 
@@ -61,12 +71,11 @@ fn named_filter() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
-    let record = String::from_utf8(dir.cmd().args(&["record", id.trim(), "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
-    let record1 = String::from_utf8(dir.cmd().args(&["record", id.trim(), "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
+    let record = String::from_utf8(dir.cmd().args(&["record", "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
+    let record1 = String::from_utf8(dir.cmd().args(&["record", "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
     // filter out item we just created
     dir.create_file(".sit/.records/filters/f1", &format!("hash != '{}'", record.trim()));
-    let output = String::from_utf8(dir.cmd().args(&["records", id.trim(), "-F", "f1"]).expect_success().stdout).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["records", "-F", "f1"]).expect_success().stdout).unwrap();
     assert_eq!(output, record1);
 }
 
@@ -78,16 +87,15 @@ fn named_user_filter() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
-    let record = String::from_utf8(dir.cmd().args(&["record", id.trim(), "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
-    let record1 = String::from_utf8(dir.cmd().args(&["record", id.trim(), "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
+    let record = String::from_utf8(dir.cmd().args(&["record", "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
+    let record1 = String::from_utf8(dir.cmd().args(&["record", "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
     // filter out item we just created
     let cfg = &format!(r#"{{"records": {{"filters": {{"f1": "hash != '{}'"}}}}}}"#, record.trim());
     user_config(&dir, cfg);
     let output = String::from_utf8(dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap())
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["records", id.trim(), "-F", "f1"]).expect_success().stdout).unwrap();
+        .args(&["records", "-F", "f1"]).expect_success().stdout).unwrap();
     assert_eq!(output, record1);
 }
 
@@ -98,9 +106,8 @@ fn repo_over_named_user_filter() {
     dir.cmd()
         .arg("init")
         .expect_success();
-       let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
-    let record = String::from_utf8(dir.cmd().args(&["record", id.trim(), "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
-    let record1 = String::from_utf8(dir.cmd().args(&["record", id.trim(), "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
+    let record = String::from_utf8(dir.cmd().args(&["record", "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
+    let record1 = String::from_utf8(dir.cmd().args(&["record", "--no-author", "-t", "Type"]).expect_success().stdout).unwrap();
     // filter out item we just created
     let cfg = &format!(r#"{{"records": {{"filters": {{"f1": "hash != '{}'"}}}}}}"#, record1.trim());
     user_config(&dir, cfg);
@@ -108,7 +115,7 @@ fn repo_over_named_user_filter() {
     let output = String::from_utf8(dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap())
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["records", id.trim(), "-F", "f1"]).expect_success().stdout).unwrap();
+        .args(&["records", "-F", "f1"]).expect_success().stdout).unwrap();
     assert_eq!(output, record);
 }
 
@@ -119,12 +126,10 @@ fn query() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id.trim()).unwrap();
     // create a record
-    let _record = item.new_record(vec![("test", &b"passed"[..])].into_iter(), true).unwrap();
-    let output = String::from_utf8(dir.cmd().args(&["records",id.trim(),"-q", "files.test"]).expect_success().stdout).unwrap();
+    let _record = repo.new_record(vec![("test", &b"passed"[..])].into_iter(), true).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["records", "-q", "files.test"]).expect_success().stdout).unwrap();
     assert_eq!(output.trim(), "passed");
 }
 
@@ -136,13 +141,11 @@ fn named_query() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id.trim()).unwrap();
     // create a record
-    let _record = item.new_record(vec![("test", &b"passed"[..])].into_iter(), true).unwrap();
+    let _record = repo.new_record(vec![("test", &b"passed"[..])].into_iter(), true).unwrap();
     dir.create_file(".sit/.records/queries/q1", "files.test");
-    let output = String::from_utf8(dir.cmd().args(&["records",id.trim(),"-Q", "q1"]).expect_success().stdout).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["records","-Q", "q1"]).expect_success().stdout).unwrap();
     assert_eq!(output.trim(), "passed");
 }
 
@@ -154,17 +157,15 @@ fn named_user_query() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id.trim()).unwrap();
     // create a record
-    let _record = item.new_record(vec![("test", &b"passed"[..])].into_iter(), true).unwrap();
+    let _record = repo.new_record(vec![("test", &b"passed"[..])].into_iter(), true).unwrap();
     let cfg = r#"{"records": {"queries": {"q1": "files.test"}}}"#;
     user_config(&dir, cfg);
     let output = String::from_utf8(dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap())
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["records", id.trim(), "-Q", "q1"]).expect_success().stdout).unwrap();
+        .args(&["records", "-Q", "q1"]).expect_success().stdout).unwrap();
     assert_eq!(output.trim(), "passed");
 }
 
@@ -176,18 +177,16 @@ fn repo_over_named_user_query() {
     dir.cmd()
         .arg("init")
         .expect_success();
-        let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
     let repo = Repository::open(dir.path(".sit")).unwrap();
-    let item = repo.item(id.trim()).unwrap();
     // create a record
-    let _record = item.new_record(vec![("test", &b"passed"[..])].into_iter(), true).unwrap();
+    let _record = repo.new_record(vec![("test", &b"passed"[..])].into_iter(), true).unwrap();
     dir.create_file(".sit/.records/queries/q1", "files.test");
     let cfg = r#"{"records": {"queries": {"q1": "null"}}}"#;
     user_config(&dir, cfg);
     let output = String::from_utf8(dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap())
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["records", id.trim(), "-Q", "q1"]).expect_success().stdout).unwrap();
+        .args(&["records", "-Q", "q1"]).expect_success().stdout).unwrap();
     assert_eq!(output.trim(), "passed");
 }
 
@@ -226,22 +225,19 @@ fn pgp_signature() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
 
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
         .env("GNUPGHOME", dir.path(".").to_str().unwrap())
-        .args(&["record", "--sign",  "--signing-key", "test@test.com", &id, "--no-author", "-t","Sometype"])
+        .args(&["record", "--sign",  "--signing-key", "test@test.com", "--no-author", "-t","Sometype"])
         .expect_success();
 
     let output = String::from_utf8(dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap())
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
         .env("GNUPGHOME", dir.path(".").to_str().unwrap())
-        .args(&["records", id.trim(), "-v", "-q", "verification.success"]).expect_success().stdout).unwrap();
+        .args(&["records", "-v", "-q", "verification.success"]).expect_success().stdout).unwrap();
     assert_eq!(output.trim(), "true");
 }
 
@@ -280,24 +276,25 @@ fn pgp_signature_wrong_data() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
 
     // Snatch the signature
     let oldrec = String::from_utf8(dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
         .env("GNUPGHOME", dir.path(".").to_str().unwrap())
-        .args(&["record", "--sign",  "--signing-key", "test@test.com", &id, "--no-author", "-t","Sometype"])
+        .args(&["record", "--sign", "--signing-key", "test@test.com", "--no-author", "-t","Sometype"])
         .expect_success().stdout).unwrap();
 
+    use std::path::PathBuf;
+    let oldrec_path: PathBuf = String::from_utf8(dir.cmd().args(&["path","--record", oldrec.trim()]).expect_success().stdout)
+        .unwrap().trim().into();
+
     use std::fs::File;
     use std::io::{Read, Write};
-    let mut f = File::open(dir.path(".sit").join("items").join(id.trim()).join(oldrec.trim()).join(".signature")).unwrap();
+    let mut f = File::open(oldrec_path.resolve_dir().unwrap().join(".signature")).unwrap();
     let mut s = String::new();
     f.read_to_string(&mut s).unwrap();
-    remove_dir_all(dir.path(".sit").join("items").join(id.trim()).join(oldrec.trim())).unwrap();
+    remove_dir_all(oldrec_path.resolve_dir().unwrap()).unwrap();
 
     let mut f = File::create(dir.path(".signature")).unwrap();
     f.write(s.as_bytes()).unwrap();
@@ -307,7 +304,7 @@ fn pgp_signature_wrong_data() {
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
         .env("GNUPGHOME", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-author", "-t","Sometype1", ".signature"])
+        .args(&["record", "--no-author", "-t","Sometype1", ".signature"])
         .expect_success();
 
 
@@ -315,7 +312,7 @@ fn pgp_signature_wrong_data() {
         .env("HOME", dir.path(".").to_str().unwrap())
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
         .env("GNUPGHOME", dir.path(".").to_str().unwrap())
-        .args(&["records", id.trim(), "-v", "-q", "verification.success"]).expect_success().stdout).unwrap();
+        .args(&["records", "-v", "-q", "verification.success"]).expect_success().stdout).unwrap();
     assert_eq!(output.trim(), "false");
 }
 
@@ -329,19 +326,16 @@ fn pgp_no_signature() {
     dir.cmd()
         .arg("init")
         .expect_success();
-    let id: String = String::from_utf8(dir.cmd()
-        .arg("item")
-        .expect_success().stdout).unwrap().trim().into();
 
     dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap()) // to ensure there are right configs
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["record", &id, "--no-author", "-t","Sometype"])
+        .args(&["record", "--no-author", "-t","Sometype"])
         .expect_success();
 
     let output = String::from_utf8(dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap())
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["records", id.trim(), "-v", "-q", "verification"]).expect_success().stdout).unwrap();
+        .args(&["records", "-v", "-q", "verification"]).expect_success().stdout).unwrap();
     assert_eq!(output.trim(), "null");
 }
diff --git a/sit/tests/command_reduce.rs b/sit/tests/command_reduce.rs
index a560c13..60383d3 100644
--- a/sit/tests/command_reduce.rs
+++ b/sit/tests/command_reduce.rs
@@ -2,7 +2,7 @@ extern crate cli_test_dir;
 extern crate sit_core;
 extern crate serde_json;
 
-use sit_core::{Repository, Item};
+use sit_core::{Repository, record::RecordOwningContainer, Record};
 
 use cli_test_dir::*;
 
@@ -10,6 +10,7 @@ include!("includes/config.rs");
 
 /// Should fail if there is no item to reduce
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn no_item() {
     let dir = TestDir::new("sit", "no_item");
     dir.cmd()
@@ -20,6 +21,7 @@ fn no_item() {
 
 /// Should return the entire reduced item
 #[test]
+#[cfg(feature = "deprecated-items")]
 fn item() {
     let dir = TestDir::new("sit", "item");
     dir.cmd()
@@ -42,9 +44,77 @@ fn item() {
 
 }
 
+/// Should return the entire reduced repository
+#[test]
+fn reduce_repo() {
+    let dir = TestDir::new("sit", "reduce_repo");
+    dir.cmd()
+        .arg("init")
+        .expect_success();
+    dir.create_file(".sit/reducers/test.js",r#"
+    module.exports = function(state, record) {
+        return Object.assign(state, {value: "hello"});
+    }
+    "#);
+    // create a record
+    Repository::open(dir.path(".sit")).unwrap().new_record(vec![("test", &b""[..])].into_iter(), true).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["reduce"]).expect_success().stdout).unwrap();
+    use serde_json::Map;
+    let mut expect = Map::new();
+    expect.insert("value".into(), serde_json::Value::String("hello".into()));
+    assert_eq!(serde_json::from_str::<serde_json::Value>(output.trim()).unwrap(), serde_json::Value::Object(expect));
+}
+
+/// Should return the entire reduced repository
+/// using a custom reducer
+#[test]
+fn reduce_repo_custom() {
+    let dir = TestDir::new("sit", "reduce_repo_custom");
+    dir.cmd()
+        .arg("init")
+        .expect_success();
+    dir.create_file("test.js",r#"
+    module.exports = function(state, record) {
+        return Object.assign(state, {value: "hello"});
+    }
+    "#);
+    // create a record
+    Repository::open(dir.path(".sit")).unwrap().new_record(vec![("test", &b""[..])].into_iter(), true).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["reduce", "-r", dir.path("test.js").to_str().unwrap()]).expect_success().stdout).unwrap();
+    use serde_json::Map;
+    let mut expect = Map::new();
+    expect.insert("value".into(), serde_json::Value::String("hello".into()));
+    assert_eq!(serde_json::from_str::<serde_json::Value>(output.trim()).unwrap(), serde_json::Value::Object(expect));
+}
+
+/// Should return the entire reduced repository
+/// using a named reducer
+#[test]
+fn reduce_repo_named() {
+    let dir = TestDir::new("sit", "reduce_repo_named");
+    dir.cmd()
+        .arg("init")
+        .expect_success();
+    dir.create_file(".sit/reducers/test/reducer.js",r#"
+    module.exports = function(state, record) {
+        return Object.assign(state, {value: "hello"});
+    }
+    "#);
+    // create a record
+    Repository::open(dir.path(".sit")).unwrap().new_record(vec![("test", &b""[..])].into_iter(), true).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["reduce", "-r", "test"]).expect_success().stdout).unwrap();
+    use serde_json::Map;
+    let mut expect = Map::new();
+    expect.insert("value".into(), serde_json::Value::String("hello".into()));
+    assert_eq!(serde_json::from_str::<serde_json::Value>(output.trim()).unwrap(), serde_json::Value::Object(expect));
+}
+
+
+
+
 /// Should apply query
 #[test]
-fn item_query() {
+fn record_query() {
     let dir = TestDir::new("sit", "query");
     dir.cmd()
         .arg("init")
@@ -54,16 +124,15 @@ fn item_query() {
         return Object.assign(state, {value: "hello"});
     }
     "#);
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
     // create a record
-    Repository::open(dir.path(".sit")).unwrap().item(id.trim()).unwrap().new_record(vec![("test", &b""[..])].into_iter(), true).unwrap();
-    let output = String::from_utf8(dir.cmd().args(&["reduce", id.trim(), "-q", "join(' ', ['item', id, value])"]).expect_success().stdout).unwrap();
-    assert_eq!(output.trim(), format!("item {} hello", id.trim()));
+    Repository::open(dir.path(".sit")).unwrap().new_record(vec![("test", &b""[..])].into_iter(), true).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["reduce", "-q", "join(' ', ['item', value])"]).expect_success().stdout).unwrap();
+    assert_eq!(output.trim(), "item hello");
 }
 
 /// Should apply named query
 #[test]
-fn item_named_query() {
+fn record_named_query() {
     let dir = TestDir::new("sit", "named_query");
     dir.cmd()
         .arg("init")
@@ -73,17 +142,16 @@ fn item_named_query() {
         return Object.assign(state, {value: "hello"});
     }
     "#);
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
     // create a record
-    Repository::open(dir.path(".sit")).unwrap().item(id.trim()).unwrap().new_record(vec![("test", &b""[..])].into_iter(), true).unwrap();
-    dir.create_file(".sit/.items/queries/q1", "join(' ', ['item', id, value])");
-    let output = String::from_utf8(dir.cmd().args(&["reduce", id.trim(), "-Q", "q1"]).expect_success().stdout).unwrap();
-    assert_eq!(output.trim(), format!("item {} hello", id.trim()));
+    Repository::open(dir.path(".sit")).unwrap().new_record(vec![("test", &b""[..])].into_iter(), true).unwrap();
+    dir.create_file(".sit/.queries/q1", "join(' ', ['item', value])");
+    let output = String::from_utf8(dir.cmd().args(&["reduce", "-Q", "q1"]).expect_success().stdout).unwrap();
+    assert_eq!(output.trim(), "item hello");
 }
 
 /// Should apply named user query
 #[test]
-fn item_named_user_query() {
+fn record_named_user_query() {
     let dir = TestDir::new("sit", "named_user_query");
     dir.cmd()
         .arg("init")
@@ -93,21 +161,20 @@ fn item_named_user_query() {
         return Object.assign(state, {value: "hello"});
     }
     "#);
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
     // create a record
-    Repository::open(dir.path(".sit")).unwrap().item(id.trim()).unwrap().new_record(vec![("test", &b""[..])].into_iter(), true).unwrap();
-    let cfg = r#"{"items": {"queries": {"q1": "join(' ', ['item', id, value])"}}}"#;
+    Repository::open(dir.path(".sit")).unwrap().new_record(vec![("test", &b""[..])].into_iter(), true).unwrap();
+    let cfg = r#"{"items": {"queries": {"q1": "join(' ', ['item', value])"}}}"#;
     user_config(&dir, cfg);
     let output = String::from_utf8(dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap())
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["reduce", id.trim(), "-Q", "q1"]).expect_success().stdout).unwrap();
-    assert_eq!(output.trim(), format!("item {} hello", id.trim()));
+        .args(&["reduce", "-Q", "q1"]).expect_success().stdout).unwrap();
+    assert_eq!(output.trim(), "item hello");
 }
 
 /// Should prefer repo named query over user user named query
 #[test]
-fn item_repo_over_named_user_query() {
+fn record_repo_over_named_user_query() {
     let dir = TestDir::new("sit", "repo_over_named_user_query");
     dir.cmd()
         .arg("init")
@@ -117,15 +184,63 @@ fn item_repo_over_named_user_query() {
         return Object.assign(state, {value: "hello"});
     }
     "#);
-    let id = String::from_utf8(dir.cmd().arg("item").expect_success().stdout).unwrap();
     // create a record
-    Repository::open(dir.path(".sit")).unwrap().item(id.trim()).unwrap().new_record(vec![("test", &b""[..])].into_iter(), true).unwrap();
-    let cfg = r#"{"items": {"queries": {"q1": "join(' ', ['item', id])"}}}"#;
+    Repository::open(dir.path(".sit")).unwrap().new_record(vec![("test", &b""[..])].into_iter(), true).unwrap();
+    let cfg = r#"{"items": {"queries": {"q1": "join(' ', ['item'])"}}}"#;
     user_config(&dir, cfg);
-    dir.create_file(".sit/.items/queries/q1", "join(' ', ['item', id, value])");
+    dir.create_file(".sit/.queries/q1", "join(' ', ['item', value])");
     let output = String::from_utf8(dir.cmd()
         .env("HOME", dir.path(".").to_str().unwrap())
         .env("USERPROFILE", dir.path(".").to_str().unwrap())
-        .args(&["reduce", id.trim(), "-Q", "q1"]).expect_success().stdout).unwrap();
-    assert_eq!(output.trim(), format!("item {} hello", id.trim()));
+        .args(&["reduce", "-Q", "q1"]).expect_success().stdout).unwrap();
+    assert_eq!(output.trim(), "item hello");
+}
+
+/// Should reduce starting at a fixed root
+#[test]
+fn reduce_repo_fixed_roots() {
+    let dir = TestDir::new("sit", "reduce_repo_fixed_roots");
+    dir.cmd()
+        .arg("init")
+        .expect_success();
+    dir.create_file(".sit/reducers/test.js",r#"
+    module.exports = function(state, record) {
+        var v = state.value || "";
+        v = v + new TextDecoder('utf-8').decode(record.files.test);
+        return Object.assign(state, {value: v});
+    }
+    "#);
+    // create a record
+    let repo = Repository::open(dir.path(".sit")).unwrap();
+    let _rec1 = repo.new_record(vec![("test", &b"1"[..])].into_iter(), false).unwrap();
+    let rec2 = repo.new_record(vec![("test", &b"2"[..])].into_iter(), false).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["reduce", "--root", &rec2.encoded_hash()]).expect_success().stdout).unwrap();
+    use serde_json::Map;
+    let mut expect = Map::new();
+    expect.insert("value".into(), serde_json::Value::String("2".into()));
+    assert_eq!(serde_json::from_str::<serde_json::Value>(output.trim()).unwrap(), serde_json::Value::Object(expect));
+}
+
+/// Should reduce starting with a certain state
+#[test]
+fn reduce_repo_initial_state() {
+    let dir = TestDir::new("sit", "reduce_repo_initial_state");
+    dir.cmd()
+        .arg("init")
+        .expect_success();
+    dir.create_file(".sit/reducers/test.js",r#"
+    module.exports = function(state, record) {
+        var v = state.value || "";
+        v = v + new TextDecoder('utf-8').decode(record.files.test);
+        return Object.assign(state, {value: v});
+    }
+    "#);
+    // create a record
+    let repo = Repository::open(dir.path(".sit")).unwrap();
+    repo.new_record(vec![("test", &b"1"[..])].into_iter(), false).unwrap();
+    let output = String::from_utf8(dir.cmd().args(&["reduce", "--state", "{\"value\": \"0\"}"]).expect_success().stdout).unwrap();
+    use serde_json::Map;
+    let mut expect = Map::new();
+    expect.insert("value".into(), serde_json::Value::String("01".into()));
+    assert_eq!(serde_json::from_str::<serde_json::Value>(output.trim()).unwrap(), serde_json::Value::Object(expect));
 }
-- 
2.16.4

